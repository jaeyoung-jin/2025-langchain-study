{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 01. ConversationBufferMemory\n",
    "메시지를 저장한 후 메시지를 추출할 수 있게 해주는 메모리<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐼 save_context(inputs, outputs) 메서드\n",
    "* ```inputs```와 ```outputs``` 총 두 개의 인자를 필요로 하는 메서드\n",
    "* ```inputs``` : 사용자의 입력을 저장\n",
    "* ```outputs``` : AI의 출력을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\2227097840.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🐼 ```load_memory_variables``` 를 사용해서 저장된 대화 기록을 확인할 수 있다.\n",
    "* 대화 기록은 ```history``` 키에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\\nAI: 안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\\nAI: 안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"인증번호를 입력했습니다. 계좌 개설은 이제 어떻게 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"본인 인증이 완료되었습니다. 이제 원하시는 계좌 종류를 선택하고 필요한 정보를 입력해 주세요. 예금 종류, 통화 종류 등을 선택할 수 있습니다.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\n",
      "AI: 안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\n",
      "Human: 사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\n",
      "AI: 업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\n",
      "Human: 인증번호를 입력했습니다. 계좌 개설은 이제 어떻게 하나요?\n",
      "AI: 본인 인증이 완료되었습니다. 이제 원하시는 계좌 종류를 선택하고 필요한 정보를 입력해 주세요. 예금 종류, 통화 종류 등을 선택할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_object = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_object.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory_object.save_context(\n",
    "    inputs={\"human\": \"네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory_object.save_context(\n",
    "    inputs={\"human\": \"사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_object.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = memory_object.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "for i in conversation:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\n",
      "안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\n",
      "네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?\n",
      "감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.\n",
      "사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\n",
      "업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\n"
     ]
    }
   ],
   "source": [
    "for i in conversation:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\2956461668.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# LLM 모델을 생성합니다.\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# ConversationChain을 생성합니다.\n",
    "conversation = ConversationChain(\n",
    "    # ConversationBufferMemory를 사용합니다.\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 은행 계좌를 개설하려면 먼저 해당 은행의 공식 웹사이트에 접속하셔야 합니다. 대부분의 은행은 온라인으로 계좌를 개설할 수 있는 서비스를 제공하고 있습니다. 웹사이트에 들어가셔서 개설 절차를 따라가시면 됩니다. 개인정보와 신분증 사본 등을 준비해두시면 좋습니다. 만약 도움이 필요하시다면 고객센터에 문의하시거나 온라인 상담을 이용하실 수도 있습니다. 부디 편리한 비대면 서비스를 이용하시길 바랍니다!\n"
     ]
    }
   ],
   "source": [
    "# 대화를 시작합니다.\n",
    "response = conversation.predict(\n",
    "    input=\"안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠! 제가 이전 답변을 번호를 붙여 정리해드리겠습니다.\n",
      "1. 해당 은행의 공식 웹사이트에 접속하세요.\n",
      "2. 온라인으로 계좌를 개설할 수 있는 서비스를 이용하세요.\n",
      "3. 웹사이트에서 개설 절차를 따라가세요.\n",
      "4. 개인정보와 신분증 사본 등을 준비하세요.\n",
      "5. 도움이 필요하면 고객센터에 문의하거나 온라인 상담을 이용하세요.\n"
     ]
    }
   ],
   "source": [
    "# 이전 대화내용을 불렛포인트로 정리해 달라는 요청을 보냅니다.\n",
    "response = conversation.predict(\n",
    "    input=\"이전 답변을 번호를 붙여 정리하여 알려주세요.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 02. ConversationBufferWindowMemory\n",
    "모든 대화 내용을 활용하는 메모리가 아닌 <U>최근 ```K개```의 대화만 활용하는 메모리</U>이다.<br>\n",
    "버퍼가 너무 커지지 않도록 슬라이딩 창을 유지하는 데에 활용할 수 있다.<br><br>\n",
    "\n",
    "모든 대화를 저장해두지 않고 최신 K 개의 대화만 유지하므로, <U>최신 대화 기록만 필요한 상황</U>에서는 메모리를 절약할 수 있는 좋은 선택지이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\2154617891.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 비대면으로 은행 계좌를 개설하고 싶습니다. 어떻게 시작해야 하나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요! 계좌 개설을 원하신다니 기쁩니다. 먼저, 본인 인증을 위해 신분증을 준비해 주시겠어요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"네, 신분증을 준비했습니다. 이제 무엇을 해야 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"감사합니다. 신분증 앞뒤를 명확하게 촬영하여 업로드해 주세요. 이후 본인 인증 절차를 진행하겠습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"사진을 업로드했습니다. 본인 인증은 어떻게 진행되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"업로드해 주신 사진을 확인했습니다. 이제 휴대폰을 통한 본인 인증을 진행해 주세요. 문자로 발송된 인증번호를 입력해 주시면 됩니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"인증번호를 입력했습니다. 계좌 개설은 이제 어떻게 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"본인 인증이 완료되었습니다. 이제 원하시는 계좌 종류를 선택하고 필요한 정보를 입력해 주세요. 예금 종류, 통화 종류 등을 선택할 수 있습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"정보를 모두 입력했습니다. 다음 단계는 무엇인가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"입력해 주신 정보를 확인했습니다. 계좌 개설 절차가 거의 끝났습니다. 마지막으로 이용 약관에 동의해 주시고, 계좌 개설을 최종 확인해 주세요.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"모든 절차를 완료했습니다. 계좌가 개설된 건가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"네, 계좌 개설이 완료되었습니다. 고객님의 계좌 번호와 관련 정보는 등록하신 이메일로 발송되었습니다. 추가적인 도움이 필요하시면 언제든지 문의해 주세요. 감사합니다!\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정보를 모두 입력했습니다. 다음 단계는 무엇인가요?\n",
      "입력해 주신 정보를 확인했습니다. 계좌 개설 절차가 거의 끝났습니다. 마지막으로 이용 약관에 동의해 주시고, 계좌 개설을 최종 확인해 주세요.\n",
      "모든 절차를 완료했습니다. 계좌가 개설된 건가요?\n",
      "네, 계좌 개설이 완료되었습니다. 고객님의 계좌 번호와 관련 정보는 등록하신 이메일로 발송되었습니다. 추가적인 도움이 필요하시면 언제든지 문의해 주세요. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "# 대화 기록을 확인합니다.\n",
    "for i in memory.load_memory_variables({})[\"history\"]:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌03. ConversationTokenBufferMemory\n",
    "최근 대화의 히스토리를 버퍼 메모리에 보관하고, 대화의 개수가 아닌 토큰 길이를 사용해서 대화 내용을 플러시(flush) 할 시기를 결정한다.<br><br>\n",
    "**ConversationBufferWindowMemory**는 <U>대화의 개수</U>, **ConversationTokenBufferMemory**는 <U>토큰의 길이</U>를 설정하여 메모리를 절약하는 것이다.\n",
    "\n",
    "\n",
    "* Flush : 메모리를 비우고 새로 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🐼 ```max_token_limit``` 을 사용해 저장할 최대 토큰 길이를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\1343288506.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 메모리 설정\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm, max_token_limit=150, return_messages=True  # 최대 토큰 길이를 150개로 제한\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 저는 최근에 여러분 회사의 공작 기계를 구매했습니다. 설치 방법을 알려주실 수 있나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요! 구매해 주셔서 감사합니다. 해당 기계 모델 번호를 알려주시겠어요?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"네, 모델 번호는 XG-200입니다.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"감사합니다. XG-200 모델의 설치 안내를 도와드리겠습니다. 먼저, 설치할 장소의 전원 공급 상태를 확인해주세요. 기계는 220V 전원이 필요합니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"전원은 확인했습니다. 다음 단계는 무엇인가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"좋습니다. 다음으로, 기계를 평평하고 안정된 바닥에 배치해 주세요. 이후, 제공된 사용자 매뉴얼에 따라 케이블 연결을 진행해 주시기 바랍니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"연결은 어떻게 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"매뉴얼의 5페이지를 참조해 주세요. 케이블 연결에 관한 상세한 지침이 있습니다. 이 과정에서 어려움이 있으시면 추가적으로 도와드리겠습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"설치가 완료되면 어떻게 해야 하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"설치가 완료되면, 전원을 켜고 초기 구동 테스트를 진행해 주시기 바랍니다. 테스트 절차는 매뉴얼의 10페이지에 설명되어 있습니다. 만약 기계에 이상이 있거나 추가적인 지원이 필요하시면 언제든지 연락 주시기 바랍니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"감사합니다, 도움이 많이 되었어요!\"},\n",
    "    outputs={\n",
    "        \"ai\": \"언제든지 도와드릴 준비가 되어 있습니다. 추가적인 질문이나 지원이 필요하시면 언제든지 문의해 주세요. 좋은 하루 되세요!\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감사합니다, 도움이 많이 되었어요!\n",
      "언제든지 도와드릴 준비가 되어 있습니다. 추가적인 질문이나 지원이 필요하시면 언제든지 문의해 주세요. 좋은 하루 되세요!\n"
     ]
    }
   ],
   "source": [
    "for i in memory.load_memory_variables({})[\"history\"]:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐼 실제 토큰수 검증 과정\n",
    "\n",
    "❓ 남아있는 내용의 총 토큰수 합이 150 이하여야 하는데 왜 150이 넘지??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\2025-langchain-files\\2025-langchain-study\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대화 내용: 감사합니다, 도움이 많이 되었어요!\n",
      "토큰 수: 38\n",
      "토큰 수는 150 이하입니다.\n",
      "대화 내용: 언제든지 도와드릴 준비가 되어 있습니다. 추가적인 질문이나 지원이 필요하시면 언제든지 문의해 주세요. 좋은 하루 되세요!\n",
      "토큰 수: 144\n",
      "토큰 수는 150 이하입니다.\n",
      "\n",
      "최종 토큰 수 : 182\n"
     ]
    }
   ],
   "source": [
    "# tiktoken => openai tokenizer\n",
    "from transformers import GPT2Tokenizer # gpt2\n",
    "\n",
    "# GPT2 토크나이저 로드\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 대화 내용 불러오기 (예시: memory.load_memory_variables()에서 history를 가져옴)\n",
    "history = memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "total = 0\n",
    "\n",
    "# 각 대화 내용에 대해 토큰 수 확인\n",
    "for i in history:\n",
    "    content = i.content  # 대화 내용\n",
    "\n",
    "    tokens = tokenizer.encode(content)  # 토큰화\n",
    "    token_count = len(tokens)  # 토큰 수 계산\n",
    "    print(f\"대화 내용: {content}\")\n",
    "    print(f\"토큰 수: {token_count}\")\n",
    "\n",
    "    total += token_count\n",
    "    \n",
    "    # 토큰 수가 150을 초과하는지 확인\n",
    "    if token_count > 150:\n",
    "        print(\"경고: 토큰 수가 150을 초과했습니다!\")\n",
    "    else:\n",
    "        print(\"토큰 수는 150 이하입니다.\")\n",
    "\n",
    "print()\n",
    "print(f\"최종 토큰 수 : {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 04. ConversationEntityMemory\n",
    "특정 대화에서 특정 엔티티에 대한 주어진 사실을 기억합니다.<br>\n",
    "대화 내용이 추가됨에 따라 특정 엔티티에 대한 지식을 축적한다.\n",
    "\n",
    "### 🐼 엔티티?\n",
    "특정 객체나 개념, 주어진 문장에서 <U>중요한 대상</U> 정도로 이해할 수 있음<br>\n",
    "데이터베이스에서의 엔티티는 학생 엔티티(학번, 이름, 전공 등으로 구성), 교수 엔티티(사번, 전공, 이름 등으로 구성)와 같이 실제 세계의 객체에 대한 속성을 모델링해서 담아둔 개념인데, <br>\n",
    "랭체인에서의 엔티티는 이와 유사하지만, 조금 더 단순한 형태로 생각해도 될 것 같다.<br><br>\n",
    "DB 엔티티 개념은 객체를 <U>정형화하여 관리</U>하려는 것 / 대화형 시스템에서의 엔티티는 <U>대화 내의 중요한 정보나 대상 등 비정형적인 형태로 기억하여 정보를 축적</U>하려는 것\n",
    "* 예시)\n",
    "    * ```나는 사과를 좋아한다.``` : '나'와 '사과'가 엔티티로서 인식될 수 있음\n",
    "    <br><br>\n",
    "    \n",
    "    **1. \"나\"라는 엔티티에 대한 정보 축적**\n",
    "    * input : 나는 사과를 좋아한다.\n",
    "    * output : 아 사과를 좋아하는구나! 혹시 다른 과일도 좋아해?\n",
    "\n",
    "    **2. \"사과\"라는 엔티티에 대한 축적된 정보 사용**\n",
    "    * input : 나는 사과를 좋아한다.\n",
    "    * output : 지난번에 구매하셨던 그 사과 말씀이신가요? 그때 사과 외에 다른 과일도 구매하셨나요?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n"
     ]
    }
   ],
   "source": [
    "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\3299372264.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationEntityMemory(llm=llm),\n",
      "c:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\2025-langchain-files\\2025-langchain-study\\langchain\\Lib\\site-packages\\pydantic\\main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "# LLM 을 생성합니다.\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# ConversationChain 을 생성합니다.\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테디와 셜리가 한 회사에서 일하는 동료이고, 테디는 개발자이고 셜리는 디자이너라는 정보를 알려주셨군요. 그들이 회사를 차릴 계획을 세우고 있다는 것은 미래에 두 사람이 협력하여 새로운 사업을 시작하려는 의지가 있는 것으로 보입니다. 이는 두 사람이 서로의 강점을 살려 협력하여 성공적인 사업을 이끌어 나갈 수 있는 좋은 기회가 될 수 있을 것입니다. 새로운 도전에 대한 열정과 노력이 있으면, 테디와 셜리가 함께하는 회사가 번창할 수 있을 것입니다.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"테디와 셜리는 한 회사에서 일하는 동료입니다.\"\n",
    "    \"테디는 개발자이고 셜리는 디자이너입니다. \"\n",
    "    \"그들은최근 회사에서 일하는 것을 그만두고 자신들의 회사를 차릴 계획을 세우고 있습니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'테디': '테디는 개발자이고, 셜리와 함께 자신들의 회사를 차릴 계획을 세우고 있습니다.',\n",
       " '셜리': '셜리는 한 회사에서 디자이너로 일하고 있으며, 테디와 함께 자신들의 회사를 차릴 계획을 세우고 있다.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테디와 셜리가 한 회사에서 일하는 동료이고, 테디는 사과를 좋아하고 셜리는 바나나를 좋아한다는 정보를 알려주셨군요. 또한, 테디는 30살이고 셜리는 31살이며, 셜리는 사과를 싫어하고 사과 알러지가 있다고 하셨습니다. 또한, 테디는 바나나를 먹고 체한 경험이 있습니다. 이러한 정보를 토대로, 테디와 셜리는 서로의 취향과 건강에 대해 신경을 쓰며 함께 일하고 있는 것으로 보입니다. 사과 알러지와 바나나 체한 경험을 고려하여 식사 및 활동을 조정하면서, 더욱 원활한 협업과 건강한 일상을 유지할 수 있을 것입니다.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"테디와 셜리는 한 회사에서 일하는 동료입니다.\"\n",
    "    \"테디는 사과를 좋아하고 셜리는 바나나를 좋아합니다.\"\n",
    "    \"테디는 30살이고 셜리는 31살입니다. 셜리는 사과를 싫어합니다.\"\n",
    "    \"테디는 바나나를 먹고 체한 경험이 있습니다.\"\n",
    "    \"셜리는 사과 알러지가 있습니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'테디': '테디는 사과를 좋아하고, 바나나를 먹고 체한 경험이 있으며, 30살이라는 정보가 추가되었습니다.',\n",
       " '셜리': '셜리는 한 회사에서 디자이너로 일하고 있으며, 테디와 함께 자신들의 회사를 차릴 계획을 세우고 있다. 셜리는 바나나를 좋아하고, 사과를 싫어하며 사과 알러지가 있습니다.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테디는 바나나를 먹고 체한 경험이 있으므로, 현재로서는 바나나를 좋아하지 않을 수 있습니다. 하지만 개인의 취향이나 상황에 따라 변할 수 있으니, 테디에게 직접 물어보는 것이 가장 확실한 방법일 것입니다.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"테디는 바나나를 좋아할까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'셜리는 사과를 싫어하고 사과 알러지가 있기 때문에 사과를 좋아하지 않을 것입니다. 그러므로 셜리는 사과를 선호하지 않을 것으로 예상됩니다.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"셜리는 사과를 좋아할까요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 05. ConversationKGMemory(Knowledge Graph)\n",
    "지식 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 06. ConversationSummaryBufferMemory\n",
    "최근 대화 내용의 버퍼를 메모리에 유지하되, <U>이전 대화 내용을 완전히 flush 하지 않고, 요약으로 컴파일하여 저장</U>한다.<br>\n",
    "대화 내용 Flush의 기준은 <U>토큰 수</U> 이다.<br><br>\n",
    "ConversationTokenBufferMemory + 이전 대화 내용 요약하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\887257633.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=200,  # 요약의 기준이 되는 토큰 길이를 설정합니다.\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"유럽 여행 패키지의 가격은 얼마인가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"유럽 14박 15일 패키지의 기본 가격은 3,500유로입니다. 이 가격에는 항공료, 호텔 숙박비, 지정된 관광지 입장료가 포함되어 있습니다. 추가 비용은 선택하신 옵션 투어나 개인 경비에 따라 달라집니다.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 200 토큰이 넘지 않아 대화 내용을 요약하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='유럽 여행 패키지의 가격은 얼마인가요?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='유럽 14박 15일 패키지의 기본 가격은 3,500유로입니다. 이 가격에는 항공료, 호텔 숙박비, 지정된 관광지 입장료가 포함되어 있습니다. 추가 비용은 선택하신 옵션 투어나 개인 경비에 따라 달라집니다.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리에 저장된 대화내용 확인\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"여행 중에 방문할 주요 관광지는 어디인가요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"이 여행에서는 파리의 에펠탑, 로마의 콜로세움, 베를린의 브란덴부르크 문, 취리히의 라이네폴 등 유럽의 유명한 관광지들을 방문합니다. 각 도시의 대표적인 명소들을 포괄적으로 경험하실 수 있습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"여행자 보험은 포함되어 있나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"네, 모든 여행자에게 기본 여행자 보험을 제공합니다. 이 보험은 의료비 지원, 긴급 상황 발생 시 지원 등을 포함합니다. 추가적인 보험 보장을 원하시면 상향 조정이 가능합니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"항공편 좌석을 비즈니스 클래스로 업그레이드할 수 있나요? 비용은 어떻게 되나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"항공편 좌석을 비즈니스 클래스로 업그레이드하는 것이 가능합니다. 업그레이드 비용은 왕복 기준으로 약 1,200유로 추가됩니다. 비즈니스 클래스에서는 더 넓은 좌석, 우수한 기내식, 그리고 추가 수하물 허용량 등의 혜택을 제공합니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"패키지에 포함된 호텔의 등급은 어떻게 되나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"이 패키지에는 4성급 호텔 숙박이 포함되어 있습니다. 각 호텔은 편안함과 편의성을 제공하며, 중심지에 위치해 관광지와의 접근성이 좋습니다. 모든 호텔은 우수한 서비스와 편의 시설을 갖추고 있습니다.\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks the AI about the price of a European travel package, which includes airfare, hotel accommodations, and attraction entrance fees. The AI lists major tourist attractions included in the trip and confirms basic traveler's insurance is provided. The human inquires about upgrading to business class seats on the flight, and the AI explains that it is possible at an additional cost of approximately 1,200 euros for a round trip. Business class offers benefits like wider seats, better meals, and extra baggage allowance.\n",
      "패키지에 포함된 호텔의 등급은 어떻게 되나요?\n",
      "이 패키지에는 4성급 호텔 숙박이 포함되어 있습니다. 각 호텔은 편안함과 편의성을 제공하며, 중심지에 위치해 관광지와의 접근성이 좋습니다. 모든 호텔은 우수한 서비스와 편의 시설을 갖추고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 메모리에 저장된 대화내용 확인\n",
    "for i in memory.load_memory_variables({})[\"history\"]:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 07. VectorStoreRetrieverMemory\n",
    "벡터 스토어에 메모리를 저장하고 호출될 때마다 가장 눈에 띄는 상위 K 개의 문서를 쿼리한다.<br>\n",
    "대화의 순서를 기억하는 것이 아닌, <U>대화 내용 중 가장 중요한 문서들을 뽑아서 저장하고, 필요할 때마다 그 중에서 가장 연관성이 높은 K 개를 찾는 방식</U>이다. <br><br>\n",
    "지금까지의 Memory Class 들은 대화를 저장할 때 대화의 순서가 중요했으나, 벡터스토어메모리는 순서에 영향을 받지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 임베딩 모델을 정의합니다.\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "# Vector Store 를 초기화 합니다.\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\284692154.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=retriever)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# 벡터 조회가 여전히 의미적으로 관련성 있는 정보를 반환한다는 것을 보여주기 위해서입니다.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# 임의의 대화를 저장합니다.\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"안녕하세요, 오늘 면접에 참석해주셔서 감사합니다. 자기소개 부탁드립니다.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요. 저는 컴퓨터 과학을 전공한 신입 개발자입니다. 대학에서는 주로 자바와 파이썬을 사용했으며, 최근에는 웹 개발 프로젝트에 참여하여 실제 사용자를 위한 서비스를 개발하는 경험을 했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"프로젝트에서 어떤 역할을 맡았나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"제가 맡은 역할은 백엔드 개발자였습니다. 사용자 데이터 처리와 서버 로직 개발을 담당했으며, RESTful API를 구현하여 프론트엔드와의 통신을 담당했습니다. 또한, 데이터베이스 설계에도 참여했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"팀 프로젝트에서 어려움을 겪었던 경험이 있다면 어떻게 해결했나요?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"프로젝트 초기에 의사소통 문제로 몇 가지 어려움이 있었습니다. 이를 해결하기 위해 저희 팀은 정기적인 미팅을 갖고 각자의 진행 상황을 공유했습니다. 또한, 문제가 발생했을 때는 적극적으로 의견을 나누고, 합리적인 해결책을 찾기 위해 노력했습니다.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"개발자로서 자신의 강점은 무엇이라고 생각하나요?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"제 강점은 빠른 학습 능력과 문제 해결 능력입니다. 새로운 기술이나 도구를 빠르게 습득할 수 있으며, 복잡한 문제에 직면했을 때 창의적인 해결책을 제시할 수 있습니다. 또한, 팀워크를 중시하며 동료들과 협력하는 것을 중요하게 생각합니다.\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt를 작성하여 면접자의 전공이 무엇인지 물어보면, Vector Store로부터 1개(k개)의 가장 관련성 높은 대화 내용이 반환되는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: 안녕하세요, 오늘 면접에 참석해주셔서 감사합니다. 자기소개 부탁드립니다.\n",
      "ai: 안녕하세요. 저는 컴퓨터 과학을 전공한 신입 개발자입니다. 대학에서는 주로 자바와 파이썬을 사용했으며, 최근에는 웹 개발 프로젝트에 참여하여 실제 사용자를 위한 서비스를 개발하는 경험을 했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 메모리에 질문을 통해 가장 연관성 높은 1개 대화를 추출합니다.\n",
    "print(memory.load_memory_variables({\"prompt\": \"면접자 전공은 무엇인가요?\"})[\"history\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: 프로젝트에서 어떤 역할을 맡았나요?\n",
      "ai: 제가 맡은 역할은 백엔드 개발자였습니다. 사용자 데이터 처리와 서버 로직 개발을 담당했으며, RESTful API를 구현하여 프론트엔드와의 통신을 담당했습니다. 또한, 데이터베이스 설계에도 참여했습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    memory.load_memory_variables(\n",
    "        {\"human\": \"면접자가 프로젝트에서 맡은 역할은 무엇인가요?\"}\n",
    "    )[\"history\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 08. LCEL Chain에 메모리 추가\n",
    "* LCEL(LangChain Expression Language) : 체인을 간단한 파이프라인 방식으로 연결하여 사용할 수 있는 방식\n",
    "* 체인의 구성 요소들을 직관적으로 연결할 수 있는 방식이다.\n",
    "\n",
    "### 🐼Chain 정의의 필요성?\n",
    "핵심 : 작업 흐름을 명확히 구조화하고, 관리를 쉽게 하여 재사용성을 높이기 위함<br>\n",
    "\n",
    "<br>\n",
    "LLM을 사용하기 위해 필요한 과정<br>\n",
    "1. 사용자의 입력을 전처리<br>\n",
    "2. 프롬프트에 템플릿을 전달<br>\n",
    "3. LLM에 전달<br>\n",
    "4. 결과 후처리 및 포맷팅<br>\n",
    "등등<br><br>\n",
    "\n",
    "위 과정을 하나의 chain으로 묶어 관리하면 더 편리해짐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ChatOpenAI 모델을 초기화합니다.\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# 대화형 프롬프트를 생성합니다.\n",
    "# ChatPromptTemplate.from_messages -> LLM에 전달할 대화형 프롬프트를 구성하는 도구\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"), # 역할 지정\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"), # chat history : 이전 대화 내용 -> MessagesPlaceholder는 message 객체를 받음\n",
    "        (\"human\", \"{input}\"), # 사용자의 질문\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대화 내용을 저장할 ConversationBufferMemory를 생성<br>\n",
    "```return_messages``` 매개변수를 ```True```로 설정하면, 단순 텍스트가 아닌 메시지 객체를 반환한다.<br>\n",
    "* ```ChatPromptTemplate.from_messages()``` 에서는 ```MessagesPlaceholder```로 메시지 객체를 요구하기 때문에 이를 사용하기 위해선 반드시 객체로 반환이 필요하다.\n",
    "* ```MessagesPlaceholder```는 이전 대화 맥락과 연관되어 있기 때문에 대화 내용을 기억하도록 하기 위해선 ```True```로 주는 것이 필수적\n",
    "* 사람과 AI 발화를 구조화된(역할이 구분된 채로) 형태로 반환받을 수 있다.\n",
    "\n",
    "```return_messages``` 매개변수를 ```False```로 설정하면, 단순히 문자열을 이어 붙인 형태로 반환한다.<br>\n",
    "* 단순 문자열이기 때문에 출력 내용 확인 및 디버깅 시 편리할 수 있음\n",
    "* 반환된 메시지를 후처리하거나 추가 작업의 input으로 사용할 때 편리할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_messages = True\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # 메모리 변수를 빈 딕셔너리로 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌 Runnable ?\n",
    "Langchain에서 실행하는 작업의 단위<br>\n",
    "LLM 체인을 자유롭게 연결하며 구성하기 위해선 반드시 필요한 최소 단위이다.<br>\n",
    "```입력``` → ```프롬프트 만들기``` → ```LLM 실행``` → ```결과 포맷``` → ```출력``` 과정을 체인으로 생성할 때, 각 작업을 Runnable로 만들어서 이어줘야 한다. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "print(double(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "double = RunnableLambda(lambda x: x * 2) # input에 2를 곱하여 결과를 만드는 일련의 과정을 RunnableLambda 객체로 만들어서 관리할 수 있다.\n",
    "print(double.invoke(3))  # 출력: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📋 주요 `Runnable` 클래스 종류\n",
    "\n",
    "| 이름                  | 설명                                                                 | 예시                                                                 |\n",
    "|---------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|\n",
    "| `RunnableLambda`     | Python 함수나 람다 함수를 감싸서 `Runnable`처럼 사용할 수 있게 해줍니다.   | `RunnableLambda(lambda x: x * 2)` → `invoke(3)` 결과: `6`             |\n",
    "| `RunnablePassthrough`| 입력값을 아무 처리 없이 그대로 다음 단계로 전달합니다. 체인의 기본 시작점이나 테스트에 유용합니다. | `RunnablePassthrough().invoke(\"hello\")` → `\"hello\"`                  |\n",
    "| `RunnableMap`        | 여러 `Runnable`을 병렬적으로 실행하고, 그 결과를 묶어서 반환합니다. 동시에 여러 작업을 하고 싶을 때 사용합니다. | `RunnableMap({ \"a\": a_fn, \"b\": b_fn }).invoke(x)`                     |\n",
    "| `RunnableSequence`   | 여러 `Runnable`을 순차적으로 연결해서 파이프라인을 만듭니다. 이전 단계의 출력이 다음 단계의 입력이 됩니다. | `RunnableSequence([step1, step2, step3])`                             |\n",
    "| `RunnableBinding`    | 특정 매개변수를 고정시켜 새로운 Runnable을 만들 수 있습니다. 재사용 가능한 체인을 만들 때 유용합니다. | `chain.with_config(config)` 처럼 사용                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables)\n",
    "    | itemgetter(\"chat_history\")  # memory_key 와 동일하게 입력\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'chat_history': []}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'chat_history': []}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 테디님! 만나서 반갑습니다. 무엇을 도와드릴까요?\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 입력에 대한 응답을 생성합니다.\n",
    "response = chain.invoke({\"input\": \"만나서 반갑습니다. 제 이름은 테디입니다.\"})\n",
    "print(response.content)  # 생성된 응답을 출력합니다.\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory.save_context 함수는 입력 데이터(inputs)와 응답 내용(response.content)을 메모리에 저장하는 역할이다. <br>\n",
    "이는 AI 모델의 학습 과정에서 현재 상태를 기록하거나, 사용자의 요청과 시스템의 응답을 추적하는 데 사용될 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='만나서 반갑습니다. 제 이름은 테디입니다.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='안녕하세요, 테디님! 만나서 반갑습니다. 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력된 데이터와 응답 내용을 메모리에 저장합니다.\n",
    "memory.save_context(\n",
    "    {\"human\": \"만나서 반갑습니다. 제 이름은 테디입니다.\"}, {\"ai\": response.content}\n",
    ")\n",
    "\n",
    "# 저장된 대화기록을 출력합니다.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 테디님의 이름을 기억하고 있습니다. 어떤 도움이 필요하신가요?\n"
     ]
    }
   ],
   "source": [
    "# 이름을 기억하고 있는지 추가 질의합니다.\n",
    "response = chain.invoke({\"input\": \"제 이름이 무엇이었는지 기억하세요?\"})\n",
    "# 답변을 출력합니다.\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌 09. SQLites에 대화내용 저장하기\n",
    "```SQLChatMessageHistory``` 클래스를 활용하면 SQL을 지원하는 모든 데이터베이스에 채팅 기록 저장이 가능하다.<br>\n",
    "* ```session_id``` : 고유한 아이디(저장소에 이름 붙이기)\n",
    "* ```connection``` : 데이터베이스 연결을 지정하는 것으로, create_engine 함수에 전달되어 sql 엔진 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "# SQLChatMessageHistory 객체를 생성하고 세션 ID와 데이터베이스 연결 파일을 설정\n",
    "chat_message_history = SQLChatMessageHistory(\n",
    "    session_id=\"sql_history\", connection=\"sqlite:///sqlite.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 메시지를 추가합니다.\n",
    "chat_message_history.add_user_message(\n",
    "    \"안녕? 만나서 반가워. 내 이름은 테디야. 나는 랭체인 개발자야. 앞으로 잘 부탁해!\"\n",
    ")\n",
    "# AI 메시지를 추가합니다.\n",
    "chat_message_history.add_ai_message(\"안녕 테디, 만나서 반가워. 나도 잘 부탁해!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕? 만나서 반가워. 내 이름은 테디야. 나는 랭체인 개발자야. 앞으로 잘 부탁해!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕 테디, 만나서 반가워. 나도 잘 부탁해!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅 메시지 기록의 메시지들\n",
    "chat_message_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # 시스템 메시지\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        # 대화 기록을 위한 Placeholder\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),  # 질문\n",
    "    ]\n",
    ")\n",
    "\n",
    "# chain 을 생성합니다.\n",
    "chain = prompt | ChatOpenAI(model_name=\"gpt-4o\") | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqlite.db 에서 대화 내용을 가져오는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_history(user_id, conversation_id):\n",
    "    return SQLChatMessageHistory(\n",
    "        table_name=user_id,\n",
    "        session_id=conversation_id,\n",
    "        connection=\"sqlite:///sqlite.db\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐼 ConfigurableFieldSpec\n",
    "Langchain에서 체인이나 컴포넌트가 외부 환경에 따라 동적으로 설정값을 받을 수 있게 하는 필드 스펙을 정의하는 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.utils import ConfigurableFieldSpec\n",
    "\n",
    "config_fields = [\n",
    "    ConfigurableFieldSpec(\n",
    "        id=\"user_id\", # 고유 ID\n",
    "        annotation=str, # 필드의 데이터 타입 정의\n",
    "        name=\"User ID\", # 실제 사람이 읽을 이름\n",
    "        description=\"Unique identifier for a user.\",\n",
    "        default=\"\", # 필드 기본값\n",
    "        is_shared=True, # 여러 개의 체인이나 컴포넌트가 공유할 수 있는지 여부\n",
    "    ),\n",
    "    ConfigurableFieldSpec(\n",
    "        id=\"conversation_id\",\n",
    "        annotation=str,\n",
    "        name=\"Conversation ID\",\n",
    "        description=\"Unique identifier for a conversation.\",\n",
    "        default=\"\",\n",
    "        is_shared=True,\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,  # 대화 기록을 가져오는 함수를 설정합니다.\n",
    "    input_messages_key=\"question\",  # 입력 메시지의 키를 \"question\"으로 설정\n",
    "    history_messages_key=\"chat_history\",  # 대화 기록 메시지의 키를 \"history\"로 설정\n",
    "    history_factory_config=config_fields,  # 대화 기록 조회시 참고할 파라미터를 설정합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"configurable\" 키 아래에 \"user_id\", \"conversation_id\" key-value 쌍을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 설정\n",
    "config = {\"configurable\": {\"user_id\": \"user1\", \"conversation_id\": \"conversation1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문에 이름을 물어보는 질문을 해보겠습니다. 이전에 저장한 대화가 있다면, 올바르게 답할 것입니다.\n",
    "\n",
    "* ```chain_with_history``` 객체의 ```invoke``` 메서드를 호출하여 질문에 대한 답변을 생성합니다.\n",
    "* ```invoke``` 메서드에는 질문 딕셔너리와 ```config``` 설정이 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 테디! 반갑습니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문과 config 를 전달하여 실행합니다.\n",
    "chain_with_history.invoke({\"question\": \"안녕 반가워, 내 이름은 테디야\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 테디라고 하셨습니다. 맞나요?'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 후속 질문을 실해합니다.\n",
    "chain_with_history.invoke({\"question\": \"내 이름이 뭐라고?\"}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 같은 user_id 를 가지지만 conversion_id 가 다른 값을 가지도록 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 저에게는 사용자의 이름을 알 수 있는 방법이 없습니다. 그러나 이름이 무엇인지 알려주시면 기억하도록 하겠습니다.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config 설정\n",
    "config = {\"configurable\": {\"user_id\": \"user1\", \"conversation_id\": \"conversation2\"}}\n",
    "\n",
    "# 질문과 config 를 전달하여 실행합니다.\n",
    "chain_with_history.invoke({\"question\": \"내 이름이 뭐라고?\"}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌10. RunnableWithMessageHistory에 ChatMessageHistory 추가\n",
    "\n",
    "### 🐼RunnableWithMessageHistory?\n",
    "사용자의 이전 대화 내용을 기록하고, 현재 체인의 프롬프트에 자동으로 반영하고, 새 대화 내용을 저장하여 다음 대화에서 이어질 수 있도록 하는 구성에 필요한 클래스<br>\n",
    "__대화 내용을 기억하고 반영할 수 있는 체인을 생성할 때 사용하는 것__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# 프롬프트 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 Question-Answering 챗봇입니다. 주어진 질문에 대한 답변을 제공해주세요.\",\n",
    "        ),\n",
    "        # 대화기록용 key 인 chat_history 는 가급적 변경 없이 사용하세요!\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"#Question:\\n{question}\"),  # 사용자 입력을 변수로 사용\n",
    "    ]\n",
    ")\n",
    "\n",
    "# llm 생성\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "# 일반 Chain 생성\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 기록을 저장할 딕셔너리\n",
    "store = {}\n",
    "\n",
    "\n",
    "# 세션 ID를 기반으로 세션 기록을 가져오는 함수, 세션 ID가 store에 존재하지 않을 경우 \n",
    "def get_session_history(session_ids):\n",
    "    print(f\"[대화 세션ID]: {session_ids}\")\n",
    "    if session_ids not in store:  # 세션 ID가 store에 없는 경우 임의로 빈 대화 기록을 만들어서 저장 후 반환하는 것\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐼전체 동작 흐름 요약\n",
    "* 사용자가 ```invoke({\"question\": \"내 이름이 뭐야? \"}, config={\"configurable\": {\"session_id\": \"abc\"}})``` 처럼 호출\n",
    "* ```RunnableWithMessageHistory```가 ```get_session_history(\"abc\")```를 호출해 대화 기록을 가져옴\n",
    "* 과거 대화를 ```chat_history``` 키에 자동으로 붙여서 체인에 넘김\n",
    "* 체인은 ```\"abc\"```라는 세션 아이디를 가진 대화 기록을 바탕으로 응답을 생성\n",
    "* 응답은 다시 히스토리에 저장되고, 다음 질문 생성시에 활용할 수 있게 되는 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain, # 기본 chain 입력 : prompt | llm | StrOutputParser()\n",
    "    get_session_history,  # 세션 ID 를 기반으로 하여 대화 기록을 가져오는 함수 / 해당 세션에 해당되는 내용을 찾아서 chat_history에 넣어주게 된다.\n",
    "    input_messages_key=\"question\",  # 사용자의 질문이 템플릿 변수에 들어갈 key / invoke({\"question\": \"오늘 날씨 어때?\"})\n",
    "    history_messages_key=\"chat_history\",  # 기록 메시지의 키\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 테디! 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"나의 이름은 테디입니다.\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 테디입니다.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"내 이름이 뭐라고?\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[대화 세션ID]: abc1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 당신의 이름을 알 수 없습니다. 개인 데이터를 저장하거나 기억할 수 없는 AI입니다.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # 질문 입력\n",
    "    {\"question\": \"내 이름이 뭐라고?\"},\n",
    "    # 세션 ID 기준으로 대화를 기록합니다.\n",
    "    config={\"configurable\": {\"session_id\": \"abc1234\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
