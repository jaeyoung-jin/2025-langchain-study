{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 01. ConversationBufferMemory\n",
    "ë©”ì‹œì§€ë¥¼ ì €ì¥í•œ í›„ ë©”ì‹œì§€ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë©”ëª¨ë¦¬<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¼ save_context(inputs, outputs) ë©”ì„œë“œ\n",
    "* ```inputs```ì™€ ```outputs``` ì´ ë‘ ê°œì˜ ì¸ìë¥¼ í•„ìš”ë¡œ í•˜ëŠ” ë©”ì„œë“œ\n",
    "* ```inputs``` : ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì €ì¥\n",
    "* ```outputs``` : AIì˜ ì¶œë ¥ì„ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\2227097840.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¼ ```load_memory_variables``` ë¥¼ ì‚¬ìš©í•´ì„œ ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
    "* ëŒ€í™” ê¸°ë¡ì€ ```history``` í‚¤ì— ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\\nAI: ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\\nAI: ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ì€ ì´ì œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë³¸ì¸ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ì‹œëŠ” ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆê¸ˆ ì¢…ë¥˜, í†µí™” ì¢…ë¥˜ ë“±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\n",
      "Human: ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\n",
      "AI: ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
      "Human: ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ì€ ì´ì œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n",
      "AI: ë³¸ì¸ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ì‹œëŠ” ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆê¸ˆ ì¢…ë¥˜, í†µí™” ì¢…ë¥˜ ë“±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_object = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_object.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory_object.save_context(\n",
    "    inputs={\"human\": \"ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "\n",
    "memory_object.save_context(\n",
    "    inputs={\"human\": \"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_object.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = memory_object.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "for i in conversation:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\n",
      "ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\n",
      "ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\n",
      "ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "for i in conversation:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\2956461668.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# LLM ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# ConversationChainì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "conversation = ConversationChain(\n",
    "    # ConversationBufferMemoryë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ë ¤ë©´ ë¨¼ì € í•´ë‹¹ ì€í–‰ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì…”ì•¼ í•©ë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ì€í–‰ì€ ì˜¨ë¼ì¸ìœ¼ë¡œ ê³„ì¢Œë¥¼ ê°œì„¤í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì›¹ì‚¬ì´íŠ¸ì— ë“¤ì–´ê°€ì…”ì„œ ê°œì„¤ ì ˆì°¨ë¥¼ ë”°ë¼ê°€ì‹œë©´ ë©ë‹ˆë‹¤. ê°œì¸ì •ë³´ì™€ ì‹ ë¶„ì¦ ì‚¬ë³¸ ë“±ì„ ì¤€ë¹„í•´ë‘ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤. ë§Œì•½ ë„ì›€ì´ í•„ìš”í•˜ì‹œë‹¤ë©´ ê³ ê°ì„¼í„°ì— ë¬¸ì˜í•˜ì‹œê±°ë‚˜ ì˜¨ë¼ì¸ ìƒë‹´ì„ ì´ìš©í•˜ì‹¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë¶€ë”” í¸ë¦¬í•œ ë¹„ëŒ€ë©´ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "response = conversation.predict(\n",
    "    input=\"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ì´ì£ ! ì œê°€ ì´ì „ ë‹µë³€ì„ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ì •ë¦¬í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
      "1. í•´ë‹¹ ì€í–‰ì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì„¸ìš”.\n",
      "2. ì˜¨ë¼ì¸ìœ¼ë¡œ ê³„ì¢Œë¥¼ ê°œì„¤í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì„¸ìš”.\n",
      "3. ì›¹ì‚¬ì´íŠ¸ì—ì„œ ê°œì„¤ ì ˆì°¨ë¥¼ ë”°ë¼ê°€ì„¸ìš”.\n",
      "4. ê°œì¸ì •ë³´ì™€ ì‹ ë¶„ì¦ ì‚¬ë³¸ ë“±ì„ ì¤€ë¹„í•˜ì„¸ìš”.\n",
      "5. ë„ì›€ì´ í•„ìš”í•˜ë©´ ê³ ê°ì„¼í„°ì— ë¬¸ì˜í•˜ê±°ë‚˜ ì˜¨ë¼ì¸ ìƒë‹´ì„ ì´ìš©í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "# ì´ì „ ëŒ€í™”ë‚´ìš©ì„ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ì •ë¦¬í•´ ë‹¬ë¼ëŠ” ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\n",
    "response = conversation.predict(\n",
    "    input=\"ì´ì „ ë‹µë³€ì„ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ ì •ë¦¬í•˜ì—¬ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 02. ConversationBufferWindowMemory\n",
    "ëª¨ë“  ëŒ€í™” ë‚´ìš©ì„ í™œìš©í•˜ëŠ” ë©”ëª¨ë¦¬ê°€ ì•„ë‹Œ <U>ìµœê·¼ ```Kê°œ```ì˜ ëŒ€í™”ë§Œ í™œìš©í•˜ëŠ” ë©”ëª¨ë¦¬</U>ì´ë‹¤.<br>\n",
    "ë²„í¼ê°€ ë„ˆë¬´ ì»¤ì§€ì§€ ì•Šë„ë¡ ìŠ¬ë¼ì´ë”© ì°½ì„ ìœ ì§€í•˜ëŠ” ë°ì— í™œìš©í•  ìˆ˜ ìˆë‹¤.<br><br>\n",
    "\n",
    "ëª¨ë“  ëŒ€í™”ë¥¼ ì €ì¥í•´ë‘ì§€ ì•Šê³  ìµœì‹  K ê°œì˜ ëŒ€í™”ë§Œ ìœ ì§€í•˜ë¯€ë¡œ, <U>ìµœì‹  ëŒ€í™” ê¸°ë¡ë§Œ í•„ìš”í•œ ìƒí™©</U>ì—ì„œëŠ” ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•  ìˆ˜ ìˆëŠ” ì¢‹ì€ ì„ íƒì§€ì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\2154617891.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ë¹„ëŒ€ë©´ìœ¼ë¡œ ì€í–‰ ê³„ì¢Œë¥¼ ê°œì„¤í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì‹œì‘í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! ê³„ì¢Œ ê°œì„¤ì„ ì›í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤. ë¨¼ì €, ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì‹ ë¶„ì¦ì„ ì¤€ë¹„í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ë„¤, ì‹ ë¶„ì¦ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ê°ì‚¬í•©ë‹ˆë‹¤. ì‹ ë¶„ì¦ ì•ë’¤ë¥¼ ëª…í™•í•˜ê²Œ ì´¬ì˜í•˜ì—¬ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ì´í›„ ë³¸ì¸ ì¸ì¦ ì ˆì°¨ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë³¸ì¸ ì¸ì¦ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì—…ë¡œë“œí•´ ì£¼ì‹  ì‚¬ì§„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì´ì œ íœ´ëŒ€í°ì„ í†µí•œ ë³¸ì¸ ì¸ì¦ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”. ë¬¸ìë¡œ ë°œì†¡ëœ ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì¸ì¦ë²ˆí˜¸ë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ì€ ì´ì œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë³¸ì¸ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì›í•˜ì‹œëŠ” ê³„ì¢Œ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ê³  í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”. ì˜ˆê¸ˆ ì¢…ë¥˜, í†µí™” ì¢…ë¥˜ ë“±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì…ë ¥í•´ ì£¼ì‹  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ ì ˆì°¨ê°€ ê±°ì˜ ëë‚¬ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ìš© ì•½ê´€ì— ë™ì˜í•´ ì£¼ì‹œê³ , ê³„ì¢Œ ê°œì„¤ì„ ìµœì¢… í™•ì¸í•´ ì£¼ì„¸ìš”.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ëª¨ë“  ì ˆì°¨ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œê°€ ê°œì„¤ëœ ê±´ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë„¤, ê³„ì¢Œ ê°œì„¤ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ê³„ì¢Œ ë²ˆí˜¸ì™€ ê´€ë ¨ ì •ë³´ëŠ” ë“±ë¡í•˜ì‹  ì´ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤!\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ë³´ë¥¼ ëª¨ë‘ ì…ë ¥í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "ì…ë ¥í•´ ì£¼ì‹  ì •ë³´ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œ ê°œì„¤ ì ˆì°¨ê°€ ê±°ì˜ ëë‚¬ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì´ìš© ì•½ê´€ì— ë™ì˜í•´ ì£¼ì‹œê³ , ê³„ì¢Œ ê°œì„¤ì„ ìµœì¢… í™•ì¸í•´ ì£¼ì„¸ìš”.\n",
      "ëª¨ë“  ì ˆì°¨ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ê³„ì¢Œê°€ ê°œì„¤ëœ ê±´ê°€ìš”?\n",
      "ë„¤, ê³„ì¢Œ ê°œì„¤ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê³ ê°ë‹˜ì˜ ê³„ì¢Œ ë²ˆí˜¸ì™€ ê´€ë ¨ ì •ë³´ëŠ” ë“±ë¡í•˜ì‹  ì´ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ê°ì‚¬í•©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ëŒ€í™” ê¸°ë¡ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "for i in memory.load_memory_variables({})[\"history\"]:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ03. ConversationTokenBufferMemory\n",
    "ìµœê·¼ ëŒ€í™”ì˜ íˆìŠ¤í† ë¦¬ë¥¼ ë²„í¼ ë©”ëª¨ë¦¬ì— ë³´ê´€í•˜ê³ , ëŒ€í™”ì˜ ê°œìˆ˜ê°€ ì•„ë‹Œ í† í° ê¸¸ì´ë¥¼ ì‚¬ìš©í•´ì„œ ëŒ€í™” ë‚´ìš©ì„ í”ŒëŸ¬ì‹œ(flush) í•  ì‹œê¸°ë¥¼ ê²°ì •í•œë‹¤.<br><br>\n",
    "**ConversationBufferWindowMemory**ëŠ” <U>ëŒ€í™”ì˜ ê°œìˆ˜</U>, **ConversationTokenBufferMemory**ëŠ” <U>í† í°ì˜ ê¸¸ì´</U>ë¥¼ ì„¤ì •í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ì ˆì•½í•˜ëŠ” ê²ƒì´ë‹¤.\n",
    "\n",
    "\n",
    "* Flush : ë©”ëª¨ë¦¬ë¥¼ ë¹„ìš°ê³  ìƒˆë¡œ ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¼ ```max_token_limit``` ì„ ì‚¬ìš©í•´ ì €ì¥í•  ìµœëŒ€ í† í° ê¸¸ì´ë¥¼ ì„¤ì •í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\1343288506.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM ëª¨ë¸ ìƒì„±\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì •\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm, max_token_limit=150, return_messages=True  # ìµœëŒ€ í† í° ê¸¸ì´ë¥¼ 150ê°œë¡œ ì œí•œ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ìµœê·¼ì— ì—¬ëŸ¬ë¶„ íšŒì‚¬ì˜ ê³µì‘ ê¸°ê³„ë¥¼ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤. ì„¤ì¹˜ ë°©ë²•ì„ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”! êµ¬ë§¤í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. í•´ë‹¹ ê¸°ê³„ ëª¨ë¸ ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ë„¤, ëª¨ë¸ ë²ˆí˜¸ëŠ” XG-200ì…ë‹ˆë‹¤.\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ê°ì‚¬í•©ë‹ˆë‹¤. XG-200 ëª¨ë¸ì˜ ì„¤ì¹˜ ì•ˆë‚´ë¥¼ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë¨¼ì €, ì„¤ì¹˜í•  ì¥ì†Œì˜ ì „ì› ê³µê¸‰ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. ê¸°ê³„ëŠ” 220V ì „ì›ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì „ì›ì€ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì¢‹ìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ, ê¸°ê³„ë¥¼ í‰í‰í•˜ê³  ì•ˆì •ëœ ë°”ë‹¥ì— ë°°ì¹˜í•´ ì£¼ì„¸ìš”. ì´í›„, ì œê³µëœ ì‚¬ìš©ì ë§¤ë‰´ì–¼ì— ë”°ë¼ ì¼€ì´ë¸” ì—°ê²°ì„ ì§„í–‰í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì—°ê²°ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë§¤ë‰´ì–¼ì˜ 5í˜ì´ì§€ë¥¼ ì°¸ì¡°í•´ ì£¼ì„¸ìš”. ì¼€ì´ë¸” ì—°ê²°ì— ê´€í•œ ìƒì„¸í•œ ì§€ì¹¨ì´ ìˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ì–´ë ¤ì›€ì´ ìˆìœ¼ì‹œë©´ ì¶”ê°€ì ìœ¼ë¡œ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì„¤ì¹˜ê°€ ì™„ë£Œë˜ë©´, ì „ì›ì„ ì¼œê³  ì´ˆê¸° êµ¬ë™ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì ˆì°¨ëŠ” ë§¤ë‰´ì–¼ì˜ 10í˜ì´ì§€ì— ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ê¸°ê³„ì— ì´ìƒì´ ìˆê±°ë‚˜ ì¶”ê°€ì ì¸ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ì—°ë½ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ê°ì‚¬í•©ë‹ˆë‹¤, ë„ì›€ì´ ë§ì´ ë˜ì—ˆì–´ìš”!\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°ì‚¬í•©ë‹ˆë‹¤, ë„ì›€ì´ ë§ì´ ë˜ì—ˆì–´ìš”!\n",
      "ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "for i in memory.load_memory_variables({})[\"history\"]:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¼ ì‹¤ì œ í† í°ìˆ˜ ê²€ì¦ ê³¼ì •\n",
    "\n",
    "â“ ë‚¨ì•„ìˆëŠ” ë‚´ìš©ì˜ ì´ í† í°ìˆ˜ í•©ì´ 150 ì´í•˜ì—¬ì•¼ í•˜ëŠ”ë° ì™œ 150ì´ ë„˜ì§€??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\2025-langchain-files\\2025-langchain-study\\langchain\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í™” ë‚´ìš©: ê°ì‚¬í•©ë‹ˆë‹¤, ë„ì›€ì´ ë§ì´ ë˜ì—ˆì–´ìš”!\n",
      "í† í° ìˆ˜: 38\n",
      "í† í° ìˆ˜ëŠ” 150 ì´í•˜ì…ë‹ˆë‹¤.\n",
      "ëŒ€í™” ë‚´ìš©: ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ ì¤€ë¹„ê°€ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!\n",
      "í† í° ìˆ˜: 144\n",
      "í† í° ìˆ˜ëŠ” 150 ì´í•˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "ìµœì¢… í† í° ìˆ˜ : 182\n"
     ]
    }
   ],
   "source": [
    "# tiktoken => openai tokenizer\n",
    "from transformers import GPT2Tokenizer # gpt2\n",
    "\n",
    "# GPT2 í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# ëŒ€í™” ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆì‹œ: memory.load_memory_variables()ì—ì„œ historyë¥¼ ê°€ì ¸ì˜´)\n",
    "history = memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "total = 0\n",
    "\n",
    "# ê° ëŒ€í™” ë‚´ìš©ì— ëŒ€í•´ í† í° ìˆ˜ í™•ì¸\n",
    "for i in history:\n",
    "    content = i.content  # ëŒ€í™” ë‚´ìš©\n",
    "\n",
    "    tokens = tokenizer.encode(content)  # í† í°í™”\n",
    "    token_count = len(tokens)  # í† í° ìˆ˜ ê³„ì‚°\n",
    "    print(f\"ëŒ€í™” ë‚´ìš©: {content}\")\n",
    "    print(f\"í† í° ìˆ˜: {token_count}\")\n",
    "\n",
    "    total += token_count\n",
    "    \n",
    "    # í† í° ìˆ˜ê°€ 150ì„ ì´ˆê³¼í•˜ëŠ”ì§€ í™•ì¸\n",
    "    if token_count > 150:\n",
    "        print(\"ê²½ê³ : í† í° ìˆ˜ê°€ 150ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"í† í° ìˆ˜ëŠ” 150 ì´í•˜ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "print()\n",
    "print(f\"ìµœì¢… í† í° ìˆ˜ : {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 04. ConversationEntityMemory\n",
    "íŠ¹ì • ëŒ€í™”ì—ì„œ íŠ¹ì • ì—”í‹°í‹°ì— ëŒ€í•œ ì£¼ì–´ì§„ ì‚¬ì‹¤ì„ ê¸°ì–µí•©ë‹ˆë‹¤.<br>\n",
    "ëŒ€í™” ë‚´ìš©ì´ ì¶”ê°€ë¨ì— ë”°ë¼ íŠ¹ì • ì—”í‹°í‹°ì— ëŒ€í•œ ì§€ì‹ì„ ì¶•ì í•œë‹¤.\n",
    "\n",
    "### ğŸ¼ ì—”í‹°í‹°?\n",
    "íŠ¹ì • ê°ì²´ë‚˜ ê°œë…, ì£¼ì–´ì§„ ë¬¸ì¥ì—ì„œ <U>ì¤‘ìš”í•œ ëŒ€ìƒ</U> ì •ë„ë¡œ ì´í•´í•  ìˆ˜ ìˆìŒ<br>\n",
    "ë°ì´í„°ë² ì´ìŠ¤ì—ì„œì˜ ì—”í‹°í‹°ëŠ” í•™ìƒ ì—”í‹°í‹°(í•™ë²ˆ, ì´ë¦„, ì „ê³µ ë“±ìœ¼ë¡œ êµ¬ì„±), êµìˆ˜ ì—”í‹°í‹°(ì‚¬ë²ˆ, ì „ê³µ, ì´ë¦„ ë“±ìœ¼ë¡œ êµ¬ì„±)ì™€ ê°™ì´ ì‹¤ì œ ì„¸ê³„ì˜ ê°ì²´ì— ëŒ€í•œ ì†ì„±ì„ ëª¨ë¸ë§í•´ì„œ ë‹´ì•„ë‘” ê°œë…ì¸ë°, <br>\n",
    "ë­ì²´ì¸ì—ì„œì˜ ì—”í‹°í‹°ëŠ” ì´ì™€ ìœ ì‚¬í•˜ì§€ë§Œ, ì¡°ê¸ˆ ë” ë‹¨ìˆœí•œ í˜•íƒœë¡œ ìƒê°í•´ë„ ë  ê²ƒ ê°™ë‹¤.<br><br>\n",
    "DB ì—”í‹°í‹° ê°œë…ì€ ê°ì²´ë¥¼ <U>ì •í˜•í™”í•˜ì—¬ ê´€ë¦¬</U>í•˜ë ¤ëŠ” ê²ƒ / ëŒ€í™”í˜• ì‹œìŠ¤í…œì—ì„œì˜ ì—”í‹°í‹°ëŠ” <U>ëŒ€í™” ë‚´ì˜ ì¤‘ìš”í•œ ì •ë³´ë‚˜ ëŒ€ìƒ ë“± ë¹„ì •í˜•ì ì¸ í˜•íƒœë¡œ ê¸°ì–µí•˜ì—¬ ì •ë³´ë¥¼ ì¶•ì </U>í•˜ë ¤ëŠ” ê²ƒ\n",
    "* ì˜ˆì‹œ)\n",
    "    * ```ë‚˜ëŠ” ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•œë‹¤.``` : 'ë‚˜'ì™€ 'ì‚¬ê³¼'ê°€ ì—”í‹°í‹°ë¡œì„œ ì¸ì‹ë  ìˆ˜ ìˆìŒ\n",
    "    <br><br>\n",
    "    \n",
    "    **1. \"ë‚˜\"ë¼ëŠ” ì—”í‹°í‹°ì— ëŒ€í•œ ì •ë³´ ì¶•ì **\n",
    "    * input : ë‚˜ëŠ” ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•œë‹¤.\n",
    "    * output : ì•„ ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•˜ëŠ”êµ¬ë‚˜! í˜¹ì‹œ ë‹¤ë¥¸ ê³¼ì¼ë„ ì¢‹ì•„í•´?\n",
    "\n",
    "    **2. \"ì‚¬ê³¼\"ë¼ëŠ” ì—”í‹°í‹°ì— ëŒ€í•œ ì¶•ì ëœ ì •ë³´ ì‚¬ìš©**\n",
    "    * input : ë‚˜ëŠ” ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•œë‹¤.\n",
    "    * output : ì§€ë‚œë²ˆì— êµ¬ë§¤í•˜ì…¨ë˜ ê·¸ ì‚¬ê³¼ ë§ì”€ì´ì‹ ê°€ìš”? ê·¸ë•Œ ì‚¬ê³¼ ì™¸ì— ë‹¤ë¥¸ ê³¼ì¼ë„ êµ¬ë§¤í•˜ì…¨ë‚˜ìš”?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{entities}\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Last line:\n",
      "Human: {input}\n",
      "You:\n"
     ]
    }
   ],
   "source": [
    "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\3299372264.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationEntityMemory(llm=llm),\n",
      "c:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\2025-langchain-files\\2025-langchain-study\\langchain\\Lib\\site-packages\\pydantic\\main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "# LLM ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# ConversationChain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í…Œë””ì™€ ì…œë¦¬ê°€ í•œ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ë™ë£Œì´ê³ , í…Œë””ëŠ” ê°œë°œìì´ê³  ì…œë¦¬ëŠ” ë””ìì´ë„ˆë¼ëŠ” ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì…¨êµ°ìš”. ê·¸ë“¤ì´ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆë‹¤ëŠ” ê²ƒì€ ë¯¸ë˜ì— ë‘ ì‚¬ëŒì´ í˜‘ë ¥í•˜ì—¬ ìƒˆë¡œìš´ ì‚¬ì—…ì„ ì‹œì‘í•˜ë ¤ëŠ” ì˜ì§€ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ëŠ” ë‘ ì‚¬ëŒì´ ì„œë¡œì˜ ê°•ì ì„ ì‚´ë ¤ í˜‘ë ¥í•˜ì—¬ ì„±ê³µì ì¸ ì‚¬ì—…ì„ ì´ëŒì–´ ë‚˜ê°ˆ ìˆ˜ ìˆëŠ” ì¢‹ì€ ê¸°íšŒê°€ ë  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ë„ì „ì— ëŒ€í•œ ì—´ì •ê³¼ ë…¸ë ¥ì´ ìˆìœ¼ë©´, í…Œë””ì™€ ì…œë¦¬ê°€ í•¨ê»˜í•˜ëŠ” íšŒì‚¬ê°€ ë²ˆì°½í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"í…Œë””ì™€ ì…œë¦¬ëŠ” í•œ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ë™ë£Œì…ë‹ˆë‹¤.\"\n",
    "    \"í…Œë””ëŠ” ê°œë°œìì´ê³  ì…œë¦¬ëŠ” ë””ìì´ë„ˆì…ë‹ˆë‹¤. \"\n",
    "    \"ê·¸ë“¤ì€ìµœê·¼ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ê²ƒì„ ê·¸ë§Œë‘ê³  ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'í…Œë””': 'í…Œë””ëŠ” ê°œë°œìì´ê³ , ì…œë¦¬ì™€ í•¨ê»˜ ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆìŠµë‹ˆë‹¤.',\n",
       " 'ì…œë¦¬': 'ì…œë¦¬ëŠ” í•œ íšŒì‚¬ì—ì„œ ë””ìì´ë„ˆë¡œ ì¼í•˜ê³  ìˆìœ¼ë©°, í…Œë””ì™€ í•¨ê»˜ ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆë‹¤.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í…Œë””ì™€ ì…œë¦¬ê°€ í•œ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ë™ë£Œì´ê³ , í…Œë””ëŠ” ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•˜ê³  ì…œë¦¬ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ì¢‹ì•„í•œë‹¤ëŠ” ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì…¨êµ°ìš”. ë˜í•œ, í…Œë””ëŠ” 30ì‚´ì´ê³  ì…œë¦¬ëŠ” 31ì‚´ì´ë©°, ì…œë¦¬ëŠ” ì‚¬ê³¼ë¥¼ ì‹«ì–´í•˜ê³  ì‚¬ê³¼ ì•ŒëŸ¬ì§€ê°€ ìˆë‹¤ê³  í•˜ì…¨ìŠµë‹ˆë‹¤. ë˜í•œ, í…Œë””ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ë¨¹ê³  ì²´í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì •ë³´ë¥¼ í† ëŒ€ë¡œ, í…Œë””ì™€ ì…œë¦¬ëŠ” ì„œë¡œì˜ ì·¨í–¥ê³¼ ê±´ê°•ì— ëŒ€í•´ ì‹ ê²½ì„ ì“°ë©° í•¨ê»˜ ì¼í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì‚¬ê³¼ ì•ŒëŸ¬ì§€ì™€ ë°”ë‚˜ë‚˜ ì²´í•œ ê²½í—˜ì„ ê³ ë ¤í•˜ì—¬ ì‹ì‚¬ ë° í™œë™ì„ ì¡°ì •í•˜ë©´ì„œ, ë”ìš± ì›í™œí•œ í˜‘ì—…ê³¼ ê±´ê°•í•œ ì¼ìƒì„ ìœ ì§€í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(\n",
    "    input=\"í…Œë””ì™€ ì…œë¦¬ëŠ” í•œ íšŒì‚¬ì—ì„œ ì¼í•˜ëŠ” ë™ë£Œì…ë‹ˆë‹¤.\"\n",
    "    \"í…Œë””ëŠ” ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•˜ê³  ì…œë¦¬ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ì¢‹ì•„í•©ë‹ˆë‹¤.\"\n",
    "    \"í…Œë””ëŠ” 30ì‚´ì´ê³  ì…œë¦¬ëŠ” 31ì‚´ì…ë‹ˆë‹¤. ì…œë¦¬ëŠ” ì‚¬ê³¼ë¥¼ ì‹«ì–´í•©ë‹ˆë‹¤.\"\n",
    "    \"í…Œë””ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ë¨¹ê³  ì²´í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    \"ì…œë¦¬ëŠ” ì‚¬ê³¼ ì•ŒëŸ¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'í…Œë””': 'í…Œë””ëŠ” ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•˜ê³ , ë°”ë‚˜ë‚˜ë¥¼ ë¨¹ê³  ì²´í•œ ê²½í—˜ì´ ìˆìœ¼ë©°, 30ì‚´ì´ë¼ëŠ” ì •ë³´ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.',\n",
       " 'ì…œë¦¬': 'ì…œë¦¬ëŠ” í•œ íšŒì‚¬ì—ì„œ ë””ìì´ë„ˆë¡œ ì¼í•˜ê³  ìˆìœ¼ë©°, í…Œë””ì™€ í•¨ê»˜ ìì‹ ë“¤ì˜ íšŒì‚¬ë¥¼ ì°¨ë¦´ ê³„íšì„ ì„¸ìš°ê³  ìˆë‹¤. ì…œë¦¬ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ì¢‹ì•„í•˜ê³ , ì‚¬ê³¼ë¥¼ ì‹«ì–´í•˜ë©° ì‚¬ê³¼ ì•ŒëŸ¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'í…Œë””ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ë¨¹ê³  ì²´í•œ ê²½í—˜ì´ ìˆìœ¼ë¯€ë¡œ, í˜„ì¬ë¡œì„œëŠ” ë°”ë‚˜ë‚˜ë¥¼ ì¢‹ì•„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê°œì¸ì˜ ì·¨í–¥ì´ë‚˜ ìƒí™©ì— ë”°ë¼ ë³€í•  ìˆ˜ ìˆìœ¼ë‹ˆ, í…Œë””ì—ê²Œ ì§ì ‘ ë¬¼ì–´ë³´ëŠ” ê²ƒì´ ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•ì¼ ê²ƒì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"í…Œë””ëŠ” ë°”ë‚˜ë‚˜ë¥¼ ì¢‹ì•„í• ê¹Œìš”?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì…œë¦¬ëŠ” ì‚¬ê³¼ë¥¼ ì‹«ì–´í•˜ê³  ì‚¬ê³¼ ì•ŒëŸ¬ì§€ê°€ ìˆê¸° ë•Œë¬¸ì— ì‚¬ê³¼ë¥¼ ì¢‹ì•„í•˜ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì…œë¦¬ëŠ” ì‚¬ê³¼ë¥¼ ì„ í˜¸í•˜ì§€ ì•Šì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"ì…œë¦¬ëŠ” ì‚¬ê³¼ë¥¼ ì¢‹ì•„í• ê¹Œìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 05. ConversationKGMemory(Knowledge Graph)\n",
    "ì§€ì‹ ê·¸ë˜í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 06. ConversationSummaryBufferMemory\n",
    "ìµœê·¼ ëŒ€í™” ë‚´ìš©ì˜ ë²„í¼ë¥¼ ë©”ëª¨ë¦¬ì— ìœ ì§€í•˜ë˜, <U>ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì™„ì „íˆ flush í•˜ì§€ ì•Šê³ , ìš”ì•½ìœ¼ë¡œ ì»´íŒŒì¼í•˜ì—¬ ì €ì¥</U>í•œë‹¤.<br>\n",
    "ëŒ€í™” ë‚´ìš© Flushì˜ ê¸°ì¤€ì€ <U>í† í° ìˆ˜</U> ì´ë‹¤.<br><br>\n",
    "ConversationTokenBufferMemory + ì´ì „ ëŒ€í™” ë‚´ìš© ìš”ì•½í•˜ì—¬ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\887257633.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=200,  # ìš”ì•½ì˜ ê¸°ì¤€ì´ ë˜ëŠ” í† í° ê¸¸ì´ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"ìœ ëŸ½ ì—¬í–‰ íŒ¨í‚¤ì§€ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ìœ ëŸ½ 14ë°• 15ì¼ íŒ¨í‚¤ì§€ì˜ ê¸°ë³¸ ê°€ê²©ì€ 3,500ìœ ë¡œì…ë‹ˆë‹¤. ì´ ê°€ê²©ì—ëŠ” í•­ê³µë£Œ, í˜¸í…” ìˆ™ë°•ë¹„, ì§€ì •ëœ ê´€ê´‘ì§€ ì…ì¥ë£Œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¹„ìš©ì€ ì„ íƒí•˜ì‹  ì˜µì…˜ íˆ¬ì–´ë‚˜ ê°œì¸ ê²½ë¹„ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ì§ 200 í† í°ì´ ë„˜ì§€ ì•Šì•„ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ì•ŠëŠ”ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ìœ ëŸ½ ì—¬í–‰ íŒ¨í‚¤ì§€ì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ìœ ëŸ½ 14ë°• 15ì¼ íŒ¨í‚¤ì§€ì˜ ê¸°ë³¸ ê°€ê²©ì€ 3,500ìœ ë¡œì…ë‹ˆë‹¤. ì´ ê°€ê²©ì—ëŠ” í•­ê³µë£Œ, í˜¸í…” ìˆ™ë°•ë¹„, ì§€ì •ëœ ê´€ê´‘ì§€ ì…ì¥ë£Œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¹„ìš©ì€ ì„ íƒí•˜ì‹  ì˜µì…˜ íˆ¬ì–´ë‚˜ ê°œì¸ ê²½ë¹„ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ëŒ€í™”ë‚´ìš© í™•ì¸\n",
    "memory.load_memory_variables({})[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì—¬í–‰ ì¤‘ì— ë°©ë¬¸í•  ì£¼ìš” ê´€ê´‘ì§€ëŠ” ì–´ë””ì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì´ ì—¬í–‰ì—ì„œëŠ” íŒŒë¦¬ì˜ ì—í íƒ‘, ë¡œë§ˆì˜ ì½œë¡œì„¸ì›€, ë² ë¥¼ë¦°ì˜ ë¸Œë€ë´ë¶€ë¥´í¬ ë¬¸, ì·¨ë¦¬íˆì˜ ë¼ì´ë„¤í´ ë“± ìœ ëŸ½ì˜ ìœ ëª…í•œ ê´€ê´‘ì§€ë“¤ì„ ë°©ë¬¸í•©ë‹ˆë‹¤. ê° ë„ì‹œì˜ ëŒ€í‘œì ì¸ ëª…ì†Œë“¤ì„ í¬ê´„ì ìœ¼ë¡œ ê²½í—˜í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì—¬í–‰ì ë³´í—˜ì€ í¬í•¨ë˜ì–´ ìˆë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë„¤, ëª¨ë“  ì—¬í–‰ìì—ê²Œ ê¸°ë³¸ ì—¬í–‰ì ë³´í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë³´í—˜ì€ ì˜ë£Œë¹„ ì§€ì›, ê¸´ê¸‰ ìƒí™© ë°œìƒ ì‹œ ì§€ì› ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë³´í—˜ ë³´ì¥ì„ ì›í•˜ì‹œë©´ ìƒí–¥ ì¡°ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"í•­ê³µí¸ ì¢Œì„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ í´ë˜ìŠ¤ë¡œ ì—…ê·¸ë ˆì´ë“œí•  ìˆ˜ ìˆë‚˜ìš”? ë¹„ìš©ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"í•­ê³µí¸ ì¢Œì„ì„ ë¹„ì¦ˆë‹ˆìŠ¤ í´ë˜ìŠ¤ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì—…ê·¸ë ˆì´ë“œ ë¹„ìš©ì€ ì™•ë³µ ê¸°ì¤€ìœ¼ë¡œ ì•½ 1,200ìœ ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ í´ë˜ìŠ¤ì—ì„œëŠ” ë” ë„“ì€ ì¢Œì„, ìš°ìˆ˜í•œ ê¸°ë‚´ì‹, ê·¸ë¦¬ê³  ì¶”ê°€ ìˆ˜í•˜ë¬¼ í—ˆìš©ëŸ‰ ë“±ì˜ í˜œíƒì„ ì œê³µí•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"íŒ¨í‚¤ì§€ì— í¬í•¨ëœ í˜¸í…”ì˜ ë“±ê¸‰ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì´ íŒ¨í‚¤ì§€ì—ëŠ” 4ì„±ê¸‰ í˜¸í…” ìˆ™ë°•ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° í˜¸í…”ì€ í¸ì•ˆí•¨ê³¼ í¸ì˜ì„±ì„ ì œê³µí•˜ë©°, ì¤‘ì‹¬ì§€ì— ìœ„ì¹˜í•´ ê´€ê´‘ì§€ì™€ì˜ ì ‘ê·¼ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤. ëª¨ë“  í˜¸í…”ì€ ìš°ìˆ˜í•œ ì„œë¹„ìŠ¤ì™€ í¸ì˜ ì‹œì„¤ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks the AI about the price of a European travel package, which includes airfare, hotel accommodations, and attraction entrance fees. The AI lists major tourist attractions included in the trip and confirms basic traveler's insurance is provided. The human inquires about upgrading to business class seats on the flight, and the AI explains that it is possible at an additional cost of approximately 1,200 euros for a round trip. Business class offers benefits like wider seats, better meals, and extra baggage allowance.\n",
      "íŒ¨í‚¤ì§€ì— í¬í•¨ëœ í˜¸í…”ì˜ ë“±ê¸‰ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\n",
      "ì´ íŒ¨í‚¤ì§€ì—ëŠ” 4ì„±ê¸‰ í˜¸í…” ìˆ™ë°•ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° í˜¸í…”ì€ í¸ì•ˆí•¨ê³¼ í¸ì˜ì„±ì„ ì œê³µí•˜ë©°, ì¤‘ì‹¬ì§€ì— ìœ„ì¹˜í•´ ê´€ê´‘ì§€ì™€ì˜ ì ‘ê·¼ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤. ëª¨ë“  í˜¸í…”ì€ ìš°ìˆ˜í•œ ì„œë¹„ìŠ¤ì™€ í¸ì˜ ì‹œì„¤ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ëŒ€í™”ë‚´ìš© í™•ì¸\n",
    "for i in memory.load_memory_variables({})[\"history\"]:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 07. VectorStoreRetrieverMemory\n",
    "ë²¡í„° ìŠ¤í† ì–´ì— ë©”ëª¨ë¦¬ë¥¼ ì €ì¥í•˜ê³  í˜¸ì¶œë  ë•Œë§ˆë‹¤ ê°€ì¥ ëˆˆì— ë„ëŠ” ìƒìœ„ K ê°œì˜ ë¬¸ì„œë¥¼ ì¿¼ë¦¬í•œë‹¤.<br>\n",
    "ëŒ€í™”ì˜ ìˆœì„œë¥¼ ê¸°ì–µí•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, <U>ëŒ€í™” ë‚´ìš© ì¤‘ ê°€ì¥ ì¤‘ìš”í•œ ë¬¸ì„œë“¤ì„ ë½‘ì•„ì„œ ì €ì¥í•˜ê³ , í•„ìš”í•  ë•Œë§ˆë‹¤ ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ì€ K ê°œë¥¼ ì°¾ëŠ” ë°©ì‹</U>ì´ë‹¤. <br><br>\n",
    "ì§€ê¸ˆê¹Œì§€ì˜ Memory Class ë“¤ì€ ëŒ€í™”ë¥¼ ì €ì¥í•  ë•Œ ëŒ€í™”ì˜ ìˆœì„œê°€ ì¤‘ìš”í–ˆìœ¼ë‚˜, ë²¡í„°ìŠ¤í† ì–´ë©”ëª¨ë¦¬ëŠ” ìˆœì„œì— ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ”ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "# Vector Store ë¥¼ ì´ˆê¸°í™” í•©ë‹ˆë‹¤.\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goodusdata\\AppData\\Local\\Temp\\ipykernel_27516\\284692154.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=retriever)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# ë²¡í„° ì¡°íšŒê°€ ì—¬ì „íˆ ì˜ë¯¸ì ìœ¼ë¡œ ê´€ë ¨ì„± ìˆëŠ” ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤.\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
    "\n",
    "# ì„ì˜ì˜ ëŒ€í™”ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì„í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì»´í“¨í„° ê³¼í•™ì„ ì „ê³µí•œ ì‹ ì… ê°œë°œìì…ë‹ˆë‹¤. ëŒ€í•™ì—ì„œëŠ” ì£¼ë¡œ ìë°”ì™€ íŒŒì´ì¬ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ìµœê·¼ì—ëŠ” ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ëŠ” ê²½í—˜ì„ í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\": \"íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ì–´ë ¤ì›€ì„ ê²ªì—ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ ì–´ë–»ê²Œ í•´ê²°í–ˆë‚˜ìš”?\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"í”„ë¡œì íŠ¸ ì´ˆê¸°ì— ì˜ì‚¬ì†Œí†µ ë¬¸ì œë¡œ ëª‡ ê°€ì§€ ì–´ë ¤ì›€ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì €í¬ íŒ€ì€ ì •ê¸°ì ì¸ ë¯¸íŒ…ì„ ê°–ê³  ê°ìì˜ ì§„í–‰ ìƒí™©ì„ ê³µìœ í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¬¸ì œê°€ ë°œìƒí–ˆì„ ë•ŒëŠ” ì ê·¹ì ìœ¼ë¡œ ì˜ê²¬ì„ ë‚˜ëˆ„ê³ , í•©ë¦¬ì ì¸ í•´ê²°ì±…ì„ ì°¾ê¸° ìœ„í•´ ë…¸ë ¥í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ê°œë°œìë¡œì„œ ìì‹ ì˜ ê°•ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì œ ê°•ì ì€ ë¹ ë¥¸ í•™ìŠµ ëŠ¥ë ¥ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ë„êµ¬ë¥¼ ë¹ ë¥´ê²Œ ìŠµë“í•  ìˆ˜ ìˆìœ¼ë©°, ë³µì¡í•œ ë¬¸ì œì— ì§ë©´í–ˆì„ ë•Œ ì°½ì˜ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ë©° ë™ë£Œë“¤ê³¼ í˜‘ë ¥í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "promptë¥¼ ì‘ì„±í•˜ì—¬ ë©´ì ‘ìì˜ ì „ê³µì´ ë¬´ì—‡ì¸ì§€ ë¬¼ì–´ë³´ë©´, Vector Storeë¡œë¶€í„° 1ê°œ(kê°œ)ì˜ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ëŒ€í™” ë‚´ìš©ì´ ë°˜í™˜ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì„í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
      "ai: ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” ì»´í“¨í„° ê³¼í•™ì„ ì „ê³µí•œ ì‹ ì… ê°œë°œìì…ë‹ˆë‹¤. ëŒ€í•™ì—ì„œëŠ” ì£¼ë¡œ ìë°”ì™€ íŒŒì´ì¬ì„ ì‚¬ìš©í–ˆìœ¼ë©°, ìµœê·¼ì—ëŠ” ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì— ì°¸ì—¬í•˜ì—¬ ì‹¤ì œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ëŠ” ê²½í—˜ì„ í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë©”ëª¨ë¦¬ì— ì§ˆë¬¸ì„ í†µí•´ ê°€ì¥ ì—°ê´€ì„± ë†’ì€ 1ê°œ ëŒ€í™”ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "print(memory.load_memory_variables({\"prompt\": \"ë©´ì ‘ì ì „ê³µì€ ë¬´ì—‡ì¸ê°€ìš”?\"})[\"history\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: í”„ë¡œì íŠ¸ì—ì„œ ì–´ë–¤ ì—­í• ì„ ë§¡ì•˜ë‚˜ìš”?\n",
      "ai: ì œê°€ ë§¡ì€ ì—­í• ì€ ë°±ì—”ë“œ ê°œë°œìì˜€ìŠµë‹ˆë‹¤. ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ì™€ ì„œë²„ ë¡œì§ ê°œë°œì„ ë‹´ë‹¹í–ˆìœ¼ë©°, RESTful APIë¥¼ êµ¬í˜„í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ì—ë„ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    memory.load_memory_variables(\n",
    "        {\"human\": \"ë©´ì ‘ìê°€ í”„ë¡œì íŠ¸ì—ì„œ ë§¡ì€ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?\"}\n",
    "    )[\"history\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 08. LCEL Chainì— ë©”ëª¨ë¦¬ ì¶”ê°€\n",
    "* LCEL(LangChain Expression Language) : ì²´ì¸ì„ ê°„ë‹¨í•œ íŒŒì´í”„ë¼ì¸ ë°©ì‹ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°©ì‹\n",
    "* ì²´ì¸ì˜ êµ¬ì„± ìš”ì†Œë“¤ì„ ì§ê´€ì ìœ¼ë¡œ ì—°ê²°í•  ìˆ˜ ìˆëŠ” ë°©ì‹ì´ë‹¤.\n",
    "\n",
    "### ğŸ¼Chain ì •ì˜ì˜ í•„ìš”ì„±?\n",
    "í•µì‹¬ : ì‘ì—… íë¦„ì„ ëª…í™•íˆ êµ¬ì¡°í™”í•˜ê³ , ê´€ë¦¬ë¥¼ ì‰½ê²Œ í•˜ì—¬ ì¬ì‚¬ìš©ì„±ì„ ë†’ì´ê¸° ìœ„í•¨<br>\n",
    "\n",
    "<br>\n",
    "LLMì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê³¼ì •<br>\n",
    "1. ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì „ì²˜ë¦¬<br>\n",
    "2. í”„ë¡¬í”„íŠ¸ì— í…œí”Œë¦¿ì„ ì „ë‹¬<br>\n",
    "3. LLMì— ì „ë‹¬<br>\n",
    "4. ê²°ê³¼ í›„ì²˜ë¦¬ ë° í¬ë§·íŒ…<br>\n",
    "ë“±ë“±<br><br>\n",
    "\n",
    "ìœ„ ê³¼ì •ì„ í•˜ë‚˜ì˜ chainìœ¼ë¡œ ë¬¶ì–´ ê´€ë¦¬í•˜ë©´ ë” í¸ë¦¬í•´ì§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# ChatPromptTemplate.from_messages -> LLMì— ì „ë‹¬í•  ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•˜ëŠ” ë„êµ¬\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"), # ì—­í•  ì§€ì •\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"), # chat history : ì´ì „ ëŒ€í™” ë‚´ìš© -> MessagesPlaceholderëŠ” message ê°ì²´ë¥¼ ë°›ìŒ\n",
    "        (\"human\", \"{input}\"), # ì‚¬ìš©ìì˜ ì§ˆë¬¸\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•  ConversationBufferMemoryë¥¼ ìƒì„±<br>\n",
    "```return_messages``` ë§¤ê°œë³€ìˆ˜ë¥¼ ```True```ë¡œ ì„¤ì •í•˜ë©´, ë‹¨ìˆœ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ë©”ì‹œì§€ ê°ì²´ë¥¼ ë°˜í™˜í•œë‹¤.<br>\n",
    "* ```ChatPromptTemplate.from_messages()``` ì—ì„œëŠ” ```MessagesPlaceholder```ë¡œ ë©”ì‹œì§€ ê°ì²´ë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì— ì´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„  ë°˜ë“œì‹œ ê°ì²´ë¡œ ë°˜í™˜ì´ í•„ìš”í•˜ë‹¤.\n",
    "* ```MessagesPlaceholder```ëŠ” ì´ì „ ëŒ€í™” ë§¥ë½ê³¼ ì—°ê´€ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ë„ë¡ í•˜ê¸° ìœ„í•´ì„  ```True```ë¡œ ì£¼ëŠ” ê²ƒì´ í•„ìˆ˜ì \n",
    "* ì‚¬ëŒê³¼ AI ë°œí™”ë¥¼ êµ¬ì¡°í™”ëœ(ì—­í• ì´ êµ¬ë¶„ëœ ì±„ë¡œ) í˜•íƒœë¡œ ë°˜í™˜ë°›ì„ ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "```return_messages``` ë§¤ê°œë³€ìˆ˜ë¥¼ ```False```ë¡œ ì„¤ì •í•˜ë©´, ë‹¨ìˆœíˆ ë¬¸ìì—´ì„ ì´ì–´ ë¶™ì¸ í˜•íƒœë¡œ ë°˜í™˜í•œë‹¤.<br>\n",
    "* ë‹¨ìˆœ ë¬¸ìì—´ì´ê¸° ë•Œë¬¸ì— ì¶œë ¥ ë‚´ìš© í™•ì¸ ë° ë””ë²„ê¹… ì‹œ í¸ë¦¬í•  ìˆ˜ ìˆìŒ\n",
    "* ë°˜í™˜ëœ ë©”ì‹œì§€ë¥¼ í›„ì²˜ë¦¬í•˜ê±°ë‚˜ ì¶”ê°€ ì‘ì—…ì˜ inputìœ¼ë¡œ ì‚¬ìš©í•  ë•Œ í¸ë¦¬í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return_messages = True\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})  # ë©”ëª¨ë¦¬ ë³€ìˆ˜ë¥¼ ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¡œ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Runnable ?\n",
    "Langchainì—ì„œ ì‹¤í–‰í•˜ëŠ” ì‘ì—…ì˜ ë‹¨ìœ„<br>\n",
    "LLM ì²´ì¸ì„ ììœ ë¡­ê²Œ ì—°ê²°í•˜ë©° êµ¬ì„±í•˜ê¸° ìœ„í•´ì„  ë°˜ë“œì‹œ í•„ìš”í•œ ìµœì†Œ ë‹¨ìœ„ì´ë‹¤.<br>\n",
    "```ì…ë ¥``` â†’ ```í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°``` â†’ ```LLM ì‹¤í–‰``` â†’ ```ê²°ê³¼ í¬ë§·``` â†’ ```ì¶œë ¥``` ê³¼ì •ì„ ì²´ì¸ìœ¼ë¡œ ìƒì„±í•  ë•Œ, ê° ì‘ì—…ì„ Runnableë¡œ ë§Œë“¤ì–´ì„œ ì´ì–´ì¤˜ì•¼ í•œë‹¤. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "print(double(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "double = RunnableLambda(lambda x: x * 2) # inputì— 2ë¥¼ ê³±í•˜ì—¬ ê²°ê³¼ë¥¼ ë§Œë“œëŠ” ì¼ë ¨ì˜ ê³¼ì •ì„ RunnableLambda ê°ì²´ë¡œ ë§Œë“¤ì–´ì„œ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.\n",
    "print(double.invoke(3))  # ì¶œë ¥: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“‹ ì£¼ìš” `Runnable` í´ë˜ìŠ¤ ì¢…ë¥˜\n",
    "\n",
    "| ì´ë¦„                  | ì„¤ëª…                                                                 | ì˜ˆì‹œ                                                                 |\n",
    "|---------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|\n",
    "| `RunnableLambda`     | Python í•¨ìˆ˜ë‚˜ ëŒë‹¤ í•¨ìˆ˜ë¥¼ ê°ì‹¸ì„œ `Runnable`ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.   | `RunnableLambda(lambda x: x * 2)` â†’ `invoke(3)` ê²°ê³¼: `6`             |\n",
    "| `RunnablePassthrough`| ì…ë ¥ê°’ì„ ì•„ë¬´ ì²˜ë¦¬ ì—†ì´ ê·¸ëŒ€ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤. ì²´ì¸ì˜ ê¸°ë³¸ ì‹œì‘ì ì´ë‚˜ í…ŒìŠ¤íŠ¸ì— ìœ ìš©í•©ë‹ˆë‹¤. | `RunnablePassthrough().invoke(\"hello\")` â†’ `\"hello\"`                  |\n",
    "| `RunnableMap`        | ì—¬ëŸ¬ `Runnable`ì„ ë³‘ë ¬ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ë¬¶ì–´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤. ë™ì‹œì— ì—¬ëŸ¬ ì‘ì—…ì„ í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. | `RunnableMap({ \"a\": a_fn, \"b\": b_fn }).invoke(x)`                     |\n",
    "| `RunnableSequence`   | ì—¬ëŸ¬ `Runnable`ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•´ì„œ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“­ë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ì´ ë©ë‹ˆë‹¤. | `RunnableSequence([step1, step2, step3])`                             |\n",
    "| `RunnableBinding`    | íŠ¹ì • ë§¤ê°œë³€ìˆ˜ë¥¼ ê³ ì •ì‹œì¼œ ìƒˆë¡œìš´ Runnableì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì²´ì¸ì„ ë§Œë“¤ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤. | `chain.with_config(config)` ì²˜ëŸ¼ ì‚¬ìš©                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables)\n",
    "    | itemgetter(\"chat_history\")  # memory_key ì™€ ë™ì¼í•˜ê²Œ ì…ë ¥\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'chat_history': []}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'chat_history': []}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”, í…Œë””ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "# chain ê°ì²´ì˜ invoke ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "response = chain.invoke({\"input\": \"ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.\"})\n",
    "print(response.content)  # ìƒì„±ëœ ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory.save_context í•¨ìˆ˜ëŠ” ì…ë ¥ ë°ì´í„°(inputs)ì™€ ì‘ë‹µ ë‚´ìš©(response.content)ì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” ì—­í• ì´ë‹¤. <br>\n",
    "ì´ëŠ” AI ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì—ì„œ í˜„ì¬ ìƒíƒœë¥¼ ê¸°ë¡í•˜ê±°ë‚˜, ì‚¬ìš©ìì˜ ìš”ì²­ê³¼ ì‹œìŠ¤í…œì˜ ì‘ë‹µì„ ì¶”ì í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, í…Œë””ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì…ë ¥ëœ ë°ì´í„°ì™€ ì‘ë‹µ ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "memory.save_context(\n",
    "    {\"human\": \"ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.\"}, {\"ai\": response.content}\n",
    ")\n",
    "\n",
    "# ì €ì¥ëœ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, í…Œë””ë‹˜ì˜ ì´ë¦„ì„ ê¸°ì–µí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¦„ì„ ê¸°ì–µí•˜ê³  ìˆëŠ”ì§€ ì¶”ê°€ ì§ˆì˜í•©ë‹ˆë‹¤.\n",
    "response = chain.invoke({\"input\": \"ì œ ì´ë¦„ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ê¸°ì–µí•˜ì„¸ìš”?\"})\n",
    "# ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 09. SQLitesì— ëŒ€í™”ë‚´ìš© ì €ì¥í•˜ê¸°\n",
    "```SQLChatMessageHistory``` í´ë˜ìŠ¤ë¥¼ í™œìš©í•˜ë©´ SQLì„ ì§€ì›í•˜ëŠ” ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ì— ì±„íŒ… ê¸°ë¡ ì €ì¥ì´ ê°€ëŠ¥í•˜ë‹¤.<br>\n",
    "* ```session_id``` : ê³ ìœ í•œ ì•„ì´ë””(ì €ì¥ì†Œì— ì´ë¦„ ë¶™ì´ê¸°)\n",
    "* ```connection``` : ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì§€ì •í•˜ëŠ” ê²ƒìœ¼ë¡œ, create_engine í•¨ìˆ˜ì— ì „ë‹¬ë˜ì–´ sql ì—”ì§„ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "# SQLChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ê³  ì„¸ì…˜ IDì™€ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° íŒŒì¼ì„ ì„¤ì •\n",
    "chat_message_history = SQLChatMessageHistory(\n",
    "    session_id=\"sql_history\", connection=\"sqlite:///sqlite.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "chat_message_history.add_user_message(\n",
    "    \"ì•ˆë…•? ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ë‚´ ì´ë¦„ì€ í…Œë””ì•¼. ë‚˜ëŠ” ë­ì²´ì¸ ê°œë°œìì•¼. ì•ìœ¼ë¡œ ì˜ ë¶€íƒí•´!\"\n",
    ")\n",
    "# AI ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "chat_message_history.add_ai_message(\"ì•ˆë…• í…Œë””, ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ë‚˜ë„ ì˜ ë¶€íƒí•´!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ì•ˆë…•? ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ë‚´ ì´ë¦„ì€ í…Œë””ì•¼. ë‚˜ëŠ” ë­ì²´ì¸ ê°œë°œìì•¼. ì•ìœ¼ë¡œ ì˜ ë¶€íƒí•´!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì•ˆë…• í…Œë””, ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ë‚˜ë„ ì˜ ë¶€íƒí•´!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì±„íŒ… ë©”ì‹œì§€ ê¸°ë¡ì˜ ë©”ì‹œì§€ë“¤\n",
    "chat_message_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain ì ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # ì‹œìŠ¤í…œ ë©”ì‹œì§€\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        # ëŒ€í™” ê¸°ë¡ì„ ìœ„í•œ Placeholder\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),  # ì§ˆë¬¸\n",
    "    ]\n",
    ")\n",
    "\n",
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = prompt | ChatOpenAI(model_name=\"gpt-4o\") | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqlite.db ì—ì„œ ëŒ€í™” ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_history(user_id, conversation_id):\n",
    "    return SQLChatMessageHistory(\n",
    "        table_name=user_id,\n",
    "        session_id=conversation_id,\n",
    "        connection=\"sqlite:///sqlite.db\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¼ ConfigurableFieldSpec\n",
    "Langchainì—ì„œ ì²´ì¸ì´ë‚˜ ì»´í¬ë„ŒíŠ¸ê°€ ì™¸ë¶€ í™˜ê²½ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •ê°’ì„ ë°›ì„ ìˆ˜ ìˆê²Œ í•˜ëŠ” í•„ë“œ ìŠ¤í™ì„ ì •ì˜í•˜ëŠ” ê°ì²´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.utils import ConfigurableFieldSpec\n",
    "\n",
    "config_fields = [\n",
    "    ConfigurableFieldSpec(\n",
    "        id=\"user_id\", # ê³ ìœ  ID\n",
    "        annotation=str, # í•„ë“œì˜ ë°ì´í„° íƒ€ì… ì •ì˜\n",
    "        name=\"User ID\", # ì‹¤ì œ ì‚¬ëŒì´ ì½ì„ ì´ë¦„\n",
    "        description=\"Unique identifier for a user.\",\n",
    "        default=\"\", # í•„ë“œ ê¸°ë³¸ê°’\n",
    "        is_shared=True, # ì—¬ëŸ¬ ê°œì˜ ì²´ì¸ì´ë‚˜ ì»´í¬ë„ŒíŠ¸ê°€ ê³µìœ í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€\n",
    "    ),\n",
    "    ConfigurableFieldSpec(\n",
    "        id=\"conversation_id\",\n",
    "        annotation=str,\n",
    "        name=\"Conversation ID\",\n",
    "        description=\"Unique identifier for a conversation.\",\n",
    "        default=\"\",\n",
    "        is_shared=True,\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,  # ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    input_messages_key=\"question\",  # ì…ë ¥ ë©”ì‹œì§€ì˜ í‚¤ë¥¼ \"question\"ìœ¼ë¡œ ì„¤ì •\n",
    "    history_messages_key=\"chat_history\",  # ëŒ€í™” ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤ë¥¼ \"history\"ë¡œ ì„¤ì •\n",
    "    history_factory_config=config_fields,  # ëŒ€í™” ê¸°ë¡ ì¡°íšŒì‹œ ì°¸ê³ í•  íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"configurable\" í‚¤ ì•„ë˜ì— \"user_id\", \"conversation_id\" key-value ìŒì„ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config ì„¤ì •\n",
    "config = {\"configurable\": {\"user_id\": \"user1\", \"conversation_id\": \"conversation1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì§ˆë¬¸ì— ì´ë¦„ì„ ë¬¼ì–´ë³´ëŠ” ì§ˆë¬¸ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ì „ì— ì €ì¥í•œ ëŒ€í™”ê°€ ìˆë‹¤ë©´, ì˜¬ë°”ë¥´ê²Œ ë‹µí•  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "* ```chain_with_history``` ê°ì²´ì˜ ```invoke``` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "* ```invoke``` ë©”ì„œë“œì—ëŠ” ì§ˆë¬¸ ë”•ì…”ë„ˆë¦¬ì™€ ```config``` ì„¤ì •ì´ ì „ë‹¬ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”, í…Œë””! ë°˜ê°‘ìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì§ˆë¬¸ê³¼ config ë¥¼ ì „ë‹¬í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "chain_with_history.invoke({\"question\": \"ì•ˆë…• ë°˜ê°€ì›Œ, ë‚´ ì´ë¦„ì€ í…Œë””ì•¼\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹¹ì‹ ì˜ ì´ë¦„ì€ í…Œë””ë¼ê³  í•˜ì…¨ìŠµë‹ˆë‹¤. ë§ë‚˜ìš”?'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í›„ì† ì§ˆë¬¸ì„ ì‹¤í•´í•©ë‹ˆë‹¤.\n",
    "chain_with_history.invoke({\"question\": \"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\"}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” ê°™ì€ user_id ë¥¼ ê°€ì§€ì§€ë§Œ conversion_id ê°€ ë‹¤ë¥¸ ê°’ì„ ê°€ì§€ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì£„ì†¡í•˜ì§€ë§Œ, ì €ì—ê²ŒëŠ” ì‚¬ìš©ìì˜ ì´ë¦„ì„ ì•Œ ìˆ˜ ìˆëŠ” ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¦„ì´ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config ì„¤ì •\n",
    "config = {\"configurable\": {\"user_id\": \"user1\", \"conversation_id\": \"conversation2\"}}\n",
    "\n",
    "# ì§ˆë¬¸ê³¼ config ë¥¼ ì „ë‹¬í•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "chain_with_history.invoke({\"question\": \"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\"}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ10. RunnableWithMessageHistoryì— ChatMessageHistory ì¶”ê°€\n",
    "\n",
    "### ğŸ¼RunnableWithMessageHistory?\n",
    "ì‚¬ìš©ìì˜ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ê¸°ë¡í•˜ê³ , í˜„ì¬ ì²´ì¸ì˜ í”„ë¡¬í”„íŠ¸ì— ìë™ìœ¼ë¡œ ë°˜ì˜í•˜ê³ , ìƒˆ ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•˜ì—¬ ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì´ì–´ì§ˆ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” êµ¬ì„±ì— í•„ìš”í•œ í´ë˜ìŠ¤<br>\n",
    "__ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ë°˜ì˜í•  ìˆ˜ ìˆëŠ” ì²´ì¸ì„ ìƒì„±í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê²ƒ__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ Question-Answering ì±—ë´‡ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\",\n",
    "        ),\n",
    "        # ëŒ€í™”ê¸°ë¡ìš© key ì¸ chat_history ëŠ” ê°€ê¸‰ì  ë³€ê²½ ì—†ì´ ì‚¬ìš©í•˜ì„¸ìš”!\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"#Question:\\n{question}\"),  # ì‚¬ìš©ì ì…ë ¥ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©\n",
    "    ]\n",
    ")\n",
    "\n",
    "# llm ìƒì„±\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "\n",
    "# ì¼ë°˜ Chain ìƒì„±\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "store = {}\n",
    "\n",
    "\n",
    "# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜, ì„¸ì…˜ IDê°€ storeì— ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° \n",
    "def get_session_history(session_ids):\n",
    "    print(f\"[ëŒ€í™” ì„¸ì…˜ID]: {session_ids}\")\n",
    "    if session_ids not in store:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš° ì„ì˜ë¡œ ë¹ˆ ëŒ€í™” ê¸°ë¡ì„ ë§Œë“¤ì–´ì„œ ì €ì¥ í›„ ë°˜í™˜í•˜ëŠ” ê²ƒ\n",
    "        # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¼ì „ì²´ ë™ì‘ íë¦„ ìš”ì•½\n",
    "* ì‚¬ìš©ìê°€ ```invoke({\"question\": \"ë‚´ ì´ë¦„ì´ ë­ì•¼? \"}, config={\"configurable\": {\"session_id\": \"abc\"}})``` ì²˜ëŸ¼ í˜¸ì¶œ\n",
    "* ```RunnableWithMessageHistory```ê°€ ```get_session_history(\"abc\")```ë¥¼ í˜¸ì¶œí•´ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜´\n",
    "* ê³¼ê±° ëŒ€í™”ë¥¼ ```chat_history``` í‚¤ì— ìë™ìœ¼ë¡œ ë¶™ì—¬ì„œ ì²´ì¸ì— ë„˜ê¹€\n",
    "* ì²´ì¸ì€ ```\"abc\"```ë¼ëŠ” ì„¸ì…˜ ì•„ì´ë””ë¥¼ ê°€ì§„ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±\n",
    "* ì‘ë‹µì€ ë‹¤ì‹œ íˆìŠ¤í† ë¦¬ì— ì €ì¥ë˜ê³ , ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±ì‹œì— í™œìš©í•  ìˆ˜ ìˆê²Œ ë˜ëŠ” êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain, # ê¸°ë³¸ chain ì…ë ¥ : prompt | llm | StrOutputParser()\n",
    "    get_session_history,  # ì„¸ì…˜ ID ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ / í•´ë‹¹ ì„¸ì…˜ì— í•´ë‹¹ë˜ëŠ” ë‚´ìš©ì„ ì°¾ì•„ì„œ chat_historyì— ë„£ì–´ì£¼ê²Œ ëœë‹¤.\n",
    "    input_messages_key=\"question\",  # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í…œí”Œë¦¿ ë³€ìˆ˜ì— ë“¤ì–´ê°ˆ key / invoke({\"question\": \"ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?\"})\n",
    "    history_messages_key=\"chat_history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ëŒ€í™” ì„¸ì…˜ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”, í…Œë””! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # ì§ˆë¬¸ ì…ë ¥\n",
    "    {\"question\": \"ë‚˜ì˜ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.\"},\n",
    "    # ì„¸ì…˜ ID ê¸°ì¤€ìœ¼ë¡œ ëŒ€í™”ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ëŒ€í™” ì„¸ì…˜ID]: abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ë‹¹ì‹ ì˜ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # ì§ˆë¬¸ ì…ë ¥\n",
    "    {\"question\": \"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\"},\n",
    "    # ì„¸ì…˜ ID ê¸°ì¤€ìœ¼ë¡œ ëŒ€í™”ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ëŒ€í™” ì„¸ì…˜ID]: abc1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì£„ì†¡í•˜ì§€ë§Œ, ë‹¹ì‹ ì˜ ì´ë¦„ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œì¸ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê±°ë‚˜ ê¸°ì–µí•  ìˆ˜ ì—†ëŠ” AIì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_history.invoke(\n",
    "    # ì§ˆë¬¸ ì…ë ¥\n",
    "    {\"question\": \"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\"},\n",
    "    # ì„¸ì…˜ ID ê¸°ì¤€ìœ¼ë¡œ ëŒ€í™”ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "    config={\"configurable\": {\"session_id\": \"abc1234\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
