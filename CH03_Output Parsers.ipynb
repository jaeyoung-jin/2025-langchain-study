{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡출력 파서 (Output Parser)\n",
    "* LLM의 출력을 구조화하는 컴포넌트\n",
    "* 출력을 원하는 형식으로 변환하여 보기 쉽게 만들거나, 구조화된 데이터 생성이 필요한 경우 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 📌01. Pydantic Output Parser\n",
    "\n",
    "Pydantic Output Parser 사용을 위해서는 두 가지 메서드가 필요하다.(대부분의 OutputParser가 필요로 함)\n",
    "\n",
    "1. ```get_format_instructions()```\n",
    "* 언어 모델이 출력해야 할 결과물의 형식을 정의해주는 지침을 반환하는 메서드\n",
    "* 만약, JSON 형식을 준수하는 결과를 출력해야 하는 경우라면, JSON 형식에 맞게 결과물을 구조화할 수 있도록 지시하는 내용이 반환된다.\n",
    "\n",
    "2. ```parse()```\n",
    "* 언어 모델의 출력을 받아들여 이를 parser의 타입에 맞게 변환하는 역할을 수행하는 메서드\n",
    "* 사전에 정의된 스키마를 반영하여 parser를 생성한 후, parse() 메서드를 통해 형식을 변환하여 원하는 데이터 형식으로 구조화할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from pprint import *\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_conversation = \"\"\" \n",
    "안녕하세요 과장님 \n",
    "오늘 너무 바빠서 전화를 드리기 어려웠습니다.\n",
    "일단 주신 파일을 보는데 차이점이 주요하게는 BASIC과 EXCLUSIVE가 주요 포인트인 것 같아요 \n",
    "HCX와 HCX-DASH는 민간 공공 모두에 약간의 입력토큰 차이만 있으니까요\n",
    "\n",
    "그럼 추가적으로 궁금한 것이 BASIC과 EXCLUSIVE에서의 보안 부분에서는 어떤 차이가 있을까요?\n",
    "BASIC으로 활용하면 보안성이 떨어지는 기술이 적용되거나 그런 것이 아닌지요?\n",
    "\n",
    "그리고 BASIC을 활용하는 것에 대한 사례, EXCLUSIVE를 활용하는 사례는 어떤 것이 있는지 대략적으로라도 알고 싶습니다.\n",
    "(제 개인적인 생각에는 요약서비스는 개인정보가 저장 여부도 중요한 것 같은데...\n",
    "다채움에서는  과제 요약서비스로 네이버 클라우드를 활용 시에는 개인정보를 활용하지도 않고, 요약한 정보가 휘발될 것 같은데 이러한 사례에서도 공공존을 활용하는 것이 맞는지 기술적인 검토나 제안 등을 해주시면 감사하겠습니다. \n",
    "경북교육청은 어떤 서비스를 활용하고 있는지 저희가 참고할 수 있으면 더욱 좋을 것 같습니다. )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 과장님,\n",
      "\n",
      "이메일의 중요한 내용은 다음과 같습니다:\n",
      "\n",
      "1. BASIC과 EXCLUSIVE의 주요 차이점에 대한 문의:\n",
      "   - 보안 부분에서의 차이점\n",
      "   - BASIC을 활용할 경우 보안성이 떨어지는 기술이 적용되는지 여부\n",
      "\n",
      "2. BASIC과 EXCLUSIVE 활용 사례에 대한 문의:\n",
      "   - BASIC과 EXCLUSIVE 각각의 활용 사례\n",
      "   - 개인정보 저장 여부와 관련된 요약 서비스의 사례\n",
      "\n",
      "3. 기술적 검토 및 제안 요청:\n",
      "   - 네이버 클라우드를 활용한 과제 요약 서비스에서의 개인정보 활용 여부\n",
      "   - 공공존 활용의 적절성에 대한 기술적 검토 및 제안\n",
      "\n",
      "4. 경북교육청의 서비스 활용 사례에 대한 참고 요청"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"다음의 이메일 내용중 중요한 내용을 추출해 주세요.\\n\\n{email_conversation}\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "answer = chain.stream({\"email_conversation\": email_conversation})\n",
    "\n",
    "# 우리가 평소에 일반적인 방법으로 LLM을 사용할 때 받게되는 응답의 형식으로 나타남\n",
    "output = stream_response(answer, return_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과물은, 우리가 일반적으로 LLM에(ChatGPT 등) 메일 요약을 요청한 경우 받을 수 있는 응답 형태이다.<br>\n",
    "하지만, 요청할 때마다 응답의 형태(형식)가 달라질 가능성이 높기 때문에, 애플리케이션 데이터로 활용하기엔 어려움이 있다.\n",
    "\n",
    "Pydantic을 사용하여 파싱하게 되면, LLM의 응답을 미리 정의해둔 구조대로 일관되게(Json 형식으로) 받을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailSummary(BaseModel):\n",
    "    person: str = Field(description=\"메일을 보낸 사람\", default=\"보낸이 미상\")\n",
    "    email: str = Field(description=\"메일을 보낸 사람의 이메일 주소\", default=\"알 수 없음\")\n",
    "    subject: str = Field(description=\"메일 제목\", default=\"알 수 없음\")\n",
    "    summary: str = Field(description=\"메일 본문을 요약한 텍스트\")\n",
    "    date: str = Field(description=\"메일 본문에 언급된 due date\", default=\"기한 없음\")\n",
    "\n",
    "\n",
    "# PydanticOutputParser 생성\n",
    "parser = PydanticOutputParser(pydantic_object=EmailSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"person\": {\"default\": \"보낸이 미상\", \"description\": \"메일을 보낸 사람\", \"title\": \"Person\", \"type\": \"string\"}, \"email\": {\"default\": \"알 수 없음\", \"description\": \"메일을 보낸 사람의 이메일 주소\", \"title\": \"Email\", \"type\": \"string\"}, \"subject\": {\"default\": \"알 수 없음\", \"description\": \"메일 제목\", \"title\": \"Subject\", \"type\": \"string\"}, \"summary\": {\"description\": \"메일 본문을 요약한 텍스트\", \"title\": \"Summary\", \"type\": \"string\"}, \"date\": {\"default\": \"기한 없음\", \"description\": \"메일 본문에 언급된 due date\", \"title\": \"Date\", \"type\": \"string\"}}, \"required\": [\"summary\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# instruction 을 출력\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌부분변수(partial_variables)\n",
    "고정된 값(변경되지 않는 값)을 미리 설정하는 기능<br>\n",
    "사용자가 입력할 때마다 변경되는 input_variables와 구분하여 템플릿을 설정한다.<br>\n",
    "\n",
    "만약, partial_variables를 사용하지 않는다면, format_instructions 역시 input_variables에 포함되어야 하며,<br>\n",
    "이 경우 프롬프트를 실행할 때마다 format_instructions 값을 매번 직접 넣어주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "EMAIL CONVERSATION:\n",
    "{email_conversation}\n",
    "\n",
    "FORMAT:\n",
    "{format}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# format 에 PydanticOutputParser의 부분 포맷팅(partial) 추가\n",
    "prompt = prompt.partial(format=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"person\": {\"default\": \"보낸이 미상\", \"description\": \"메일을 보낸 사람\", \"title\": \"Person\", \"type\": \"string\"}, \"email\": {\"default\": \"알 수 없음\", \"description\": \"메일을 보낸 사람의 이메일 주소\", \"title\": \"Email\", \"type\": \"string\"}, \"subject\": {\"default\": \"알 수 없음\", \"description\": \"메일 제목\", \"title\": \"Subject\", \"type\": \"string\"}, \"summary\": {\"description\": \"메일 본문을 요약한 텍스트\", \"title\": \"Summary\", \"type\": \"string\"}, \"date\": {\"default\": \"기한 없음\", \"description\": \"메일 본문에 언급된 due date\", \"title\": \"Date\", \"type\": \"string\"}}, \"required\": [\"summary\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# 전달되는 instruction 내용 확인해보기\n",
    "# 형식 지시사항에 앞서 정의한 Class의 내용이 반영되었음을 확인할 수 있다.\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 을 생성합니다.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"person\": \"보낸이 미상\",\n",
      "    \"email\": \"알 수 없음\",\n",
      "    \"subject\": \"알 수 없음\",\n",
      "    \"summary\": \"보낸이는 BASIC과 EXCLUSIVE의 주요 차이점에 대해 문의하고 있으며, 특히 보안성 차이에 대해 궁금해하고 있습니다. 또한 BASIC과 EXCLUSIVE의 활용 사례에 대한 정보를 요청하고 있습니다. 개인정보 저장 여부와 관련된 요약 서비스의 기술적 검토 및 제안도 요청하고 있으며, 경북교육청의 서비스 활용 사례에 대한 참고를 원하고 있습니다.\",\n",
      "    \"date\": \"기한 없음\"\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "response = chain.stream(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 결과는 JSON 형태로 출력됩니다.\n",
    "output = stream_response(response, return_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person='보낸이 미상' email='알 수 없음' subject='알 수 없음' summary='보낸이는 BASIC과 EXCLUSIVE의 주요 차이점에 대해 문의하고 있으며, 특히 보안성 차이에 대해 궁금해하고 있습니다. 또한 BASIC과 EXCLUSIVE의 활용 사례에 대한 정보를 요청하고 있습니다. 개인정보 저장 여부와 관련된 요약 서비스의 기술적 검토 및 제안도 요청하고 있으며, 경북교육청의 서비스 활용 사례에 대한 참고를 원하고 있습니다.' date='기한 없음'\n"
     ]
    }
   ],
   "source": [
    "# PydanticOutputParser 를 사용하여 결과를 파싱합니다.\n",
    "structured_output = parser.parse(output)\n",
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 파서를 추가하여 전체 체인을 재구성합니다.\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmailSummary(person='보낸이 미상', email='알 수 없음', subject='알 수 없음', summary='이메일 발신자는 BASIC과 EXCLUSIVE의 주요 차이점에 대해 문의하고 있으며, 특히 보안 측면에서의 차이를 알고 싶어합니다. 또한 BASIC과 EXCLUSIVE의 활용 사례에 대한 정보를 요청하고 있습니다. 개인정보 저장 여부와 관련된 요약 서비스의 기술적 검토 및 제안도 필요하다고 언급하고 있으며, 경북교육청의 활용 사례에 대한 참고를 원하고 있습니다.', date='기한 없음')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 결과는 EmailSummary 객체 형태로 출력됩니다.\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_structered = ChatOpenAI(\n",
    "    temperature=0, model_name=\"gpt-4o\"\n",
    ").with_structured_output(EmailSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:410: UserWarning: Invalid schema for OpenAI's structured output feature, which is the default method for `with_structured_output` as of langchain-openai==0.3. Specify `method=\"function_calling\"` instead or update your schema. See supported schemas: https://platform.openai.com/docs/guides/structured-outputs#supported-schemas\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'EmailSummary': In context=('properties', 'person'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[199]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# invoke() 함수를 호출하여 결과를 출력합니다.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# https://docs.pydantic.dev/latest/concepts/fields/#default-values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m answer = \u001b[43mllm_with_structered\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail_conversation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m answer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5358\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5353\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5354\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5355\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5356\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5357\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5359\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5360\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5361\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5362\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:903\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    901\u001b[39m         response = \u001b[38;5;28mself\u001b[39m.root_client.beta.chat.completions.parse(**payload)\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43m_handle_openai_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_responses_api(payload):\n\u001b[32m    905\u001b[39m     original_schema_obj = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:411\u001b[39m, in \u001b[36m_handle_openai_bad_request\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    403\u001b[39m     message = (\n\u001b[32m    404\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid schema for OpenAI\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms structured output feature, which is the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    405\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdefault method for `with_structured_output` as of langchain-openai==0.3. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://platform.openai.com/docs/guides/structured-outputs#supported-schemas\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    409\u001b[39m     )\n\u001b[32m    410\u001b[39m     warnings.warn(message)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:901\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    899\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    903\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'EmailSummary': In context=('properties', 'person'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"
     ]
    }
   ],
   "source": [
    "# invoke() 함수를 호출하여 결과를 출력합니다.\n",
    "# https://docs.pydantic.dev/latest/concepts/fields/#default-values\n",
    "answer = llm_with_structered.invoke(email_conversation)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌02. CommaSeparatedListOutputParser\n",
    "\n",
    "쉼표로 구분된 항목 목록을 반환할 필요가 있을 때 유용한 파서<br>\n",
    "요청한 정보를 쉼표로 구분하여 간결한 형태로 제공받을 수 있다. <br><br>\n",
    "\n",
    "### 🐼예시\n",
    "* 모델이 출력하는 답변 : \"apple, grape, banana\"\n",
    "* CommaSeparatedListOutputParser 사용 시 : [\"apple\", \"grape\", \"banana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 콤마로 구분된 리스트 출력 파서 초기화\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "\n",
    "# 출력 형식 지침 가져오기 -> get_format_instructions는 모델에게 전달할 Instructions를 반환한다.\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📌만약, subject 가 fruits 라면?\n",
    "\n",
    "아래와 같은 프롬프트가 구성된다.\n",
    "\n",
    "```\n",
    "List five fruits.\n",
    "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz` \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    # 주제에 대한 다섯 가지를 나열하라는 템플릿\n",
    "    # {subject} : 사용자가 입력할 주제가 들어갈 자리\n",
    "    # {format_instructions} : 앞서 반환된 출력 형식 지침을 프롬프트 템플릿에 함께 제공\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],  # 입력 변수로 'subject' 사용\n",
    "    # 부분 변수로 형식 지침 사용\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 프롬프트, 모델, 출력 파서를 연결하여 체인 생성\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['융프라우', '취리히', '루체른', '제네바', '베른']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"스위스 관광명소\"에 대한 체인 호출 실행\n",
    "chain.invoke({\"subject\": \"스위스 관광명소\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['융프라우']\n",
      "['취리히']\n",
      "['루체른']\n",
      "['인터라켄']\n",
      "['제네바']\n"
     ]
    }
   ],
   "source": [
    "# 스트림을 순회합니다.\n",
    "for s in chain.stream({\"subject\": \"스위스 관광명소\"}):\n",
    "    print(s)  # 스트림의 내용을 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌03. StructuredOutputParser\n",
    "LLM의 응답을 dict 형식으로 구성하여 key-value 쌍으로 반환받을 수 있다.<br>\n",
    "`Pydantic/JSON` 파서의 경우 GPT 등 강력한 모델을 활용하는 경우 더 유용하며, `StructuredOutputParser`는 <U>파라미터 수가 더 적은 모델에 유용</U>하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐼ResponseSchema 클래스\n",
    "`StructuredOutputParser`의 dict 구조에서, key-value 쌍에 각각 어떤 값들이 들어가야 하는지 정의하는 데 사용된다.<br>\n",
    "\n",
    "속성\n",
    "* `name` : 응답 필드의 이름(dict key)\n",
    "* `description` : 응답 필드에 대한 설명(dict value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 질문에 대한 답변\n",
    "\n",
    "'''\n",
    "응답의 형태\n",
    "{'answer' : '[사용자의 질문에 대한 답변]', 'source' : '[사용자의 질문에 답할 때 사용한 웹사이트 주소]'}\n",
    "'''\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"사용자의 질문에 대한 답변\"),\n",
    "    ResponseSchema(\n",
    "        name=\"source\",\n",
    "        description=\"사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.\",\n",
    "    ),\n",
    "]\n",
    "# 응답 스키마를 기반으로 한 구조화된 출력 파서 초기화\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // 사용자의 질문에 대한 답변\\n\\t\"source\": string  // 사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.\\n}\\n```'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 출력 형식 지시사항을 파싱합니다.\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트 형태\n",
    "```\n",
    "answer the users question as best as possible.\n",
    "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // 사용자의 질문에 대한 답변\\n\\t\"source\": string  // 사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.\\n}\\n```\n",
    "{사용자의 질문}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = PromptTemplate(\n",
    "    # 사용자의 질문에 최대한 답변하도록 템플릿을 설정합니다.\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    # 입력 변수로 'question'을 사용합니다.\n",
    "    input_variables=[\"question\"],\n",
    "    # 부분 변수로 'format_instructions'을 사용합니다.\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)  # ChatOpenAI 모델 초기화\n",
    "chain = prompt | model | output_parser  # 프롬프트, 모델, 출력 파서를 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '캐나다의 수도는 오타와입니다.',\n",
       " 'source': 'https://ko.wikipedia.org/wiki/%EC%98%A4%ED%83%80%EC%99%80'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 캐나다의 수도가 무엇인지 질문합니다.\n",
    "chain.invoke({\"question\": \"캐나다의 수도는 어디인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': '이순신은 조선시대의 무신 이순신 장군으로서, 임진왜란에서 일본군을 물리치고 전략적 승리를 거두었습니다.', 'source': 'https://ko.wikipedia.org/wiki/%EC%9D%B4%EC%88%9C%EC%8B%A0'}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"이순신의 업적은 무엇인가요?\"}):\n",
    "    # 스트리밍 출력\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌04. JsonOutputParser\n",
    "사용자가 원하는 JSON 스키마를 지정할 수 있으며, 해당 스키마에 맞게 결과를 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 객체를 생성합니다.\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🐼BaseModel\n",
    "`BaseModel`을 상속받은 클래스는 자동으로 데이터 타입 검증 기능을 갖는다.<br>\n",
    "아래 Topic은 description과 hashtags가 문자열(str) 타입이라는 규칙을 정의한 것이며, 자동으로 타입이 검증된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 데이터 구조를 정의합니다.\n",
    "class Topic(BaseModel):\n",
    "    description: str = Field(description=\"주제에 대한 간결한 설명\")\n",
    "    hashtags: str = Field(description=\"해시태그 형식의 키워드(2개 이상)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': '지구 온난화는 지구의 평균 기온이 상승하는 현상으로, 주로 인간 활동에 의해 발생하는 온실가스 배출이 주요 원인입니다. 이는 극지방의 빙하 감소, 해수면 상승, 기후 패턴 변화 등 심각한 환경적 영향을 초래합니다.',\n",
       " 'hashtags': '#지구온난화 #기후변화 #환경보호'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질의 작성\n",
    "question = \"지구 온난화의 심각성 대해 알려주세요.\"\n",
    "\n",
    "# 파서를 설정하고 프롬프트 템플릿에 지시사항을 주입합니다.\n",
    "parser = JsonOutputParser(pydantic_object=Topic)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트 입니다. 질문에 간결하게 답변하세요.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | model | parser  # 체인을 구성합니다.\n",
    "\n",
    "chain.invoke({\"question\": question})  # 체인을 호출하여 쿼리 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Email(BaseModel):\n",
    "    #send : str = Field(\"보낸이 미상\", description=\"메일을 보낸 사람의 이름\")\n",
    "    send : str = Field(description=\"메일을 보낸 사람의 이름\")\n",
    "    content: str = Field(description=\"메일의 핵심 내용을 한줄로 정리\")\n",
    "    receive: str = Field(description=\"메일 받은 사람 이름\")\n",
    "    follow_up: str = Field(description=\"필요한 후속 조치\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'send': '보낸이 미상',\n",
       " 'content': '네이버클라우드플랫폼은 장비 세팅 완료 후 터널링 생성 가능하며, Pre-Shared Key에 특수문자 사용 불가.',\n",
       " 'receive': '김민성 매니저',\n",
       " 'follow_up': '장비 세팅 완료 후 연락 및 특수문자 없는 Pre-Shared Key 전달, 특정 서버 서브넷 IP 대역 확인 요청.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질의 작성\n",
    "question = \"\"\" \n",
    "\n",
    "안녕하세요. 김민성 매니저님.\n",
    "굿어스데이터 진재영입니다.\n",
    "\n",
    "네이버클라우드플랫폼은 장비 세팅 완료 이전에 터널링을 생성하는 기능을 지원하지 않고 있습니다.\n",
    "따라서, 13시에 본사 장비 세팅 완료하신 후 연락 주시면 터널링 생성 진행하도록 하겠습니다.\n",
    "\n",
    "또한, 민간존 IPSec VPN Pre-Shared Key에는 특수문자 사용이 불가합니다. \n",
    "따라서 특수문자가 포함되지 않은 Pre-Shared Key 전달 부탁드립니다.\n",
    "\n",
    "[살루스케어 NCP IP 정보]\n",
    "VPC : 10.0.0.0/16\n",
    "IPSec VPN Gateway : 175.106.107.89\n",
    "\n",
    "추가로, IPSec VPN 연동하시고자 하는 특정 서버(서브넷)가 있으신지 확인 요청드립니다.\n",
    "우선 전체 VPC 대역으로 전달드리오나, 특정 서버에 대해서만 연동을 원하신다면, 해당 서브넷 IP 대역으로 다시 전달드리도록 하겠습니다. \n",
    "\n",
    "확인 부탁드립니다.\n",
    "\n",
    "감사합니다.\n",
    "진재영 드림\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 파서를 설정하고 프롬프트 템플릿에 지시사항을 주입합니다.\n",
    "parser = JsonOutputParser(pydantic_object=Email)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트 입니다. 주어진 메일을 형식에 맞게 요약하세요.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | model | parser  # 체인을 구성합니다.\n",
    "\n",
    "chain.invoke({\"question\": question})  # 체인을 호출하여 쿼리 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌05. PandasDataFrameOutputParser\n",
    "Pandas Dataframe은 Python으로 2차원 데이터를 다룰 때 사용되는데, <br>\n",
    "PandasDataFrameOutputParser를 사용하면 데이터프레임에서 데이터를 뽑아 정리된 형태로 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns # 예시 데이터셋 가져오기 위한 용도\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI 모델 초기화 (gpt-3.5-turbo 모델 사용을 권장합니다)\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 목적으로만 사용됩니다.\n",
    "def format_parser_output(parser_output: Dict[str, Any]) -> None:\n",
    "    # 파서 출력의 키들을 순회합니다.\n",
    "    for key in parser_output.keys():\n",
    "        # 각 키의 값을 딕셔너리로 변환합니다.\n",
    "        parser_output[key] = parser_output[key].to_dict()\n",
    "    # 예쁘게 출력합니다.\n",
    "    return pprint.PrettyPrinter(width=4, compact=True).pprint(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'penguins' 데이터셋 로드\n",
    "df = sns.load_dataset('penguins')\n",
    "df.head()\n",
    "\n",
    "# 펭귄의 종 / 서식하는 섬 / 부리 길이 / 부리 깊이 / 날개 길이 / 체중 / 성별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\n",
      "1. The column names are limited to the possible columns below.\n",
      "2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\n",
      "3. Remember that arrays are optional and not necessarily required.\n",
      "4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\n",
      "\n",
      "As an example, for the formats:\n",
      "1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\n",
      "2. String \"row:1\" is a well-formatted instance which gets row 1.\n",
      "3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\n",
      "4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\n",
      "5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\n",
      "6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\n",
      "7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\n",
      "\n",
      "Here are the possible columns:\n",
      "```\n",
      "species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 파서를 설정하고 프롬프트 템플릿에 지시사항을 주입합니다.\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# 파서의 지시사항을 출력합니다.\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'island': {0: 'Torgersen',\n",
      "            1: 'Torgersen',\n",
      "            2: 'Torgersen',\n",
      "            3: 'Torgersen',\n",
      "            4: 'Torgersen',\n",
      "            5: 'Torgersen',\n",
      "            6: 'Torgersen',\n",
      "            7: 'Torgersen',\n",
      "            8: 'Torgersen',\n",
      "            9: 'Torgersen',\n",
      "            10: 'Torgersen',\n",
      "            11: 'Torgersen',\n",
      "            12: 'Torgersen',\n",
      "            13: 'Torgersen',\n",
      "            14: 'Torgersen',\n",
      "            15: 'Torgersen',\n",
      "            16: 'Torgersen',\n",
      "            17: 'Torgersen',\n",
      "            18: 'Torgersen',\n",
      "            19: 'Torgersen',\n",
      "            20: 'Biscoe',\n",
      "            21: 'Biscoe',\n",
      "            22: 'Biscoe',\n",
      "            23: 'Biscoe',\n",
      "            24: 'Biscoe',\n",
      "            25: 'Biscoe',\n",
      "            26: 'Biscoe',\n",
      "            27: 'Biscoe',\n",
      "            28: 'Biscoe',\n",
      "            29: 'Biscoe',\n",
      "            30: 'Dream',\n",
      "            31: 'Dream',\n",
      "            32: 'Dream',\n",
      "            33: 'Dream',\n",
      "            34: 'Dream',\n",
      "            35: 'Dream',\n",
      "            36: 'Dream',\n",
      "            37: 'Dream',\n",
      "            38: 'Dream',\n",
      "            39: 'Dream',\n",
      "            40: 'Dream',\n",
      "            41: 'Dream',\n",
      "            42: 'Dream',\n",
      "            43: 'Dream',\n",
      "            44: 'Dream',\n",
      "            45: 'Dream',\n",
      "            46: 'Dream',\n",
      "            47: 'Dream',\n",
      "            48: 'Dream',\n",
      "            49: 'Dream',\n",
      "            50: 'Biscoe',\n",
      "            51: 'Biscoe',\n",
      "            52: 'Biscoe',\n",
      "            53: 'Biscoe',\n",
      "            54: 'Biscoe',\n",
      "            55: 'Biscoe',\n",
      "            56: 'Biscoe',\n",
      "            57: 'Biscoe',\n",
      "            58: 'Biscoe',\n",
      "            59: 'Biscoe',\n",
      "            60: 'Biscoe',\n",
      "            61: 'Biscoe',\n",
      "            62: 'Biscoe',\n",
      "            63: 'Biscoe',\n",
      "            64: 'Biscoe',\n",
      "            65: 'Biscoe',\n",
      "            66: 'Biscoe',\n",
      "            67: 'Biscoe',\n",
      "            68: 'Torgersen',\n",
      "            69: 'Torgersen',\n",
      "            70: 'Torgersen',\n",
      "            71: 'Torgersen',\n",
      "            72: 'Torgersen',\n",
      "            73: 'Torgersen',\n",
      "            74: 'Torgersen',\n",
      "            75: 'Torgersen',\n",
      "            76: 'Torgersen',\n",
      "            77: 'Torgersen',\n",
      "            78: 'Torgersen',\n",
      "            79: 'Torgersen',\n",
      "            80: 'Torgersen',\n",
      "            81: 'Torgersen',\n",
      "            82: 'Torgersen',\n",
      "            83: 'Torgersen',\n",
      "            84: 'Dream',\n",
      "            85: 'Dream',\n",
      "            86: 'Dream',\n",
      "            87: 'Dream',\n",
      "            88: 'Dream',\n",
      "            89: 'Dream',\n",
      "            90: 'Dream',\n",
      "            91: 'Dream',\n",
      "            92: 'Dream',\n",
      "            93: 'Dream',\n",
      "            94: 'Dream',\n",
      "            95: 'Dream',\n",
      "            96: 'Dream',\n",
      "            97: 'Dream',\n",
      "            98: 'Dream',\n",
      "            99: 'Dream',\n",
      "            100: 'Biscoe',\n",
      "            101: 'Biscoe',\n",
      "            102: 'Biscoe',\n",
      "            103: 'Biscoe',\n",
      "            104: 'Biscoe',\n",
      "            105: 'Biscoe',\n",
      "            106: 'Biscoe',\n",
      "            107: 'Biscoe',\n",
      "            108: 'Biscoe',\n",
      "            109: 'Biscoe',\n",
      "            110: 'Biscoe',\n",
      "            111: 'Biscoe',\n",
      "            112: 'Biscoe',\n",
      "            113: 'Biscoe',\n",
      "            114: 'Biscoe',\n",
      "            115: 'Biscoe',\n",
      "            116: 'Torgersen',\n",
      "            117: 'Torgersen',\n",
      "            118: 'Torgersen',\n",
      "            119: 'Torgersen',\n",
      "            120: 'Torgersen',\n",
      "            121: 'Torgersen',\n",
      "            122: 'Torgersen',\n",
      "            123: 'Torgersen',\n",
      "            124: 'Torgersen',\n",
      "            125: 'Torgersen',\n",
      "            126: 'Torgersen',\n",
      "            127: 'Torgersen',\n",
      "            128: 'Torgersen',\n",
      "            129: 'Torgersen',\n",
      "            130: 'Torgersen',\n",
      "            131: 'Torgersen',\n",
      "            132: 'Dream',\n",
      "            133: 'Dream',\n",
      "            134: 'Dream',\n",
      "            135: 'Dream',\n",
      "            136: 'Dream',\n",
      "            137: 'Dream',\n",
      "            138: 'Dream',\n",
      "            139: 'Dream',\n",
      "            140: 'Dream',\n",
      "            141: 'Dream',\n",
      "            142: 'Dream',\n",
      "            143: 'Dream',\n",
      "            144: 'Dream',\n",
      "            145: 'Dream',\n",
      "            146: 'Dream',\n",
      "            147: 'Dream',\n",
      "            148: 'Dream',\n",
      "            149: 'Dream',\n",
      "            150: 'Dream',\n",
      "            151: 'Dream',\n",
      "            152: 'Dream',\n",
      "            153: 'Dream',\n",
      "            154: 'Dream',\n",
      "            155: 'Dream',\n",
      "            156: 'Dream',\n",
      "            157: 'Dream',\n",
      "            158: 'Dream',\n",
      "            159: 'Dream',\n",
      "            160: 'Dream',\n",
      "            161: 'Dream',\n",
      "            162: 'Dream',\n",
      "            163: 'Dream',\n",
      "            164: 'Dream',\n",
      "            165: 'Dream',\n",
      "            166: 'Dream',\n",
      "            167: 'Dream',\n",
      "            168: 'Dream',\n",
      "            169: 'Dream',\n",
      "            170: 'Dream',\n",
      "            171: 'Dream',\n",
      "            172: 'Dream',\n",
      "            173: 'Dream',\n",
      "            174: 'Dream',\n",
      "            175: 'Dream',\n",
      "            176: 'Dream',\n",
      "            177: 'Dream',\n",
      "            178: 'Dream',\n",
      "            179: 'Dream',\n",
      "            180: 'Dream',\n",
      "            181: 'Dream',\n",
      "            182: 'Dream',\n",
      "            183: 'Dream',\n",
      "            184: 'Dream',\n",
      "            185: 'Dream',\n",
      "            186: 'Dream',\n",
      "            187: 'Dream',\n",
      "            188: 'Dream',\n",
      "            189: 'Dream',\n",
      "            190: 'Dream',\n",
      "            191: 'Dream',\n",
      "            192: 'Dream',\n",
      "            193: 'Dream',\n",
      "            194: 'Dream',\n",
      "            195: 'Dream',\n",
      "            196: 'Dream',\n",
      "            197: 'Dream',\n",
      "            198: 'Dream',\n",
      "            199: 'Dream',\n",
      "            200: 'Dream',\n",
      "            201: 'Dream',\n",
      "            202: 'Dream',\n",
      "            203: 'Dream',\n",
      "            204: 'Dream',\n",
      "            205: 'Dream',\n",
      "            206: 'Dream',\n",
      "            207: 'Dream',\n",
      "            208: 'Dream',\n",
      "            209: 'Dream',\n",
      "            210: 'Dream',\n",
      "            211: 'Dream',\n",
      "            212: 'Dream',\n",
      "            213: 'Dream',\n",
      "            214: 'Dream',\n",
      "            215: 'Dream',\n",
      "            216: 'Dream',\n",
      "            217: 'Dream',\n",
      "            218: 'Dream',\n",
      "            219: 'Dream',\n",
      "            220: 'Biscoe',\n",
      "            221: 'Biscoe',\n",
      "            222: 'Biscoe',\n",
      "            223: 'Biscoe',\n",
      "            224: 'Biscoe',\n",
      "            225: 'Biscoe',\n",
      "            226: 'Biscoe',\n",
      "            227: 'Biscoe',\n",
      "            228: 'Biscoe',\n",
      "            229: 'Biscoe',\n",
      "            230: 'Biscoe',\n",
      "            231: 'Biscoe',\n",
      "            232: 'Biscoe',\n",
      "            233: 'Biscoe',\n",
      "            234: 'Biscoe',\n",
      "            235: 'Biscoe',\n",
      "            236: 'Biscoe',\n",
      "            237: 'Biscoe',\n",
      "            238: 'Biscoe',\n",
      "            239: 'Biscoe',\n",
      "            240: 'Biscoe',\n",
      "            241: 'Biscoe',\n",
      "            242: 'Biscoe',\n",
      "            243: 'Biscoe',\n",
      "            244: 'Biscoe',\n",
      "            245: 'Biscoe',\n",
      "            246: 'Biscoe',\n",
      "            247: 'Biscoe',\n",
      "            248: 'Biscoe',\n",
      "            249: 'Biscoe',\n",
      "            250: 'Biscoe',\n",
      "            251: 'Biscoe',\n",
      "            252: 'Biscoe',\n",
      "            253: 'Biscoe',\n",
      "            254: 'Biscoe',\n",
      "            255: 'Biscoe',\n",
      "            256: 'Biscoe',\n",
      "            257: 'Biscoe',\n",
      "            258: 'Biscoe',\n",
      "            259: 'Biscoe',\n",
      "            260: 'Biscoe',\n",
      "            261: 'Biscoe',\n",
      "            262: 'Biscoe',\n",
      "            263: 'Biscoe',\n",
      "            264: 'Biscoe',\n",
      "            265: 'Biscoe',\n",
      "            266: 'Biscoe',\n",
      "            267: 'Biscoe',\n",
      "            268: 'Biscoe',\n",
      "            269: 'Biscoe',\n",
      "            270: 'Biscoe',\n",
      "            271: 'Biscoe',\n",
      "            272: 'Biscoe',\n",
      "            273: 'Biscoe',\n",
      "            274: 'Biscoe',\n",
      "            275: 'Biscoe',\n",
      "            276: 'Biscoe',\n",
      "            277: 'Biscoe',\n",
      "            278: 'Biscoe',\n",
      "            279: 'Biscoe',\n",
      "            280: 'Biscoe',\n",
      "            281: 'Biscoe',\n",
      "            282: 'Biscoe',\n",
      "            283: 'Biscoe',\n",
      "            284: 'Biscoe',\n",
      "            285: 'Biscoe',\n",
      "            286: 'Biscoe',\n",
      "            287: 'Biscoe',\n",
      "            288: 'Biscoe',\n",
      "            289: 'Biscoe',\n",
      "            290: 'Biscoe',\n",
      "            291: 'Biscoe',\n",
      "            292: 'Biscoe',\n",
      "            293: 'Biscoe',\n",
      "            294: 'Biscoe',\n",
      "            295: 'Biscoe',\n",
      "            296: 'Biscoe',\n",
      "            297: 'Biscoe',\n",
      "            298: 'Biscoe',\n",
      "            299: 'Biscoe',\n",
      "            300: 'Biscoe',\n",
      "            301: 'Biscoe',\n",
      "            302: 'Biscoe',\n",
      "            303: 'Biscoe',\n",
      "            304: 'Biscoe',\n",
      "            305: 'Biscoe',\n",
      "            306: 'Biscoe',\n",
      "            307: 'Biscoe',\n",
      "            308: 'Biscoe',\n",
      "            309: 'Biscoe',\n",
      "            310: 'Biscoe',\n",
      "            311: 'Biscoe',\n",
      "            312: 'Biscoe',\n",
      "            313: 'Biscoe',\n",
      "            314: 'Biscoe',\n",
      "            315: 'Biscoe',\n",
      "            316: 'Biscoe',\n",
      "            317: 'Biscoe',\n",
      "            318: 'Biscoe',\n",
      "            319: 'Biscoe',\n",
      "            320: 'Biscoe',\n",
      "            321: 'Biscoe',\n",
      "            322: 'Biscoe',\n",
      "            323: 'Biscoe',\n",
      "            324: 'Biscoe',\n",
      "            325: 'Biscoe',\n",
      "            326: 'Biscoe',\n",
      "            327: 'Biscoe',\n",
      "            328: 'Biscoe',\n",
      "            329: 'Biscoe',\n",
      "            330: 'Biscoe',\n",
      "            331: 'Biscoe',\n",
      "            332: 'Biscoe',\n",
      "            333: 'Biscoe',\n",
      "            334: 'Biscoe',\n",
      "            335: 'Biscoe',\n",
      "            336: 'Biscoe',\n",
      "            337: 'Biscoe',\n",
      "            338: 'Biscoe',\n",
      "            339: 'Biscoe',\n",
      "            340: 'Biscoe',\n",
      "            341: 'Biscoe',\n",
      "            342: 'Biscoe',\n",
      "            343: 'Biscoe'}}\n"
     ]
    }
   ],
   "source": [
    "# 열 작업 예시입니다.\n",
    "df_query = \"island column 을 조회해 주세요.\"\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿을 설정합니다.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],  # 입력 변수 설정\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    },  # 부분 변수 설정\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# 체인 실행\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# 출력\n",
    "format_parser_output(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'bill_depth_mm': 18.7,\n",
      "       'bill_length_mm': 39.1,\n",
      "       'body_mass_g': 3750.0,\n",
      "       'flipper_length_mm': 181.0,\n",
      "       'island': 'Torgersen',\n",
      "       'sex': 'Male',\n",
      "       'species': 'Adelie'}}\n"
     ]
    }
   ],
   "source": [
    "# 행 조회 예시입니다.\n",
    "# df_query = \"Retrieve the first row.\"\n",
    "df_query = \"0번째 행 출력\"\n",
    "\n",
    "# 체인 실행\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# 결과 출력\n",
    "format_parser_output(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3562.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_mass_g'].head().mean()\n",
    "#print(df['body_mass_g'].iloc[:5].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 3562.5}\n"
     ]
    }
   ],
   "source": [
    "# 임의의 Pandas DataFrame 작업 예시, 행의 수를 제한합니다.\n",
    "df_query = \"Retrieve the average of the body_mass_g from row 0 to 4.\" \n",
    "\n",
    "# 체인 실행\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# 결과 출력\n",
    "print(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 4201.754385964912}\n"
     ]
    }
   ],
   "source": [
    "#df_query = \"Calculate average body_mass_g rate\" # **중요한점 : 올바르게 형식화된, 명확한 쿼리를 사용하는 것이 중요!!\n",
    "df_query = \"Calculate the average of the 'body_mass_g' column.\"\n",
    "\n",
    "# 체인 실행\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# 결과 출력\n",
    "print(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4201.754385964912"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_mass_g'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌06. DatetimeOutputParser\n",
    "LLM의 출력을 `datetime` 형식으로 파싱하는데 활용 가능\n",
    "\n",
    "### 🐼날짜 및 시간 형식 코드\n",
    "\n",
    "| 형식 코드 | 설명               | 예시                     |\n",
    "|----------|------------------|-------------------------|\n",
    "| `%Y`     | 4자리 연도        | `2024`                  |\n",
    "| `%y`     | 2자리 연도        | `24`                    |\n",
    "| `%m`     | 2자리 월          | `07`                    |\n",
    "| `%d`     | 2자리 일          | `04`                    |\n",
    "| `%H`     | 24시간제 시간     | `14`                    |\n",
    "| `%I`     | 12시간제 시간     | `02`                    |\n",
    "| `%p`     | AM 또는 PM       | `PM`                    |\n",
    "| `%M`     | 2자리 분          | `45`                    |\n",
    "| `%S`     | 2자리 초          | `08`                    |\n",
    "| `%f`     | 마이크로초 (6자리) | `000123`                |\n",
    "| `%z`     | UTC 오프셋        | `+0900`                 |\n",
    "| `%Z`     | 시간대 이름       | `KST`                    |\n",
    "| `%a`     | 요일 약어         | `Thu`                   |\n",
    "| `%A`     | 요일 전체         | `Thursday`              |\n",
    "| `%b`     | 월 약어           | `Jul`                   |\n",
    "| `%B`     | 월 전체           | `July`                  |\n",
    "| `%c`     | 전체 날짜와 시간  | `Thu Jul 4 14:45:08 2024` |\n",
    "| `%x`     | 전체 날짜         | `07/04/24`              |\n",
    "| `%X`     | 전체 시간         | `14:45:08`              |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 및 시간 출력 파서\n",
    "output_parser = DatetimeOutputParser()\n",
    "output_parser.format = \"%Y-%m-%d\"\n",
    "#output_parser.format = \"%c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%d'.\\n\\nExamples: 1562-10-11, 0602-12-21, 1650-11-06\\n\\nReturn ONLY this string, no other words!\"}, template='Answer the users question:\\n\\n#Format Instructions: \\n{format_instructions}\\n\\n#Question: \\n{question}\\n\\n#Answer:')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 질문에 대한 답변 템플릿\n",
    "template = \"\"\"Answer the users question:\\n\\n#Format Instructions: \\n{format_instructions}\\n\\n#Question: \\n{question}\\n\\n#Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\n",
    "        \"format_instructions\": output_parser.get_format_instructions()\n",
    "    },  # 지침을 템플릿에 적용\n",
    ")\n",
    "\n",
    "# 프롬프트 내용을 출력\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 을 생성합니다.\n",
    "chain = prompt | ChatOpenAI() | output_parser\n",
    "\n",
    "# 체인을 호출하여 질문에 대한 답변을 받습니다.\n",
    "output = chain.invoke({\"question\": \"Google 이 창업한 연도는?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1998, 9, 4, 0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datetime 객체 형태로 출력됨\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1998-09-04'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과를 문자열로 변환\n",
    "output.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌07. EnumOutputParser\n",
    "LLM의 응답 값을 제한된 범위 안에서만 허용하도록 설정하는 데에 도움을 줄 수 있는 파서이다.<br>\n",
    "예상치 못한 응답값을 방지하는 데에 도움이 될 수 있다.<br>\n",
    "(ex. Y/N로 대답해야 하는 경우, Task의 진행상태(성공, 실패, 진행중)를 출력해야 하는 경우 등)\n",
    "\n",
    "### 🐼Enum?\n",
    "Enumeration(열거형)이란, 서로 관련있는 여러 개의 상수 집합을 정의할 때 사용하는 모듈이다.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colors(Enum):\n",
    "    RED = \"빨간색\"\n",
    "    GREEN = \"초록색\"\n",
    "    BLUE = \"파란색\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'Colors'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Colors.BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnumOutputParser 인스턴스 생성\n",
    "parser = EnumOutputParser(enum=Colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 프롬프트 템플릿을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"다음의 물체는 어떤 색깔인가요?\n",
    "\n",
    "Object: {object}\n",
    "\n",
    "Instructions: {instructions}\"\"\"\n",
    "    # 파서에서 지시사항 형식을 가져와 부분적으로 적용합니다.\n",
    ").partial(instructions=parser.get_format_instructions())\n",
    "# 프롬프트와 ChatOpenAI, 파서를 연결합니다.\n",
    "chain = prompt | ChatOpenAI() | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colors.BLUE\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"하늘\"})  # \"하늘\" 에 대한 체인 호출 실행\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또다른 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviews(Enum):\n",
    "    POSITIVE = \"대체로 긍정적\"\n",
    "    NEUTRAL = \"호불호가 갈림\"\n",
    "    NEGATIVE = \"대체로 부정적\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnumOutputParser 인스턴스 생성\n",
    "parser = EnumOutputParser(enum=Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"다음 영화의 평점은 어떤가요?\n",
    "\n",
    "Object: {object}\n",
    "\n",
    "Instructions: {instructions}\"\"\"\n",
    "    # 파서에서 지시사항 형식을 가져와 부분적으로 적용합니다.\n",
    ").partial(instructions=parser.get_format_instructions())\n",
    "# 프롬프트와 ChatOpenAI, 파서를 연결합니다.\n",
    "chain = prompt | ChatOpenAI() | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews.POSITIVE\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"The Shawshank Redemption\"})  # 쇼생크 탈출\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews.NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"Eternals\"})  # 이터널스\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews.NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"Mars Needs Moms\"})  # 화성은 엄마가 필요해(2011)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📌08. OutputFixingParser\n",
    "출력 파싱 과정에서 발생할 수 있는 오류를 자동으로 수정하는 기능을 제공한다.<br>\n",
    "파서가 처리할 수 없는 형식이나 오류를 반환하는 경우, LLM을 추가적으로 호출하여 오류를 수정할 수 있다.\n",
    "\n",
    "예를 들어, 첫 번째 결과에서 정의된 스키마를 준수하지 않는 결과가 도출될 경우,<br>\n",
    "`OutputFixingParser`가 자동으로 출력 형식이 잘못되었음을 인식하고 이를 수정하기 위한 내용을 추가하여 LLM에 다시 응답을 요청한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.output_parsers import OutputFixingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(\n",
    "        description=\"list of names of films they starred in\")\n",
    "\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:83\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:145\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    144\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:161\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:119\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[129]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m misformatted = \u001b[33m\"\u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mTom Hanks\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfilm_names\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mForrest Gump\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]}\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 잘못된 형식으로 입력된 데이터를 파싱하려고 시도\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmisformatted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 오류 출력\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:83\u001b[39m, in \u001b[36mPydanticOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> TBaseModel:\n\u001b[32m     75\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m        The parsed pydantic object.\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:97\u001b[39m, in \u001b[36mJsonOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m     89\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a JSON object.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m        The parsed JSON object.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:67\u001b[39m, in \u001b[36mPydanticOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the result of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m \u001b[33;03m    The parsed pydantic object.\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     json_object = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_obj(json_object)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:86\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     85\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "# 잘못된 형식을 일부러 입력\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"\n",
    "\n",
    "# 잘못된 형식으로 입력된 데이터를 파싱하려고 시도\n",
    "parser.parse(misformatted)\n",
    "\n",
    "# 오류 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 잘못된 형식의 출력\n",
    "misformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'instructions'}.  Expected: ['completion', 'error', 'instructions'] Received: ['completion', 'error']\\nNote: if you intended {instructions} to be part of the string and not a variable, please escape it with double curly braces like: '{{instructions}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:83\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:145\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    144\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:161\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:119\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:70\u001b[39m, in \u001b[36mOutputFixingParser.parse\u001b[39m\u001b[34m(self, completion)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:83\u001b[39m, in \u001b[36mPydanticOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m    The parsed pydantic object.\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:97\u001b[39m, in \u001b[36mJsonOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a JSON object.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m    The parsed JSON object.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:67\u001b[39m, in \u001b[36mPydanticOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     json_object = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_obj(json_object)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:86\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     85\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:86\u001b[39m, in \u001b[36mOutputFixingParser.parse\u001b[39m\u001b[34m(self, completion)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     84\u001b[39m     completion = \u001b[38;5;28mself\u001b[39m.retry_chain.invoke(\n\u001b[32m     85\u001b[39m         \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m             instructions=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_format_instructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     87\u001b[39m             completion=completion,\n\u001b[32m     88\u001b[39m             error=\u001b[38;5;28mrepr\u001b[39m(e),\n\u001b[32m     89\u001b[39m         )\n\u001b[32m     90\u001b[39m     )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# Case: self.parser does not have get_format_instructions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:92\u001b[39m, in \u001b[36mPydanticOutputParser.get_format_instructions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Copy schema to avoid altering original Pydantic schema.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m schema = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpydantic_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_json_schema\u001b[49m().items())\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Remove extraneous fields.\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'Actor' has no attribute 'model_json_schema'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# OutputFixingParser 를 사용하여 잘못된 형식의 출력을 파싱\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m actor = \u001b[43mnew_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmisformatted\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:93\u001b[39m, in \u001b[36mOutputFixingParser.parse\u001b[39m\u001b[34m(self, completion)\u001b[39m\n\u001b[32m     84\u001b[39m                     completion = \u001b[38;5;28mself\u001b[39m.retry_chain.invoke(\n\u001b[32m     85\u001b[39m                         \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     86\u001b[39m                             instructions=\u001b[38;5;28mself\u001b[39m.parser.get_format_instructions(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m                         )\n\u001b[32m     90\u001b[39m                     )\n\u001b[32m     91\u001b[39m                 \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m     92\u001b[39m                     \u001b[38;5;66;03m# Case: self.parser does not have get_format_instructions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m                     completion = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                            \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[33m\"\u001b[39m\u001b[33mFailed to parse\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\prompts\\base.py:210\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    209\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] = config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1925\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1921\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1922\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1923\u001b[39m         output = cast(\n\u001b[32m   1924\u001b[39m             Output,\n\u001b[32m-> \u001b[39m\u001b[32m1925\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1927\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1928\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1933\u001b[39m         )\n\u001b[32m   1934\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1935\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\prompts\\base.py:184\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     _inner_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_prompt(**_inner_input)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\prompts\\base.py:178\u001b[39m, in \u001b[36mBasePromptTemplate._validate_input\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    172\u001b[39m     example_key = missing.pop()\n\u001b[32m    173\u001b[39m     msg += (\n\u001b[32m    174\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m to be part of the string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    175\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    177\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    179\u001b[39m         create_message(message=msg, error_code=ErrorCode.INVALID_PROMPT_INPUT)\n\u001b[32m    180\u001b[39m     )\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[31mKeyError\u001b[39m: \"Input to PromptTemplate is missing variables {'instructions'}.  Expected: ['completion', 'error', 'instructions'] Received: ['completion', 'error']\\nNote: if you intended {instructions} to be part of the string and not a variable, please escape it with double curly braces like: '{{instructions}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "# OutputFixingParser 를 사용하여 잘못된 형식의 출력을 파싱\n",
    "actor = new_parser.parse(misformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 파싱된 결과\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mactor\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'actor' is not defined"
     ]
    }
   ],
   "source": [
    "# 파싱된 결과\n",
    "actor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
