{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ì¶œë ¥ íŒŒì„œ (Output Parser)\n",
    "* LLMì˜ ì¶œë ¥ì„ êµ¬ì¡°í™”í•˜ëŠ” ì»´í¬ë„ŒíŠ¸\n",
    "* ì¶œë ¥ì„ ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë³´ê¸° ì‰½ê²Œ ë§Œë“¤ê±°ë‚˜, êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### ğŸ“Œ01. Pydantic Output Parser\n",
    "\n",
    "Pydantic Output Parser ì‚¬ìš©ì„ ìœ„í•´ì„œëŠ” ë‘ ê°€ì§€ ë©”ì„œë“œê°€ í•„ìš”í•˜ë‹¤.(ëŒ€ë¶€ë¶„ì˜ OutputParserê°€ í•„ìš”ë¡œ í•¨)\n",
    "\n",
    "1. ```get_format_instructions()```\n",
    "* ì–¸ì–´ ëª¨ë¸ì´ ì¶œë ¥í•´ì•¼ í•  ê²°ê³¼ë¬¼ì˜ í˜•ì‹ì„ ì •ì˜í•´ì£¼ëŠ” ì§€ì¹¨ì„ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ\n",
    "* ë§Œì•½, JSON í˜•ì‹ì„ ì¤€ìˆ˜í•˜ëŠ” ê²°ê³¼ë¥¼ ì¶œë ¥í•´ì•¼ í•˜ëŠ” ê²½ìš°ë¼ë©´, JSON í˜•ì‹ì— ë§ê²Œ ê²°ê³¼ë¬¼ì„ êµ¬ì¡°í™”í•  ìˆ˜ ìˆë„ë¡ ì§€ì‹œí•˜ëŠ” ë‚´ìš©ì´ ë°˜í™˜ëœë‹¤.\n",
    "\n",
    "2. ```parse()```\n",
    "* ì–¸ì–´ ëª¨ë¸ì˜ ì¶œë ¥ì„ ë°›ì•„ë“¤ì—¬ ì´ë¥¼ parserì˜ íƒ€ì…ì— ë§ê²Œ ë³€í™˜í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì„œë“œ\n",
    "* ì‚¬ì „ì— ì •ì˜ëœ ìŠ¤í‚¤ë§ˆë¥¼ ë°˜ì˜í•˜ì—¬ parserë¥¼ ìƒì„±í•œ í›„, parse() ë©”ì„œë“œë¥¼ í†µí•´ í˜•ì‹ì„ ë³€í™˜í•˜ì—¬ ì›í•˜ëŠ” ë°ì´í„° í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•  ìˆ˜ ìˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from pprint import *\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_conversation = \"\"\" \n",
    "ì•ˆë…•í•˜ì„¸ìš” ê³¼ì¥ë‹˜ \n",
    "ì˜¤ëŠ˜ ë„ˆë¬´ ë°”ë¹ ì„œ ì „í™”ë¥¼ ë“œë¦¬ê¸° ì–´ë ¤ì› ìŠµë‹ˆë‹¤.\n",
    "ì¼ë‹¨ ì£¼ì‹  íŒŒì¼ì„ ë³´ëŠ”ë° ì°¨ì´ì ì´ ì£¼ìš”í•˜ê²ŒëŠ” BASICê³¼ EXCLUSIVEê°€ ì£¼ìš” í¬ì¸íŠ¸ì¸ ê²ƒ ê°™ì•„ìš” \n",
    "HCXì™€ HCX-DASHëŠ” ë¯¼ê°„ ê³µê³µ ëª¨ë‘ì— ì•½ê°„ì˜ ì…ë ¥í† í° ì°¨ì´ë§Œ ìˆìœ¼ë‹ˆê¹Œìš”\n",
    "\n",
    "ê·¸ëŸ¼ ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ê²ƒì´ BASICê³¼ EXCLUSIVEì—ì„œì˜ ë³´ì•ˆ ë¶€ë¶„ì—ì„œëŠ” ì–´ë–¤ ì°¨ì´ê°€ ìˆì„ê¹Œìš”?\n",
    "BASICìœ¼ë¡œ í™œìš©í•˜ë©´ ë³´ì•ˆì„±ì´ ë–¨ì–´ì§€ëŠ” ê¸°ìˆ ì´ ì ìš©ë˜ê±°ë‚˜ ê·¸ëŸ° ê²ƒì´ ì•„ë‹Œì§€ìš”?\n",
    "\n",
    "ê·¸ë¦¬ê³  BASICì„ í™œìš©í•˜ëŠ” ê²ƒì— ëŒ€í•œ ì‚¬ë¡€, EXCLUSIVEë¥¼ í™œìš©í•˜ëŠ” ì‚¬ë¡€ëŠ” ì–´ë–¤ ê²ƒì´ ìˆëŠ”ì§€ ëŒ€ëµì ìœ¼ë¡œë¼ë„ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
    "(ì œ ê°œì¸ì ì¸ ìƒê°ì—ëŠ” ìš”ì•½ì„œë¹„ìŠ¤ëŠ” ê°œì¸ì •ë³´ê°€ ì €ì¥ ì—¬ë¶€ë„ ì¤‘ìš”í•œ ê²ƒ ê°™ì€ë°...\n",
    "ë‹¤ì±„ì›€ì—ì„œëŠ”  ê³¼ì œ ìš”ì•½ì„œë¹„ìŠ¤ë¡œ ë„¤ì´ë²„ í´ë¼ìš°ë“œë¥¼ í™œìš© ì‹œì—ëŠ” ê°œì¸ì •ë³´ë¥¼ í™œìš©í•˜ì§€ë„ ì•Šê³ , ìš”ì•½í•œ ì •ë³´ê°€ íœ˜ë°œë  ê²ƒ ê°™ì€ë° ì´ëŸ¬í•œ ì‚¬ë¡€ì—ì„œë„ ê³µê³µì¡´ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ë§ëŠ”ì§€ ê¸°ìˆ ì ì¸ ê²€í† ë‚˜ ì œì•ˆ ë“±ì„ í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. \n",
    "ê²½ë¶êµìœ¡ì²­ì€ ì–´ë–¤ ì„œë¹„ìŠ¤ë¥¼ í™œìš©í•˜ê³  ìˆëŠ”ì§€ ì €í¬ê°€ ì°¸ê³ í•  ìˆ˜ ìˆìœ¼ë©´ ë”ìš± ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. )\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš” ê³¼ì¥ë‹˜,\n",
      "\n",
      "ì´ë©”ì¼ì˜ ì¤‘ìš”í•œ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. BASICê³¼ EXCLUSIVEì˜ ì£¼ìš” ì°¨ì´ì ì— ëŒ€í•œ ë¬¸ì˜:\n",
      "   - ë³´ì•ˆ ë¶€ë¶„ì—ì„œì˜ ì°¨ì´ì \n",
      "   - BASICì„ í™œìš©í•  ê²½ìš° ë³´ì•ˆì„±ì´ ë–¨ì–´ì§€ëŠ” ê¸°ìˆ ì´ ì ìš©ë˜ëŠ”ì§€ ì—¬ë¶€\n",
      "\n",
      "2. BASICê³¼ EXCLUSIVE í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ë¬¸ì˜:\n",
      "   - BASICê³¼ EXCLUSIVE ê°ê°ì˜ í™œìš© ì‚¬ë¡€\n",
      "   - ê°œì¸ì •ë³´ ì €ì¥ ì—¬ë¶€ì™€ ê´€ë ¨ëœ ìš”ì•½ ì„œë¹„ìŠ¤ì˜ ì‚¬ë¡€\n",
      "\n",
      "3. ê¸°ìˆ ì  ê²€í†  ë° ì œì•ˆ ìš”ì²­:\n",
      "   - ë„¤ì´ë²„ í´ë¼ìš°ë“œë¥¼ í™œìš©í•œ ê³¼ì œ ìš”ì•½ ì„œë¹„ìŠ¤ì—ì„œì˜ ê°œì¸ì •ë³´ í™œìš© ì—¬ë¶€\n",
      "   - ê³µê³µì¡´ í™œìš©ì˜ ì ì ˆì„±ì— ëŒ€í•œ ê¸°ìˆ ì  ê²€í†  ë° ì œì•ˆ\n",
      "\n",
      "4. ê²½ë¶êµìœ¡ì²­ì˜ ì„œë¹„ìŠ¤ í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ì°¸ê³  ìš”ì²­"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒì˜ ì´ë©”ì¼ ë‚´ìš©ì¤‘ ì¤‘ìš”í•œ ë‚´ìš©ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\\n\\n{email_conversation}\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "answer = chain.stream({\"email_conversation\": email_conversation})\n",
    "\n",
    "# ìš°ë¦¬ê°€ í‰ì†Œì— ì¼ë°˜ì ì¸ ë°©ë²•ìœ¼ë¡œ LLMì„ ì‚¬ìš©í•  ë•Œ ë°›ê²Œë˜ëŠ” ì‘ë‹µì˜ í˜•ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚¨\n",
    "output = stream_response(answer, return_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ì˜ ê²°ê³¼ë¬¼ì€, ìš°ë¦¬ê°€ ì¼ë°˜ì ìœ¼ë¡œ LLMì—(ChatGPT ë“±) ë©”ì¼ ìš”ì•½ì„ ìš”ì²­í•œ ê²½ìš° ë°›ì„ ìˆ˜ ìˆëŠ” ì‘ë‹µ í˜•íƒœì´ë‹¤.<br>\n",
    "í•˜ì§€ë§Œ, ìš”ì²­í•  ë•Œë§ˆë‹¤ ì‘ë‹µì˜ í˜•íƒœ(í˜•ì‹)ê°€ ë‹¬ë¼ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸ì—, ì• í”Œë¦¬ì¼€ì´ì…˜ ë°ì´í„°ë¡œ í™œìš©í•˜ê¸°ì—” ì–´ë ¤ì›€ì´ ìˆë‹¤.\n",
    "\n",
    "Pydanticì„ ì‚¬ìš©í•˜ì—¬ íŒŒì‹±í•˜ê²Œ ë˜ë©´, LLMì˜ ì‘ë‹µì„ ë¯¸ë¦¬ ì •ì˜í•´ë‘” êµ¬ì¡°ëŒ€ë¡œ ì¼ê´€ë˜ê²Œ(Json í˜•ì‹ìœ¼ë¡œ) ë°›ì„ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailSummary(BaseModel):\n",
    "    person: str = Field(description=\"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒ\", default=\"ë³´ë‚¸ì´ ë¯¸ìƒ\")\n",
    "    email: str = Field(description=\"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ\", default=\"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "    subject: str = Field(description=\"ë©”ì¼ ì œëª©\", default=\"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "    summary: str = Field(description=\"ë©”ì¼ ë³¸ë¬¸ì„ ìš”ì•½í•œ í…ìŠ¤íŠ¸\")\n",
    "    date: str = Field(description=\"ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰ëœ due date\", default=\"ê¸°í•œ ì—†ìŒ\")\n",
    "\n",
    "\n",
    "# PydanticOutputParser ìƒì„±\n",
    "parser = PydanticOutputParser(pydantic_object=EmailSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"person\": {\"default\": \"ë³´ë‚¸ì´ ë¯¸ìƒ\", \"description\": \"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒ\", \"title\": \"Person\", \"type\": \"string\"}, \"email\": {\"default\": \"ì•Œ ìˆ˜ ì—†ìŒ\", \"description\": \"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ\", \"title\": \"Email\", \"type\": \"string\"}, \"subject\": {\"default\": \"ì•Œ ìˆ˜ ì—†ìŒ\", \"description\": \"ë©”ì¼ ì œëª©\", \"title\": \"Subject\", \"type\": \"string\"}, \"summary\": {\"description\": \"ë©”ì¼ ë³¸ë¬¸ì„ ìš”ì•½í•œ í…ìŠ¤íŠ¸\", \"title\": \"Summary\", \"type\": \"string\"}, \"date\": {\"default\": \"ê¸°í•œ ì—†ìŒ\", \"description\": \"ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰ëœ due date\", \"title\": \"Date\", \"type\": \"string\"}}, \"required\": [\"summary\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# instruction ì„ ì¶œë ¥\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œë¶€ë¶„ë³€ìˆ˜(partial_variables)\n",
    "ê³ ì •ëœ ê°’(ë³€ê²½ë˜ì§€ ì•ŠëŠ” ê°’)ì„ ë¯¸ë¦¬ ì„¤ì •í•˜ëŠ” ê¸°ëŠ¥<br>\n",
    "ì‚¬ìš©ìê°€ ì…ë ¥í•  ë•Œë§ˆë‹¤ ë³€ê²½ë˜ëŠ” input_variablesì™€ êµ¬ë¶„í•˜ì—¬ í…œí”Œë¦¿ì„ ì„¤ì •í•œë‹¤.<br>\n",
    "\n",
    "ë§Œì•½, partial_variablesë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, format_instructions ì—­ì‹œ input_variablesì— í¬í•¨ë˜ì–´ì•¼ í•˜ë©°,<br>\n",
    "ì´ ê²½ìš° í”„ë¡¬í”„íŠ¸ë¥¼ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ format_instructions ê°’ì„ ë§¤ë²ˆ ì§ì ‘ ë„£ì–´ì£¼ì–´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "EMAIL CONVERSATION:\n",
    "{email_conversation}\n",
    "\n",
    "FORMAT:\n",
    "{format}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# format ì— PydanticOutputParserì˜ ë¶€ë¶„ í¬ë§·íŒ…(partial) ì¶”ê°€\n",
    "prompt = prompt.partial(format=parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"person\": {\"default\": \"ë³´ë‚¸ì´ ë¯¸ìƒ\", \"description\": \"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒ\", \"title\": \"Person\", \"type\": \"string\"}, \"email\": {\"default\": \"ì•Œ ìˆ˜ ì—†ìŒ\", \"description\": \"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë©”ì¼ ì£¼ì†Œ\", \"title\": \"Email\", \"type\": \"string\"}, \"subject\": {\"default\": \"ì•Œ ìˆ˜ ì—†ìŒ\", \"description\": \"ë©”ì¼ ì œëª©\", \"title\": \"Subject\", \"type\": \"string\"}, \"summary\": {\"description\": \"ë©”ì¼ ë³¸ë¬¸ì„ ìš”ì•½í•œ í…ìŠ¤íŠ¸\", \"title\": \"Summary\", \"type\": \"string\"}, \"date\": {\"default\": \"ê¸°í•œ ì—†ìŒ\", \"description\": \"ë©”ì¼ ë³¸ë¬¸ì— ì–¸ê¸‰ëœ due date\", \"title\": \"Date\", \"type\": \"string\"}}, \"required\": [\"summary\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ì „ë‹¬ë˜ëŠ” instruction ë‚´ìš© í™•ì¸í•´ë³´ê¸°\n",
    "# í˜•ì‹ ì§€ì‹œì‚¬í•­ì— ì•ì„œ ì •ì˜í•œ Classì˜ ë‚´ìš©ì´ ë°˜ì˜ë˜ì—ˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"person\": \"ë³´ë‚¸ì´ ë¯¸ìƒ\",\n",
      "    \"email\": \"ì•Œ ìˆ˜ ì—†ìŒ\",\n",
      "    \"subject\": \"ì•Œ ìˆ˜ ì—†ìŒ\",\n",
      "    \"summary\": \"ë³´ë‚¸ì´ëŠ” BASICê³¼ EXCLUSIVEì˜ ì£¼ìš” ì°¨ì´ì ì— ëŒ€í•´ ë¬¸ì˜í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ë³´ì•ˆì„± ì°¨ì´ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ BASICê³¼ EXCLUSIVEì˜ í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì²­í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê°œì¸ì •ë³´ ì €ì¥ ì—¬ë¶€ì™€ ê´€ë ¨ëœ ìš”ì•½ ì„œë¹„ìŠ¤ì˜ ê¸°ìˆ ì  ê²€í†  ë° ì œì•ˆë„ ìš”ì²­í•˜ê³  ìˆìœ¼ë©°, ê²½ë¶êµìœ¡ì²­ì˜ ì„œë¹„ìŠ¤ í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ì°¸ê³ ë¥¼ ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\n",
      "    \"date\": \"ê¸°í•œ ì—†ìŒ\"\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "response = chain.stream(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"ì´ë©”ì¼ ë‚´ìš©ì¤‘ ì£¼ìš” ë‚´ìš©ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ëŠ” JSON í˜•íƒœë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.\n",
    "output = stream_response(response, return_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person='ë³´ë‚¸ì´ ë¯¸ìƒ' email='ì•Œ ìˆ˜ ì—†ìŒ' subject='ì•Œ ìˆ˜ ì—†ìŒ' summary='ë³´ë‚¸ì´ëŠ” BASICê³¼ EXCLUSIVEì˜ ì£¼ìš” ì°¨ì´ì ì— ëŒ€í•´ ë¬¸ì˜í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ë³´ì•ˆì„± ì°¨ì´ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ BASICê³¼ EXCLUSIVEì˜ í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì²­í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê°œì¸ì •ë³´ ì €ì¥ ì—¬ë¶€ì™€ ê´€ë ¨ëœ ìš”ì•½ ì„œë¹„ìŠ¤ì˜ ê¸°ìˆ ì  ê²€í†  ë° ì œì•ˆë„ ìš”ì²­í•˜ê³  ìˆìœ¼ë©°, ê²½ë¶êµìœ¡ì²­ì˜ ì„œë¹„ìŠ¤ í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ì°¸ê³ ë¥¼ ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.' date='ê¸°í•œ ì—†ìŒ'\n"
     ]
    }
   ],
   "source": [
    "# PydanticOutputParser ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.\n",
    "structured_output = parser.parse(output)\n",
    "print(structured_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ íŒŒì„œë¥¼ ì¶”ê°€í•˜ì—¬ ì „ì²´ ì²´ì¸ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmailSummary(person='ë³´ë‚¸ì´ ë¯¸ìƒ', email='ì•Œ ìˆ˜ ì—†ìŒ', subject='ì•Œ ìˆ˜ ì—†ìŒ', summary='ì´ë©”ì¼ ë°œì‹ ìëŠ” BASICê³¼ EXCLUSIVEì˜ ì£¼ìš” ì°¨ì´ì ì— ëŒ€í•´ ë¬¸ì˜í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ë³´ì•ˆ ì¸¡ë©´ì—ì„œì˜ ì°¨ì´ë¥¼ ì•Œê³  ì‹¶ì–´í•©ë‹ˆë‹¤. ë˜í•œ BASICê³¼ EXCLUSIVEì˜ í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ì •ë³´ë¥¼ ìš”ì²­í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê°œì¸ì •ë³´ ì €ì¥ ì—¬ë¶€ì™€ ê´€ë ¨ëœ ìš”ì•½ ì„œë¹„ìŠ¤ì˜ ê¸°ìˆ ì  ê²€í†  ë° ì œì•ˆë„ í•„ìš”í•˜ë‹¤ê³  ì–¸ê¸‰í•˜ê³  ìˆìœ¼ë©°, ê²½ë¶êµìœ¡ì²­ì˜ í™œìš© ì‚¬ë¡€ì— ëŒ€í•œ ì°¸ê³ ë¥¼ ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.', date='ê¸°í•œ ì—†ìŒ')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"ì´ë©”ì¼ ë‚´ìš©ì¤‘ ì£¼ìš” ë‚´ìš©ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ëŠ” EmailSummary ê°ì²´ í˜•íƒœë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_structered = ChatOpenAI(\n",
    "    temperature=0, model_name=\"gpt-4o\"\n",
    ").with_structured_output(EmailSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:410: UserWarning: Invalid schema for OpenAI's structured output feature, which is the default method for `with_structured_output` as of langchain-openai==0.3. Specify `method=\"function_calling\"` instead or update your schema. See supported schemas: https://platform.openai.com/docs/guides/structured-outputs#supported-schemas\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'EmailSummary': In context=('properties', 'person'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[199]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# invoke() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# https://docs.pydantic.dev/latest/concepts/fields/#default-values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m answer = \u001b[43mllm_with_structered\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43memail_conversation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m answer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5358\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5353\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5354\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5355\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5356\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5357\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5358\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5359\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5360\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5361\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5362\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:903\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    901\u001b[39m         response = \u001b[38;5;28mself\u001b[39m.root_client.beta.chat.completions.parse(**payload)\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43m_handle_openai_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._use_responses_api(payload):\n\u001b[32m    905\u001b[39m     original_schema_obj = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:411\u001b[39m, in \u001b[36m_handle_openai_bad_request\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m    403\u001b[39m     message = (\n\u001b[32m    404\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid schema for OpenAI\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms structured output feature, which is the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    405\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdefault method for `with_structured_output` as of langchain-openai==0.3. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://platform.openai.com/docs/guides/structured-outputs#supported-schemas\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    409\u001b[39m     )\n\u001b[32m    410\u001b[39m     warnings.warn(message)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:901\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    899\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    900\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    903\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\openai\\_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         err.response.read()\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1026\u001b[39m     cast_to=cast_to,\n\u001b[32m   1027\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1031\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1032\u001b[39m )\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Invalid schema for response_format 'EmailSummary': In context=('properties', 'person'), 'default' is not permitted.\", 'type': 'invalid_request_error', 'param': 'response_format', 'code': None}}"
     ]
    }
   ],
   "source": [
    "# invoke() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "# https://docs.pydantic.dev/latest/concepts/fields/#default-values\n",
    "answer = llm_with_structered.invoke(email_conversation)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ02. CommaSeparatedListOutputParser\n",
    "\n",
    "ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í•­ëª© ëª©ë¡ì„ ë°˜í™˜í•  í•„ìš”ê°€ ìˆì„ ë•Œ ìœ ìš©í•œ íŒŒì„œ<br>\n",
    "ìš”ì²­í•œ ì •ë³´ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ê°„ê²°í•œ í˜•íƒœë¡œ ì œê³µë°›ì„ ìˆ˜ ìˆë‹¤. <br><br>\n",
    "\n",
    "### ğŸ¼ì˜ˆì‹œ\n",
    "* ëª¨ë¸ì´ ì¶œë ¥í•˜ëŠ” ë‹µë³€ : \"apple, grape, banana\"\n",
    "* CommaSeparatedListOutputParser ì‚¬ìš© ì‹œ : [\"apple\", \"grape\", \"banana\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸° -> get_format_instructionsëŠ” ëª¨ë¸ì—ê²Œ ì „ë‹¬í•  Instructionsë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œë§Œì•½, subject ê°€ fruits ë¼ë©´?\n",
    "\n",
    "ì•„ë˜ì™€ ê°™ì€ í”„ë¡¬í”„íŠ¸ê°€ êµ¬ì„±ëœë‹¤.\n",
    "\n",
    "```\n",
    "List five fruits.\n",
    "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz` \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    # ì£¼ì œì— ëŒ€í•œ ë‹¤ì„¯ ê°€ì§€ë¥¼ ë‚˜ì—´í•˜ë¼ëŠ” í…œí”Œë¦¿\n",
    "    # {subject} : ì‚¬ìš©ìê°€ ì…ë ¥í•  ì£¼ì œê°€ ë“¤ì–´ê°ˆ ìë¦¬\n",
    "    # {format_instructions} : ì•ì„œ ë°˜í™˜ëœ ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— í•¨ê»˜ ì œê³µ\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],  # ì…ë ¥ ë³€ìˆ˜ë¡œ 'subject' ì‚¬ìš©\n",
    "    # ë¶€ë¶„ ë³€ìˆ˜ë¡œ í˜•ì‹ ì§€ì¹¨ ì‚¬ìš©\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ìœµí”„ë¼ìš°', 'ì·¨ë¦¬íˆ', 'ë£¨ì²´ë¥¸', 'ì œë„¤ë°”', 'ë² ë¥¸']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"ìŠ¤ìœ„ìŠ¤ ê´€ê´‘ëª…ì†Œ\"ì— ëŒ€í•œ ì²´ì¸ í˜¸ì¶œ ì‹¤í–‰\n",
    "chain.invoke({\"subject\": \"ìŠ¤ìœ„ìŠ¤ ê´€ê´‘ëª…ì†Œ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ìœµí”„ë¼ìš°']\n",
      "['ì·¨ë¦¬íˆ']\n",
      "['ë£¨ì²´ë¥¸']\n",
      "['ì¸í„°ë¼ì¼„']\n",
      "['ì œë„¤ë°”']\n"
     ]
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¼ì„ ìˆœíšŒí•©ë‹ˆë‹¤.\n",
    "for s in chain.stream({\"subject\": \"ìŠ¤ìœ„ìŠ¤ ê´€ê´‘ëª…ì†Œ\"}):\n",
    "    print(s)  # ìŠ¤íŠ¸ë¦¼ì˜ ë‚´ìš©ì„ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ03. StructuredOutputParser\n",
    "LLMì˜ ì‘ë‹µì„ dict í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ key-value ìŒìœ¼ë¡œ ë°˜í™˜ë°›ì„ ìˆ˜ ìˆë‹¤.<br>\n",
    "`Pydantic/JSON` íŒŒì„œì˜ ê²½ìš° GPT ë“± ê°•ë ¥í•œ ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ê²½ìš° ë” ìœ ìš©í•˜ë©°, `StructuredOutputParser`ëŠ” <U>íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ë” ì ì€ ëª¨ë¸ì— ìœ ìš©</U>í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¼ResponseSchema í´ë˜ìŠ¤\n",
    "`StructuredOutputParser`ì˜ dict êµ¬ì¡°ì—ì„œ, key-value ìŒì— ê°ê° ì–´ë–¤ ê°’ë“¤ì´ ë“¤ì–´ê°€ì•¼ í•˜ëŠ”ì§€ ì •ì˜í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.<br>\n",
    "\n",
    "ì†ì„±\n",
    "* `name` : ì‘ë‹µ í•„ë“œì˜ ì´ë¦„(dict key)\n",
    "* `description` : ì‘ë‹µ í•„ë“œì— ëŒ€í•œ ì„¤ëª…(dict value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€\n",
    "\n",
    "'''\n",
    "ì‘ë‹µì˜ í˜•íƒœ\n",
    "{'answer' : '[ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€]', 'source' : '[ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•  ë•Œ ì‚¬ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ì£¼ì†Œ]'}\n",
    "'''\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€\"),\n",
    "    ResponseSchema(\n",
    "        name=\"source\",\n",
    "        description=\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ `ì¶œì²˜`, `ì›¹ì‚¬ì´íŠ¸ì£¼ì†Œ` ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.\",\n",
    "    ),\n",
    "]\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€\\n\\t\"source\": string  // ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ `ì¶œì²˜`, `ì›¹ì‚¬ì´íŠ¸ì£¼ì†Œ` ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.\\n}\\n```'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­ì„ íŒŒì‹±í•©ë‹ˆë‹¤.\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í”„ë¡¬í”„íŠ¸ í˜•íƒœ\n",
    "```\n",
    "answer the users question as best as possible.\n",
    "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€\\n\\t\"source\": string  // ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœ `ì¶œì²˜`, `ì›¹ì‚¬ì´íŠ¸ì£¼ì†Œ` ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.\\n}\\n```\n",
    "{ì‚¬ìš©ìì˜ ì§ˆë¬¸}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = PromptTemplate(\n",
    "    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìµœëŒ€í•œ ë‹µë³€í•˜ë„ë¡ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    # ì…ë ¥ ë³€ìˆ˜ë¡œ 'question'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    input_variables=[\"question\"],\n",
    "    # ë¶€ë¶„ ë³€ìˆ˜ë¡œ 'format_instructions'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)  # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "chain = prompt | model | output_parser  # í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'ìºë‚˜ë‹¤ì˜ ìˆ˜ë„ëŠ” ì˜¤íƒ€ì™€ì…ë‹ˆë‹¤.',\n",
       " 'source': 'https://ko.wikipedia.org/wiki/%EC%98%A4%ED%83%80%EC%99%80'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìºë‚˜ë‹¤ì˜ ìˆ˜ë„ê°€ ë¬´ì—‡ì¸ì§€ ì§ˆë¬¸í•©ë‹ˆë‹¤.\n",
    "chain.invoke({\"question\": \"ìºë‚˜ë‹¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'ì´ìˆœì‹ ì€ ì¡°ì„ ì‹œëŒ€ì˜ ë¬´ì‹  ì´ìˆœì‹  ì¥êµ°ìœ¼ë¡œì„œ, ì„ì§„ì™œë€ì—ì„œ ì¼ë³¸êµ°ì„ ë¬¼ë¦¬ì¹˜ê³  ì „ëµì  ìŠ¹ë¦¬ë¥¼ ê±°ë‘ì—ˆìŠµë‹ˆë‹¤.', 'source': 'https://ko.wikipedia.org/wiki/%EC%9D%B4%EC%88%9C%EC%8B%A0'}\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"ì´ìˆœì‹ ì˜ ì—…ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"}):\n",
    "    # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ04. JsonOutputParser\n",
    "ì‚¬ìš©ìê°€ ì›í•˜ëŠ” JSON ìŠ¤í‚¤ë§ˆë¥¼ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë©°, í•´ë‹¹ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ê²°ê³¼ë¥¼ ì¶œë ¥í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¼BaseModel\n",
    "`BaseModel`ì„ ìƒì†ë°›ì€ í´ë˜ìŠ¤ëŠ” ìë™ìœ¼ë¡œ ë°ì´í„° íƒ€ì… ê²€ì¦ ê¸°ëŠ¥ì„ ê°–ëŠ”ë‹¤.<br>\n",
    "ì•„ë˜ Topicì€ descriptionê³¼ hashtagsê°€ ë¬¸ìì—´(str) íƒ€ì…ì´ë¼ëŠ” ê·œì¹™ì„ ì •ì˜í•œ ê²ƒì´ë©°, ìë™ìœ¼ë¡œ íƒ€ì…ì´ ê²€ì¦ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›í•˜ëŠ” ë°ì´í„° êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class Topic(BaseModel):\n",
    "    description: str = Field(description=\"ì£¼ì œì— ëŒ€í•œ ê°„ê²°í•œ ì„¤ëª…\")\n",
    "    hashtags: str = Field(description=\"í•´ì‹œíƒœê·¸ í˜•ì‹ì˜ í‚¤ì›Œë“œ(2ê°œ ì´ìƒ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'ì§€êµ¬ ì˜¨ë‚œí™”ëŠ” ì§€êµ¬ì˜ í‰ê·  ê¸°ì˜¨ì´ ìƒìŠ¹í•˜ëŠ” í˜„ìƒìœ¼ë¡œ, ì£¼ë¡œ ì¸ê°„ í™œë™ì— ì˜í•´ ë°œìƒí•˜ëŠ” ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œì´ ì£¼ìš” ì›ì¸ì…ë‹ˆë‹¤. ì´ëŠ” ê·¹ì§€ë°©ì˜ ë¹™í•˜ ê°ì†Œ, í•´ìˆ˜ë©´ ìƒìŠ¹, ê¸°í›„ íŒ¨í„´ ë³€í™” ë“± ì‹¬ê°í•œ í™˜ê²½ì  ì˜í–¥ì„ ì´ˆë˜í•©ë‹ˆë‹¤.',\n",
       " 'hashtags': '#ì§€êµ¬ì˜¨ë‚œí™” #ê¸°í›„ë³€í™” #í™˜ê²½ë³´í˜¸'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì§ˆì˜ ì‘ì„±\n",
    "question = \"ì§€êµ¬ ì˜¨ë‚œí™”ì˜ ì‹¬ê°ì„± ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# íŒŒì„œë¥¼ ì„¤ì •í•˜ê³  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì§€ì‹œì‚¬í•­ì„ ì£¼ì…í•©ë‹ˆë‹¤.\n",
    "parser = JsonOutputParser(pydantic_object=Topic)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | model | parser  # ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "chain.invoke({\"question\": question})  # ì²´ì¸ì„ í˜¸ì¶œí•˜ì—¬ ì¿¼ë¦¬ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Email(BaseModel):\n",
    "    #send : str = Field(\"ë³´ë‚¸ì´ ë¯¸ìƒ\", description=\"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë¦„\")\n",
    "    send : str = Field(description=\"ë©”ì¼ì„ ë³´ë‚¸ ì‚¬ëŒì˜ ì´ë¦„\")\n",
    "    content: str = Field(description=\"ë©”ì¼ì˜ í•µì‹¬ ë‚´ìš©ì„ í•œì¤„ë¡œ ì •ë¦¬\")\n",
    "    receive: str = Field(description=\"ë©”ì¼ ë°›ì€ ì‚¬ëŒ ì´ë¦„\")\n",
    "    follow_up: str = Field(description=\"í•„ìš”í•œ í›„ì† ì¡°ì¹˜\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'send': 'ë³´ë‚¸ì´ ë¯¸ìƒ',\n",
       " 'content': 'ë„¤ì´ë²„í´ë¼ìš°ë“œí”Œë«í¼ì€ ì¥ë¹„ ì„¸íŒ… ì™„ë£Œ í›„ í„°ë„ë§ ìƒì„± ê°€ëŠ¥í•˜ë©°, Pre-Shared Keyì— íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš© ë¶ˆê°€.',\n",
       " 'receive': 'ê¹€ë¯¼ì„± ë§¤ë‹ˆì €',\n",
       " 'follow_up': 'ì¥ë¹„ ì„¸íŒ… ì™„ë£Œ í›„ ì—°ë½ ë° íŠ¹ìˆ˜ë¬¸ì ì—†ëŠ” Pre-Shared Key ì „ë‹¬, íŠ¹ì • ì„œë²„ ì„œë¸Œë„· IP ëŒ€ì—­ í™•ì¸ ìš”ì²­.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì§ˆì˜ ì‘ì„±\n",
    "question = \"\"\" \n",
    "\n",
    "ì•ˆë…•í•˜ì„¸ìš”. ê¹€ë¯¼ì„± ë§¤ë‹ˆì €ë‹˜.\n",
    "êµ¿ì–´ìŠ¤ë°ì´í„° ì§„ì¬ì˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë„¤ì´ë²„í´ë¼ìš°ë“œí”Œë«í¼ì€ ì¥ë¹„ ì„¸íŒ… ì™„ë£Œ ì´ì „ì— í„°ë„ë§ì„ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.\n",
    "ë”°ë¼ì„œ, 13ì‹œì— ë³¸ì‚¬ ì¥ë¹„ ì„¸íŒ… ì™„ë£Œí•˜ì‹  í›„ ì—°ë½ ì£¼ì‹œë©´ í„°ë„ë§ ìƒì„± ì§„í–‰í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ, ë¯¼ê°„ì¡´ IPSec VPN Pre-Shared Keyì—ëŠ” íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš©ì´ ë¶ˆê°€í•©ë‹ˆë‹¤. \n",
    "ë”°ë¼ì„œ íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ë˜ì§€ ì•Šì€ Pre-Shared Key ì „ë‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "[ì‚´ë£¨ìŠ¤ì¼€ì–´ NCP IP ì •ë³´]\n",
    "VPC : 10.0.0.0/16\n",
    "IPSec VPN Gateway : 175.106.107.89\n",
    "\n",
    "ì¶”ê°€ë¡œ, IPSec VPN ì—°ë™í•˜ì‹œê³ ì í•˜ëŠ” íŠ¹ì • ì„œë²„(ì„œë¸Œë„·)ê°€ ìˆìœ¼ì‹ ì§€ í™•ì¸ ìš”ì²­ë“œë¦½ë‹ˆë‹¤.\n",
    "ìš°ì„  ì „ì²´ VPC ëŒ€ì—­ìœ¼ë¡œ ì „ë‹¬ë“œë¦¬ì˜¤ë‚˜, íŠ¹ì • ì„œë²„ì— ëŒ€í•´ì„œë§Œ ì—°ë™ì„ ì›í•˜ì‹ ë‹¤ë©´, í•´ë‹¹ ì„œë¸Œë„· IP ëŒ€ì—­ìœ¼ë¡œ ë‹¤ì‹œ ì „ë‹¬ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. \n",
    "\n",
    "í™•ì¸ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "ê°ì‚¬í•©ë‹ˆë‹¤.\n",
    "ì§„ì¬ì˜ ë“œë¦¼\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# íŒŒì„œë¥¼ ì„¤ì •í•˜ê³  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì§€ì‹œì‚¬í•­ì„ ì£¼ì…í•©ë‹ˆë‹¤.\n",
    "parser = JsonOutputParser(pydantic_object=Email)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë©”ì¼ì„ í˜•ì‹ì— ë§ê²Œ ìš”ì•½í•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "chain = prompt | model | parser  # ì²´ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "chain.invoke({\"question\": question})  # ì²´ì¸ì„ í˜¸ì¶œí•˜ì—¬ ì¿¼ë¦¬ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ05. PandasDataFrameOutputParser\n",
    "Pandas Dataframeì€ Pythonìœ¼ë¡œ 2ì°¨ì› ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ ì‚¬ìš©ë˜ëŠ”ë°, <br>\n",
    "PandasDataFrameOutputParserë¥¼ ì‚¬ìš©í•˜ë©´ ë°ì´í„°í”„ë ˆì„ì—ì„œ ë°ì´í„°ë¥¼ ë½‘ì•„ ì •ë¦¬ëœ í˜•íƒœë¡œ ë³¼ ìˆ˜ ìˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from typing import Any, Dict\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns # ì˜ˆì‹œ ë°ì´í„°ì…‹ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ìš©ë„\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™” (gpt-3.5-turbo ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤)\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "def format_parser_output(parser_output: Dict[str, Any]) -> None:\n",
    "    # íŒŒì„œ ì¶œë ¥ì˜ í‚¤ë“¤ì„ ìˆœíšŒí•©ë‹ˆë‹¤.\n",
    "    for key in parser_output.keys():\n",
    "        # ê° í‚¤ì˜ ê°’ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        parser_output[key] = parser_output[key].to_dict()\n",
    "    # ì˜ˆì˜ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "    return pprint.PrettyPrinter(width=4, compact=True).pprint(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'penguins' ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "df = sns.load_dataset('penguins')\n",
    "df.head()\n",
    "\n",
    "# í­ê·„ì˜ ì¢… / ì„œì‹í•˜ëŠ” ì„¬ / ë¶€ë¦¬ ê¸¸ì´ / ë¶€ë¦¬ ê¹Šì´ / ë‚ ê°œ ê¸¸ì´ / ì²´ì¤‘ / ì„±ë³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\n",
      "1. The column names are limited to the possible columns below.\n",
      "2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\n",
      "3. Remember that arrays are optional and not necessarily required.\n",
      "4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\n",
      "\n",
      "As an example, for the formats:\n",
      "1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\n",
      "2. String \"row:1\" is a well-formatted instance which gets row 1.\n",
      "3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\n",
      "4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\n",
      "5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\n",
      "6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\n",
      "7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\n",
      "\n",
      "Here are the possible columns:\n",
      "```\n",
      "species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì„œë¥¼ ì„¤ì •í•˜ê³  í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì§€ì‹œì‚¬í•­ì„ ì£¼ì…í•©ë‹ˆë‹¤.\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# íŒŒì„œì˜ ì§€ì‹œì‚¬í•­ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'island': {0: 'Torgersen',\n",
      "            1: 'Torgersen',\n",
      "            2: 'Torgersen',\n",
      "            3: 'Torgersen',\n",
      "            4: 'Torgersen',\n",
      "            5: 'Torgersen',\n",
      "            6: 'Torgersen',\n",
      "            7: 'Torgersen',\n",
      "            8: 'Torgersen',\n",
      "            9: 'Torgersen',\n",
      "            10: 'Torgersen',\n",
      "            11: 'Torgersen',\n",
      "            12: 'Torgersen',\n",
      "            13: 'Torgersen',\n",
      "            14: 'Torgersen',\n",
      "            15: 'Torgersen',\n",
      "            16: 'Torgersen',\n",
      "            17: 'Torgersen',\n",
      "            18: 'Torgersen',\n",
      "            19: 'Torgersen',\n",
      "            20: 'Biscoe',\n",
      "            21: 'Biscoe',\n",
      "            22: 'Biscoe',\n",
      "            23: 'Biscoe',\n",
      "            24: 'Biscoe',\n",
      "            25: 'Biscoe',\n",
      "            26: 'Biscoe',\n",
      "            27: 'Biscoe',\n",
      "            28: 'Biscoe',\n",
      "            29: 'Biscoe',\n",
      "            30: 'Dream',\n",
      "            31: 'Dream',\n",
      "            32: 'Dream',\n",
      "            33: 'Dream',\n",
      "            34: 'Dream',\n",
      "            35: 'Dream',\n",
      "            36: 'Dream',\n",
      "            37: 'Dream',\n",
      "            38: 'Dream',\n",
      "            39: 'Dream',\n",
      "            40: 'Dream',\n",
      "            41: 'Dream',\n",
      "            42: 'Dream',\n",
      "            43: 'Dream',\n",
      "            44: 'Dream',\n",
      "            45: 'Dream',\n",
      "            46: 'Dream',\n",
      "            47: 'Dream',\n",
      "            48: 'Dream',\n",
      "            49: 'Dream',\n",
      "            50: 'Biscoe',\n",
      "            51: 'Biscoe',\n",
      "            52: 'Biscoe',\n",
      "            53: 'Biscoe',\n",
      "            54: 'Biscoe',\n",
      "            55: 'Biscoe',\n",
      "            56: 'Biscoe',\n",
      "            57: 'Biscoe',\n",
      "            58: 'Biscoe',\n",
      "            59: 'Biscoe',\n",
      "            60: 'Biscoe',\n",
      "            61: 'Biscoe',\n",
      "            62: 'Biscoe',\n",
      "            63: 'Biscoe',\n",
      "            64: 'Biscoe',\n",
      "            65: 'Biscoe',\n",
      "            66: 'Biscoe',\n",
      "            67: 'Biscoe',\n",
      "            68: 'Torgersen',\n",
      "            69: 'Torgersen',\n",
      "            70: 'Torgersen',\n",
      "            71: 'Torgersen',\n",
      "            72: 'Torgersen',\n",
      "            73: 'Torgersen',\n",
      "            74: 'Torgersen',\n",
      "            75: 'Torgersen',\n",
      "            76: 'Torgersen',\n",
      "            77: 'Torgersen',\n",
      "            78: 'Torgersen',\n",
      "            79: 'Torgersen',\n",
      "            80: 'Torgersen',\n",
      "            81: 'Torgersen',\n",
      "            82: 'Torgersen',\n",
      "            83: 'Torgersen',\n",
      "            84: 'Dream',\n",
      "            85: 'Dream',\n",
      "            86: 'Dream',\n",
      "            87: 'Dream',\n",
      "            88: 'Dream',\n",
      "            89: 'Dream',\n",
      "            90: 'Dream',\n",
      "            91: 'Dream',\n",
      "            92: 'Dream',\n",
      "            93: 'Dream',\n",
      "            94: 'Dream',\n",
      "            95: 'Dream',\n",
      "            96: 'Dream',\n",
      "            97: 'Dream',\n",
      "            98: 'Dream',\n",
      "            99: 'Dream',\n",
      "            100: 'Biscoe',\n",
      "            101: 'Biscoe',\n",
      "            102: 'Biscoe',\n",
      "            103: 'Biscoe',\n",
      "            104: 'Biscoe',\n",
      "            105: 'Biscoe',\n",
      "            106: 'Biscoe',\n",
      "            107: 'Biscoe',\n",
      "            108: 'Biscoe',\n",
      "            109: 'Biscoe',\n",
      "            110: 'Biscoe',\n",
      "            111: 'Biscoe',\n",
      "            112: 'Biscoe',\n",
      "            113: 'Biscoe',\n",
      "            114: 'Biscoe',\n",
      "            115: 'Biscoe',\n",
      "            116: 'Torgersen',\n",
      "            117: 'Torgersen',\n",
      "            118: 'Torgersen',\n",
      "            119: 'Torgersen',\n",
      "            120: 'Torgersen',\n",
      "            121: 'Torgersen',\n",
      "            122: 'Torgersen',\n",
      "            123: 'Torgersen',\n",
      "            124: 'Torgersen',\n",
      "            125: 'Torgersen',\n",
      "            126: 'Torgersen',\n",
      "            127: 'Torgersen',\n",
      "            128: 'Torgersen',\n",
      "            129: 'Torgersen',\n",
      "            130: 'Torgersen',\n",
      "            131: 'Torgersen',\n",
      "            132: 'Dream',\n",
      "            133: 'Dream',\n",
      "            134: 'Dream',\n",
      "            135: 'Dream',\n",
      "            136: 'Dream',\n",
      "            137: 'Dream',\n",
      "            138: 'Dream',\n",
      "            139: 'Dream',\n",
      "            140: 'Dream',\n",
      "            141: 'Dream',\n",
      "            142: 'Dream',\n",
      "            143: 'Dream',\n",
      "            144: 'Dream',\n",
      "            145: 'Dream',\n",
      "            146: 'Dream',\n",
      "            147: 'Dream',\n",
      "            148: 'Dream',\n",
      "            149: 'Dream',\n",
      "            150: 'Dream',\n",
      "            151: 'Dream',\n",
      "            152: 'Dream',\n",
      "            153: 'Dream',\n",
      "            154: 'Dream',\n",
      "            155: 'Dream',\n",
      "            156: 'Dream',\n",
      "            157: 'Dream',\n",
      "            158: 'Dream',\n",
      "            159: 'Dream',\n",
      "            160: 'Dream',\n",
      "            161: 'Dream',\n",
      "            162: 'Dream',\n",
      "            163: 'Dream',\n",
      "            164: 'Dream',\n",
      "            165: 'Dream',\n",
      "            166: 'Dream',\n",
      "            167: 'Dream',\n",
      "            168: 'Dream',\n",
      "            169: 'Dream',\n",
      "            170: 'Dream',\n",
      "            171: 'Dream',\n",
      "            172: 'Dream',\n",
      "            173: 'Dream',\n",
      "            174: 'Dream',\n",
      "            175: 'Dream',\n",
      "            176: 'Dream',\n",
      "            177: 'Dream',\n",
      "            178: 'Dream',\n",
      "            179: 'Dream',\n",
      "            180: 'Dream',\n",
      "            181: 'Dream',\n",
      "            182: 'Dream',\n",
      "            183: 'Dream',\n",
      "            184: 'Dream',\n",
      "            185: 'Dream',\n",
      "            186: 'Dream',\n",
      "            187: 'Dream',\n",
      "            188: 'Dream',\n",
      "            189: 'Dream',\n",
      "            190: 'Dream',\n",
      "            191: 'Dream',\n",
      "            192: 'Dream',\n",
      "            193: 'Dream',\n",
      "            194: 'Dream',\n",
      "            195: 'Dream',\n",
      "            196: 'Dream',\n",
      "            197: 'Dream',\n",
      "            198: 'Dream',\n",
      "            199: 'Dream',\n",
      "            200: 'Dream',\n",
      "            201: 'Dream',\n",
      "            202: 'Dream',\n",
      "            203: 'Dream',\n",
      "            204: 'Dream',\n",
      "            205: 'Dream',\n",
      "            206: 'Dream',\n",
      "            207: 'Dream',\n",
      "            208: 'Dream',\n",
      "            209: 'Dream',\n",
      "            210: 'Dream',\n",
      "            211: 'Dream',\n",
      "            212: 'Dream',\n",
      "            213: 'Dream',\n",
      "            214: 'Dream',\n",
      "            215: 'Dream',\n",
      "            216: 'Dream',\n",
      "            217: 'Dream',\n",
      "            218: 'Dream',\n",
      "            219: 'Dream',\n",
      "            220: 'Biscoe',\n",
      "            221: 'Biscoe',\n",
      "            222: 'Biscoe',\n",
      "            223: 'Biscoe',\n",
      "            224: 'Biscoe',\n",
      "            225: 'Biscoe',\n",
      "            226: 'Biscoe',\n",
      "            227: 'Biscoe',\n",
      "            228: 'Biscoe',\n",
      "            229: 'Biscoe',\n",
      "            230: 'Biscoe',\n",
      "            231: 'Biscoe',\n",
      "            232: 'Biscoe',\n",
      "            233: 'Biscoe',\n",
      "            234: 'Biscoe',\n",
      "            235: 'Biscoe',\n",
      "            236: 'Biscoe',\n",
      "            237: 'Biscoe',\n",
      "            238: 'Biscoe',\n",
      "            239: 'Biscoe',\n",
      "            240: 'Biscoe',\n",
      "            241: 'Biscoe',\n",
      "            242: 'Biscoe',\n",
      "            243: 'Biscoe',\n",
      "            244: 'Biscoe',\n",
      "            245: 'Biscoe',\n",
      "            246: 'Biscoe',\n",
      "            247: 'Biscoe',\n",
      "            248: 'Biscoe',\n",
      "            249: 'Biscoe',\n",
      "            250: 'Biscoe',\n",
      "            251: 'Biscoe',\n",
      "            252: 'Biscoe',\n",
      "            253: 'Biscoe',\n",
      "            254: 'Biscoe',\n",
      "            255: 'Biscoe',\n",
      "            256: 'Biscoe',\n",
      "            257: 'Biscoe',\n",
      "            258: 'Biscoe',\n",
      "            259: 'Biscoe',\n",
      "            260: 'Biscoe',\n",
      "            261: 'Biscoe',\n",
      "            262: 'Biscoe',\n",
      "            263: 'Biscoe',\n",
      "            264: 'Biscoe',\n",
      "            265: 'Biscoe',\n",
      "            266: 'Biscoe',\n",
      "            267: 'Biscoe',\n",
      "            268: 'Biscoe',\n",
      "            269: 'Biscoe',\n",
      "            270: 'Biscoe',\n",
      "            271: 'Biscoe',\n",
      "            272: 'Biscoe',\n",
      "            273: 'Biscoe',\n",
      "            274: 'Biscoe',\n",
      "            275: 'Biscoe',\n",
      "            276: 'Biscoe',\n",
      "            277: 'Biscoe',\n",
      "            278: 'Biscoe',\n",
      "            279: 'Biscoe',\n",
      "            280: 'Biscoe',\n",
      "            281: 'Biscoe',\n",
      "            282: 'Biscoe',\n",
      "            283: 'Biscoe',\n",
      "            284: 'Biscoe',\n",
      "            285: 'Biscoe',\n",
      "            286: 'Biscoe',\n",
      "            287: 'Biscoe',\n",
      "            288: 'Biscoe',\n",
      "            289: 'Biscoe',\n",
      "            290: 'Biscoe',\n",
      "            291: 'Biscoe',\n",
      "            292: 'Biscoe',\n",
      "            293: 'Biscoe',\n",
      "            294: 'Biscoe',\n",
      "            295: 'Biscoe',\n",
      "            296: 'Biscoe',\n",
      "            297: 'Biscoe',\n",
      "            298: 'Biscoe',\n",
      "            299: 'Biscoe',\n",
      "            300: 'Biscoe',\n",
      "            301: 'Biscoe',\n",
      "            302: 'Biscoe',\n",
      "            303: 'Biscoe',\n",
      "            304: 'Biscoe',\n",
      "            305: 'Biscoe',\n",
      "            306: 'Biscoe',\n",
      "            307: 'Biscoe',\n",
      "            308: 'Biscoe',\n",
      "            309: 'Biscoe',\n",
      "            310: 'Biscoe',\n",
      "            311: 'Biscoe',\n",
      "            312: 'Biscoe',\n",
      "            313: 'Biscoe',\n",
      "            314: 'Biscoe',\n",
      "            315: 'Biscoe',\n",
      "            316: 'Biscoe',\n",
      "            317: 'Biscoe',\n",
      "            318: 'Biscoe',\n",
      "            319: 'Biscoe',\n",
      "            320: 'Biscoe',\n",
      "            321: 'Biscoe',\n",
      "            322: 'Biscoe',\n",
      "            323: 'Biscoe',\n",
      "            324: 'Biscoe',\n",
      "            325: 'Biscoe',\n",
      "            326: 'Biscoe',\n",
      "            327: 'Biscoe',\n",
      "            328: 'Biscoe',\n",
      "            329: 'Biscoe',\n",
      "            330: 'Biscoe',\n",
      "            331: 'Biscoe',\n",
      "            332: 'Biscoe',\n",
      "            333: 'Biscoe',\n",
      "            334: 'Biscoe',\n",
      "            335: 'Biscoe',\n",
      "            336: 'Biscoe',\n",
      "            337: 'Biscoe',\n",
      "            338: 'Biscoe',\n",
      "            339: 'Biscoe',\n",
      "            340: 'Biscoe',\n",
      "            341: 'Biscoe',\n",
      "            342: 'Biscoe',\n",
      "            343: 'Biscoe'}}\n"
     ]
    }
   ],
   "source": [
    "# ì—´ ì‘ì—… ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
    "df_query = \"island column ì„ ì¡°íšŒí•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],  # ì…ë ¥ ë³€ìˆ˜ ì„¤ì •\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    },  # ë¶€ë¶„ ë³€ìˆ˜ ì„¤ì •\n",
    ")\n",
    "\n",
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# ì¶œë ¥\n",
    "format_parser_output(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'bill_depth_mm': 18.7,\n",
      "       'bill_length_mm': 39.1,\n",
      "       'body_mass_g': 3750.0,\n",
      "       'flipper_length_mm': 181.0,\n",
      "       'island': 'Torgersen',\n",
      "       'sex': 'Male',\n",
      "       'species': 'Adelie'}}\n"
     ]
    }
   ],
   "source": [
    "# í–‰ ì¡°íšŒ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
    "# df_query = \"Retrieve the first row.\"\n",
    "df_query = \"0ë²ˆì§¸ í–‰ ì¶œë ¥\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "format_parser_output(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3562.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_mass_g'].head().mean()\n",
    "#print(df['body_mass_g'].iloc[:5].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 3562.5}\n"
     ]
    }
   ],
   "source": [
    "# ì„ì˜ì˜ Pandas DataFrame ì‘ì—… ì˜ˆì‹œ, í–‰ì˜ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n",
    "df_query = \"Retrieve the average of the body_mass_g from row 0 to 4.\" \n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 4201.754385964912}\n"
     ]
    }
   ],
   "source": [
    "#df_query = \"Calculate average body_mass_g rate\" # **ì¤‘ìš”í•œì  : ì˜¬ë°”ë¥´ê²Œ í˜•ì‹í™”ëœ, ëª…í™•í•œ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”!!\n",
    "df_query = \"Calculate the average of the 'body_mass_g' column.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "parser_output = chain.invoke({\"query\": df_query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(parser_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4201.754385964912"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_mass_g'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ06. DatetimeOutputParser\n",
    "LLMì˜ ì¶œë ¥ì„ `datetime` í˜•ì‹ìœ¼ë¡œ íŒŒì‹±í•˜ëŠ”ë° í™œìš© ê°€ëŠ¥\n",
    "\n",
    "### ğŸ¼ë‚ ì§œ ë° ì‹œê°„ í˜•ì‹ ì½”ë“œ\n",
    "\n",
    "| í˜•ì‹ ì½”ë“œ | ì„¤ëª…               | ì˜ˆì‹œ                     |\n",
    "|----------|------------------|-------------------------|\n",
    "| `%Y`     | 4ìë¦¬ ì—°ë„        | `2024`                  |\n",
    "| `%y`     | 2ìë¦¬ ì—°ë„        | `24`                    |\n",
    "| `%m`     | 2ìë¦¬ ì›”          | `07`                    |\n",
    "| `%d`     | 2ìë¦¬ ì¼          | `04`                    |\n",
    "| `%H`     | 24ì‹œê°„ì œ ì‹œê°„     | `14`                    |\n",
    "| `%I`     | 12ì‹œê°„ì œ ì‹œê°„     | `02`                    |\n",
    "| `%p`     | AM ë˜ëŠ” PM       | `PM`                    |\n",
    "| `%M`     | 2ìë¦¬ ë¶„          | `45`                    |\n",
    "| `%S`     | 2ìë¦¬ ì´ˆ          | `08`                    |\n",
    "| `%f`     | ë§ˆì´í¬ë¡œì´ˆ (6ìë¦¬) | `000123`                |\n",
    "| `%z`     | UTC ì˜¤í”„ì…‹        | `+0900`                 |\n",
    "| `%Z`     | ì‹œê°„ëŒ€ ì´ë¦„       | `KST`                    |\n",
    "| `%a`     | ìš”ì¼ ì•½ì–´         | `Thu`                   |\n",
    "| `%A`     | ìš”ì¼ ì „ì²´         | `Thursday`              |\n",
    "| `%b`     | ì›” ì•½ì–´           | `Jul`                   |\n",
    "| `%B`     | ì›” ì „ì²´           | `July`                  |\n",
    "| `%c`     | ì „ì²´ ë‚ ì§œì™€ ì‹œê°„  | `Thu Jul 4 14:45:08 2024` |\n",
    "| `%x`     | ì „ì²´ ë‚ ì§œ         | `07/04/24`              |\n",
    "| `%X`     | ì „ì²´ ì‹œê°„         | `14:45:08`              |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚ ì§œ ë° ì‹œê°„ ì¶œë ¥ íŒŒì„œ\n",
    "output_parser = DatetimeOutputParser()\n",
    "output_parser.format = \"%Y-%m-%d\"\n",
    "#output_parser.format = \"%c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%d'.\\n\\nExamples: 1562-10-11, 0602-12-21, 1650-11-06\\n\\nReturn ONLY this string, no other words!\"}, template='Answer the users question:\\n\\n#Format Instructions: \\n{format_instructions}\\n\\n#Question: \\n{question}\\n\\n#Answer:')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ í…œí”Œë¦¿\n",
    "template = \"\"\"Answer the users question:\\n\\n#Format Instructions: \\n{format_instructions}\\n\\n#Question: \\n{question}\\n\\n#Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\n",
    "        \"format_instructions\": output_parser.get_format_instructions()\n",
    "    },  # ì§€ì¹¨ì„ í…œí”Œë¦¿ì— ì ìš©\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ì¶œë ¥\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "chain = prompt | ChatOpenAI() | output_parser\n",
    "\n",
    "# ì²´ì¸ì„ í˜¸ì¶œí•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "output = chain.invoke({\"question\": \"Google ì´ ì°½ì—…í•œ ì—°ë„ëŠ”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1998, 9, 4, 0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datetime ê°ì²´ í˜•íƒœë¡œ ì¶œë ¥ë¨\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1998-09-04'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "output.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ07. EnumOutputParser\n",
    "LLMì˜ ì‘ë‹µ ê°’ì„ ì œí•œëœ ë²”ìœ„ ì•ˆì—ì„œë§Œ í—ˆìš©í•˜ë„ë¡ ì„¤ì •í•˜ëŠ” ë°ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” íŒŒì„œì´ë‹¤.<br>\n",
    "ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µê°’ì„ ë°©ì§€í•˜ëŠ” ë°ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤.<br>\n",
    "(ex. Y/Në¡œ ëŒ€ë‹µí•´ì•¼ í•˜ëŠ” ê²½ìš°, Taskì˜ ì§„í–‰ìƒíƒœ(ì„±ê³µ, ì‹¤íŒ¨, ì§„í–‰ì¤‘)ë¥¼ ì¶œë ¥í•´ì•¼ í•˜ëŠ” ê²½ìš° ë“±)\n",
    "\n",
    "### ğŸ¼Enum?\n",
    "Enumeration(ì—´ê±°í˜•)ì´ë€, ì„œë¡œ ê´€ë ¨ìˆëŠ” ì—¬ëŸ¬ ê°œì˜ ìƒìˆ˜ ì§‘í•©ì„ ì •ì˜í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“ˆì´ë‹¤.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.enum import EnumOutputParser\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colors(Enum):\n",
    "    RED = \"ë¹¨ê°„ìƒ‰\"\n",
    "    GREEN = \"ì´ˆë¡ìƒ‰\"\n",
    "    BLUE = \"íŒŒë€ìƒ‰\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enum 'Colors'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Colors.BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnumOutputParser ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "parser = EnumOutputParser(enum=Colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"ë‹¤ìŒì˜ ë¬¼ì²´ëŠ” ì–´ë–¤ ìƒ‰ê¹”ì¸ê°€ìš”?\n",
    "\n",
    "Object: {object}\n",
    "\n",
    "Instructions: {instructions}\"\"\"\n",
    "    # íŒŒì„œì—ì„œ ì§€ì‹œì‚¬í•­ í˜•ì‹ì„ ê°€ì ¸ì™€ ë¶€ë¶„ì ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.\n",
    ").partial(instructions=parser.get_format_instructions())\n",
    "# í”„ë¡¬í”„íŠ¸ì™€ ChatOpenAI, íŒŒì„œë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "chain = prompt | ChatOpenAI() | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colors.BLUE\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"í•˜ëŠ˜\"})  # \"í•˜ëŠ˜\" ì— ëŒ€í•œ ì²´ì¸ í˜¸ì¶œ ì‹¤í–‰\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜ë‹¤ë¥¸ ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviews(Enum):\n",
    "    POSITIVE = \"ëŒ€ì²´ë¡œ ê¸ì •ì \"\n",
    "    NEUTRAL = \"í˜¸ë¶ˆí˜¸ê°€ ê°ˆë¦¼\"\n",
    "    NEGATIVE = \"ëŒ€ì²´ë¡œ ë¶€ì •ì \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EnumOutputParser ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "parser = EnumOutputParser(enum=Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"ë‹¤ìŒ ì˜í™”ì˜ í‰ì ì€ ì–´ë–¤ê°€ìš”?\n",
    "\n",
    "Object: {object}\n",
    "\n",
    "Instructions: {instructions}\"\"\"\n",
    "    # íŒŒì„œì—ì„œ ì§€ì‹œì‚¬í•­ í˜•ì‹ì„ ê°€ì ¸ì™€ ë¶€ë¶„ì ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.\n",
    ").partial(instructions=parser.get_format_instructions())\n",
    "# í”„ë¡¬í”„íŠ¸ì™€ ChatOpenAI, íŒŒì„œë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "chain = prompt | ChatOpenAI() | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews.POSITIVE\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"The Shawshank Redemption\"})  # ì‡¼ìƒí¬ íƒˆì¶œ\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews.NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"Eternals\"})  # ì´í„°ë„ìŠ¤\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews.NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"object\": \"Mars Needs Moms\"})  # í™”ì„±ì€ ì—„ë§ˆê°€ í•„ìš”í•´(2011)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ08. OutputFixingParser\n",
    "ì¶œë ¥ íŒŒì‹± ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì˜¤ë¥˜ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.<br>\n",
    "íŒŒì„œê°€ ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” í˜•ì‹ì´ë‚˜ ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš°, LLMì„ ì¶”ê°€ì ìœ¼ë¡œ í˜¸ì¶œí•˜ì—¬ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´, ì²« ë²ˆì§¸ ê²°ê³¼ì—ì„œ ì •ì˜ëœ ìŠ¤í‚¤ë§ˆë¥¼ ì¤€ìˆ˜í•˜ì§€ ì•ŠëŠ” ê²°ê³¼ê°€ ë„ì¶œë  ê²½ìš°,<br>\n",
    "`OutputFixingParser`ê°€ ìë™ìœ¼ë¡œ ì¶œë ¥ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŒì„ ì¸ì‹í•˜ê³  ì´ë¥¼ ìˆ˜ì •í•˜ê¸° ìœ„í•œ ë‚´ìš©ì„ ì¶”ê°€í•˜ì—¬ LLMì— ë‹¤ì‹œ ì‘ë‹µì„ ìš”ì²­í•œë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.output_parsers import OutputFixingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(\n",
    "        description=\"list of names of films they starred in\")\n",
    "\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:83\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:145\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    144\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:161\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:119\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[129]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m misformatted = \u001b[33m\"\u001b[39m\u001b[33m{\u001b[39m\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mTom Hanks\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfilm_names\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: [\u001b[39m\u001b[33m'\u001b[39m\u001b[33mForrest Gump\u001b[39m\u001b[33m'\u001b[39m\u001b[33m]}\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# ì˜ëª»ëœ í˜•ì‹ìœ¼ë¡œ ì…ë ¥ëœ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ë ¤ê³  ì‹œë„\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmisformatted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ì˜¤ë¥˜ ì¶œë ¥\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:83\u001b[39m, in \u001b[36mPydanticOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> TBaseModel:\n\u001b[32m     75\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m        The parsed pydantic object.\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:97\u001b[39m, in \u001b[36mJsonOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m     89\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a JSON object.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m        The parsed JSON object.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:67\u001b[39m, in \u001b[36mPydanticOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the result of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m \u001b[33;03m    The parsed pydantic object.\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     json_object = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_obj(json_object)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:86\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     85\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "# ì˜ëª»ëœ í˜•ì‹ì„ ì¼ë¶€ëŸ¬ ì…ë ¥\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"\n",
    "\n",
    "# ì˜ëª»ëœ í˜•ì‹ìœ¼ë¡œ ì…ë ¥ëœ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ë ¤ê³  ì‹œë„\n",
    "parser.parse(misformatted)\n",
    "\n",
    "# ì˜¤ë¥˜ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì˜ëª»ëœ í˜•ì‹ì˜ ì¶œë ¥\n",
    "misformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'instructions'}.  Expected: ['completion', 'error', 'instructions'] Received: ['completion', 'error']\\nNote: if you intended {instructions} to be part of the string and not a variable, please escape it with double curly braces like: '{{instructions}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:83\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:145\u001b[39m, in \u001b[36mparse_json_markdown\u001b[39m\u001b[34m(json_string, parser)\u001b[39m\n\u001b[32m    144\u001b[39m     json_str = json_string \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m match.group(\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:161\u001b[39m, in \u001b[36m_parse_json\u001b[39m\u001b[34m(json_str, parser)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\utils\\json.py:119\u001b[39m, in \u001b[36mparse_partial_json\u001b[39m\u001b[34m(s, strict)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# If we got here, we ran out of characters to remove\u001b[39;00m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# and still couldn't parse the string as JSON, so return the parse error\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# for the original string.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:359\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    358\u001b[39m     kw[\u001b[33m'\u001b[39m\u001b[33mparse_constant\u001b[39m\u001b[33m'\u001b[39m] = parse_constant\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOutputParserException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:70\u001b[39m, in \u001b[36mOutputFixingParser.parse\u001b[39m\u001b[34m(self, completion)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:83\u001b[39m, in \u001b[36mPydanticOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a pydantic object.\u001b[39;00m\n\u001b[32m     76\u001b[39m \n\u001b[32m     77\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \u001b[33;03m    The parsed pydantic object.\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:97\u001b[39m, in \u001b[36mJsonOutputParser.parse\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse the output of an LLM call to a JSON object.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m    The parsed JSON object.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:67\u001b[39m, in \u001b[36mPydanticOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     json_object = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_obj(json_object)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\json.py:86\u001b[39m, in \u001b[36mJsonOutputParser.parse_result\u001b[39m\u001b[34m(self, result, partial)\u001b[39m\n\u001b[32m     85\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid json output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output=text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOutputParserException\u001b[39m: Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:86\u001b[39m, in \u001b[36mOutputFixingParser.parse\u001b[39m\u001b[34m(self, completion)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     84\u001b[39m     completion = \u001b[38;5;28mself\u001b[39m.retry_chain.invoke(\n\u001b[32m     85\u001b[39m         \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m             instructions=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_format_instructions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     87\u001b[39m             completion=completion,\n\u001b[32m     88\u001b[39m             error=\u001b[38;5;28mrepr\u001b[39m(e),\n\u001b[32m     89\u001b[39m         )\n\u001b[32m     90\u001b[39m     )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# Case: self.parser does not have get_format_instructions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py:92\u001b[39m, in \u001b[36mPydanticOutputParser.get_format_instructions\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# Copy schema to avoid altering original Pydantic schema.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m schema = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpydantic_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_json_schema\u001b[49m().items())\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Remove extraneous fields.\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'Actor' has no attribute 'model_json_schema'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[127]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# OutputFixingParser ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ëª»ëœ í˜•ì‹ì˜ ì¶œë ¥ì„ íŒŒì‹±\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m actor = \u001b[43mnew_parser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmisformatted\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain\\output_parsers\\fix.py:93\u001b[39m, in \u001b[36mOutputFixingParser.parse\u001b[39m\u001b[34m(self, completion)\u001b[39m\n\u001b[32m     84\u001b[39m                     completion = \u001b[38;5;28mself\u001b[39m.retry_chain.invoke(\n\u001b[32m     85\u001b[39m                         \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     86\u001b[39m                             instructions=\u001b[38;5;28mself\u001b[39m.parser.get_format_instructions(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m                         )\n\u001b[32m     90\u001b[39m                     )\n\u001b[32m     91\u001b[39m                 \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[32m     92\u001b[39m                     \u001b[38;5;66;03m# Case: self.parser does not have get_format_instructions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m                     completion = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                            \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[33m\"\u001b[39m\u001b[33mFailed to parse\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3023\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3021\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3022\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3023\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3024\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3025\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\prompts\\base.py:210\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    209\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] = config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1925\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1921\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1922\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1923\u001b[39m         output = cast(\n\u001b[32m   1924\u001b[39m             Output,\n\u001b[32m-> \u001b[39m\u001b[32m1925\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1927\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1928\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1933\u001b[39m         )\n\u001b[32m   1934\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1935\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\runnables\\config.py:430\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\prompts\\base.py:184\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     _inner_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_prompt(**_inner_input)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Goodusdata\\Desktop\\jy\\AI Study\\langchain\\Lib\\site-packages\\langchain_core\\prompts\\base.py:178\u001b[39m, in \u001b[36mBasePromptTemplate._validate_input\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    172\u001b[39m     example_key = missing.pop()\n\u001b[32m    173\u001b[39m     msg += (\n\u001b[32m    174\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m to be part of the string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    175\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    177\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    179\u001b[39m         create_message(message=msg, error_code=ErrorCode.INVALID_PROMPT_INPUT)\n\u001b[32m    180\u001b[39m     )\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[31mKeyError\u001b[39m: \"Input to PromptTemplate is missing variables {'instructions'}.  Expected: ['completion', 'error', 'instructions'] Received: ['completion', 'error']\\nNote: if you intended {instructions} to be part of the string and not a variable, please escape it with double curly braces like: '{{instructions}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "# OutputFixingParser ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ëª»ëœ í˜•ì‹ì˜ ì¶œë ¥ì„ íŒŒì‹±\n",
    "actor = new_parser.parse(misformatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# íŒŒì‹±ëœ ê²°ê³¼\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mactor\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'actor' is not defined"
     ]
    }
   ],
   "source": [
    "# íŒŒì‹±ëœ ê²°ê³¼\n",
    "actor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
